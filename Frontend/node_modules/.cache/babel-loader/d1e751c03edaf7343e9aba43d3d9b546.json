{"ast":null,"code":"/**\n * Indexes for all substring searches (e.g. the term \"cat\" is indexed as \"c\", \"ca\", \"cat\", \"a\", \"at\", and \"t\").\n */\nvar AllSubstringsIndexStrategy = /*#__PURE__*/function () {\n  function AllSubstringsIndexStrategy() {}\n\n  var _proto = AllSubstringsIndexStrategy.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.expandToken = function expandToken(token) {\n    var expandedTokens = [];\n    var string;\n\n    for (var i = 0, length = token.length; i < length; ++i) {\n      string = '';\n\n      for (var j = i; j < length; ++j) {\n        string += token.charAt(j);\n        expandedTokens.push(string);\n      }\n    }\n\n    return expandedTokens;\n  };\n\n  return AllSubstringsIndexStrategy;\n}();\n/**\n * Indexes for exact word matches.\n */\n\n\nvar ExactWordIndexStrategy = /*#__PURE__*/function () {\n  function ExactWordIndexStrategy() {}\n\n  var _proto = ExactWordIndexStrategy.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.expandToken = function expandToken(token) {\n    return token ? [token] : [];\n  };\n\n  return ExactWordIndexStrategy;\n}();\n/**\n * Indexes for prefix searches (e.g. the term \"cat\" is indexed as \"c\", \"ca\", and \"cat\" allowing prefix search lookups).\n */\n\n\nvar PrefixIndexStrategy = /*#__PURE__*/function () {\n  function PrefixIndexStrategy() {}\n\n  var _proto = PrefixIndexStrategy.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.expandToken = function expandToken(token) {\n    var expandedTokens = [];\n    var string = '';\n\n    for (var i = 0, length = token.length; i < length; ++i) {\n      string += token.charAt(i);\n      expandedTokens.push(string);\n    }\n\n    return expandedTokens;\n  };\n\n  return PrefixIndexStrategy;\n}();\n/**\n * Enforces case-sensitive text matches.\n */\n\n\nvar CaseSensitiveSanitizer = /*#__PURE__*/function () {\n  function CaseSensitiveSanitizer() {}\n\n  var _proto = CaseSensitiveSanitizer.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.sanitize = function sanitize(text) {\n    return text ? text.trim() : '';\n  };\n\n  return CaseSensitiveSanitizer;\n}();\n/**\n * Sanitizes text by converting to a locale-friendly lower-case version and triming leading and trailing whitespace.\n */\n\n\nvar LowerCaseSanitizer = /*#__PURE__*/function () {\n  function LowerCaseSanitizer() {}\n\n  var _proto = LowerCaseSanitizer.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.sanitize = function sanitize(text) {\n    return text ? text.toLocaleLowerCase().trim() : '';\n  };\n\n  return LowerCaseSanitizer;\n}();\n/**\n * Find and return a nested object value.\n *\n * @param object to crawl\n * @param path Property path\n * @returns {any}\n */\n\n\nfunction getNestedFieldValue(object, path) {\n  path = path || [];\n  object = object || {};\n  var value = object; // walk down the property path\n\n  for (var i = 0; i < path.length; i++) {\n    value = value[path[i]];\n\n    if (value == null) {\n      return null;\n    }\n  }\n\n  return value;\n}\n/**\n * Search index capable of returning results matching a set of tokens and ranked according to TF-IDF.\n */\n\n\nvar TfIdfSearchIndex = /*#__PURE__*/function () {\n  function TfIdfSearchIndex(uidFieldName) {\n    this._uidFieldName = uidFieldName;\n    this._tokenToIdfCache = {};\n    this._tokenMap = {};\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = TfIdfSearchIndex.prototype;\n\n  _proto.indexDocument = function indexDocument(token, uid, doc) {\n    this._tokenToIdfCache = {}; // New index invalidates previous IDF caches\n\n    var tokenMap = this._tokenMap;\n    var tokenDatum;\n\n    if (typeof tokenMap[token] !== 'object') {\n      tokenMap[token] = tokenDatum = {\n        $numDocumentOccurrences: 0,\n        $totalNumOccurrences: 1,\n        $uidMap: {}\n      };\n    } else {\n      tokenDatum = tokenMap[token];\n      tokenDatum.$totalNumOccurrences++;\n    }\n\n    var uidMap = tokenDatum.$uidMap;\n\n    if (typeof uidMap[uid] !== 'object') {\n      tokenDatum.$numDocumentOccurrences++;\n      uidMap[uid] = {\n        $document: doc,\n        $numTokenOccurrences: 1\n      };\n    } else {\n      uidMap[uid].$numTokenOccurrences++;\n    }\n  }\n  /**\n   * @inheritDocs\n   */\n  ;\n\n  _proto.search = function search(tokens, corpus) {\n    var uidToDocumentMap = {};\n\n    for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n      var token = tokens[i];\n      var tokenMetadata = this._tokenMap[token]; // Short circuit if no matches were found for any given token.\n\n      if (!tokenMetadata) {\n        return [];\n      }\n\n      if (i === 0) {\n        var keys = Object.keys(tokenMetadata.$uidMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n          uidToDocumentMap[uid] = tokenMetadata.$uidMap[uid].$document;\n        }\n      } else {\n        var keys = Object.keys(uidToDocumentMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n\n          if (typeof tokenMetadata.$uidMap[uid] !== 'object') {\n            delete uidToDocumentMap[uid];\n          }\n        }\n      }\n    }\n\n    var documents = [];\n\n    for (var uid in uidToDocumentMap) {\n      documents.push(uidToDocumentMap[uid]);\n    }\n\n    var calculateTfIdf = this._createCalculateTfIdf(); // Return documents sorted by TF-IDF\n\n\n    return documents.sort(function (documentA, documentB) {\n      return calculateTfIdf(tokens, documentB, corpus) - calculateTfIdf(tokens, documentA, corpus);\n    });\n  };\n\n  _proto._createCalculateIdf = function _createCalculateIdf() {\n    var tokenMap = this._tokenMap;\n    var tokenToIdfCache = this._tokenToIdfCache;\n    return function calculateIdf(token, documents) {\n      if (!tokenToIdfCache[token]) {\n        var numDocumentsWithToken = typeof tokenMap[token] !== 'undefined' ? tokenMap[token].$numDocumentOccurrences : 0;\n        tokenToIdfCache[token] = 1 + Math.log(documents.length / (1 + numDocumentsWithToken));\n      }\n\n      return tokenToIdfCache[token];\n    };\n  };\n\n  _proto._createCalculateTfIdf = function _createCalculateTfIdf() {\n    var tokenMap = this._tokenMap;\n    var uidFieldName = this._uidFieldName;\n\n    var calculateIdf = this._createCalculateIdf();\n\n    return function calculateTfIdf(tokens, document, documents) {\n      var score = 0;\n\n      for (var i = 0, numTokens = tokens.length; i < numTokens; ++i) {\n        var token = tokens[i];\n        var inverseDocumentFrequency = calculateIdf(token, documents);\n\n        if (inverseDocumentFrequency === Infinity) {\n          inverseDocumentFrequency = 0;\n        }\n\n        var uid;\n\n        if (uidFieldName instanceof Array) {\n          uid = document && getNestedFieldValue(document, uidFieldName);\n        } else {\n          uid = document && document[uidFieldName];\n        }\n\n        var termFrequency = typeof tokenMap[token] !== 'undefined' && typeof tokenMap[token].$uidMap[uid] !== 'undefined' ? tokenMap[token].$uidMap[uid].$numTokenOccurrences : 0;\n        score += termFrequency * inverseDocumentFrequency;\n      }\n\n      return score;\n    };\n  };\n\n  return TfIdfSearchIndex;\n}();\n/**\n * Search index capable of returning results matching a set of tokens but without any meaningful rank or order.\n */\n\n\nvar UnorderedSearchIndex = /*#__PURE__*/function () {\n  function UnorderedSearchIndex() {\n    this._tokenToUidToDocumentMap = {};\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = UnorderedSearchIndex.prototype;\n\n  _proto.indexDocument = function indexDocument(token, uid, doc) {\n    if (typeof this._tokenToUidToDocumentMap[token] !== 'object') {\n      this._tokenToUidToDocumentMap[token] = {};\n    }\n\n    this._tokenToUidToDocumentMap[token][uid] = doc;\n  }\n  /**\n   * @inheritDocs\n   */\n  ;\n\n  _proto.search = function search(tokens, corpus) {\n    var intersectingDocumentMap = {};\n    var tokenToUidToDocumentMap = this._tokenToUidToDocumentMap;\n\n    for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n      var token = tokens[i];\n      var documentMap = tokenToUidToDocumentMap[token]; // Short circuit if no matches were found for any given token.\n\n      if (!documentMap) {\n        return [];\n      }\n\n      if (i === 0) {\n        var keys = Object.keys(documentMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n          intersectingDocumentMap[uid] = documentMap[uid];\n        }\n      } else {\n        var keys = Object.keys(intersectingDocumentMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n\n          if (typeof documentMap[uid] !== 'object') {\n            delete intersectingDocumentMap[uid];\n          }\n        }\n      }\n    }\n\n    var keys = Object.keys(intersectingDocumentMap);\n    var documents = [];\n\n    for (var i = 0, numKeys = keys.length; i < numKeys; i++) {\n      var uid = keys[i];\n      documents.push(intersectingDocumentMap[uid]);\n    }\n\n    return documents;\n  };\n\n  return UnorderedSearchIndex;\n}();\n\nvar REGEX = /[^a-zа-яё0-9\\-']+/i;\n/**\n * Simple tokenizer that splits strings on whitespace characters and returns an array of all non-empty substrings.\n */\n\nvar SimpleTokenizer = /*#__PURE__*/function () {\n  function SimpleTokenizer() {}\n\n  var _proto = SimpleTokenizer.prototype;\n  /**\n   * @inheritDocs\n   */\n\n  _proto.tokenize = function tokenize(text) {\n    return text.split(REGEX).filter(function (text) {\n      return text;\n    } // Filter empty tokens\n    );\n  };\n\n  return SimpleTokenizer;\n}();\n/**\n * Stemming is the process of reducing search tokens to their root (or stem) so that searches for different forms of a\n * word will match. For example \"search\", \"searching\" and \"searched\" are all reduced to the stem \"search\".\n *\n * <p>This stemming tokenizer converts tokens (words) to their stem forms before returning them. It requires an\n * external stemming function to be provided; for this purpose I recommend the NPM 'porter-stemmer' library.\n *\n * <p>For more information see http : //tartarus.org/~martin/PorterStemmer/\n */\n\n\nvar StemmingTokenizer = /*#__PURE__*/function () {\n  /**\n   * Constructor.\n   *\n   * @param stemmingFunction Function capable of accepting a word and returning its stem.\n   * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n   */\n  function StemmingTokenizer(stemmingFunction, decoratedTokenizer) {\n    this._stemmingFunction = stemmingFunction;\n    this._tokenizer = decoratedTokenizer;\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = StemmingTokenizer.prototype;\n\n  _proto.tokenize = function tokenize(text) {\n    return this._tokenizer.tokenize(text).map(this._stemmingFunction);\n  };\n\n  return StemmingTokenizer;\n}();\n/**\n * Stop words list copied from Lunr JS.\n */\n\n\nvar StopWordsMap = {\n  a: true,\n  able: true,\n  about: true,\n  across: true,\n  after: true,\n  all: true,\n  almost: true,\n  also: true,\n  am: true,\n  among: true,\n  an: true,\n  and: true,\n  any: true,\n  are: true,\n  as: true,\n  at: true,\n  be: true,\n  because: true,\n  been: true,\n  but: true,\n  by: true,\n  can: true,\n  cannot: true,\n  could: true,\n  dear: true,\n  did: true,\n  'do': true,\n  does: true,\n  either: true,\n  'else': true,\n  ever: true,\n  every: true,\n  'for': true,\n  from: true,\n  'get': true,\n  got: true,\n  had: true,\n  has: true,\n  have: true,\n  he: true,\n  her: true,\n  hers: true,\n  him: true,\n  his: true,\n  how: true,\n  however: true,\n  i: true,\n  'if': true,\n  'in': true,\n  into: true,\n  is: true,\n  it: true,\n  its: true,\n  just: true,\n  least: true,\n  \"let\": true,\n  like: true,\n  likely: true,\n  may: true,\n  me: true,\n  might: true,\n  most: true,\n  must: true,\n  my: true,\n  neither: true,\n  no: true,\n  nor: true,\n  not: true,\n  of: true,\n  off: true,\n  often: true,\n  on: true,\n  only: true,\n  or: true,\n  other: true,\n  our: true,\n  own: true,\n  rather: true,\n  said: true,\n  say: true,\n  says: true,\n  she: true,\n  should: true,\n  since: true,\n  so: true,\n  some: true,\n  than: true,\n  that: true,\n  the: true,\n  their: true,\n  them: true,\n  then: true,\n  there: true,\n  these: true,\n  they: true,\n  'this': true,\n  tis: true,\n  to: true,\n  too: true,\n  twas: true,\n  us: true,\n  wants: true,\n  was: true,\n  we: true,\n  were: true,\n  what: true,\n  when: true,\n  where: true,\n  which: true,\n  'while': true,\n  who: true,\n  whom: true,\n  why: true,\n  will: true,\n  'with': true,\n  would: true,\n  yet: true,\n  you: true,\n  your: true\n}; // Prevent false positives for inherited properties\n\nStopWordsMap.constructor = false;\nStopWordsMap.hasOwnProperty = false;\nStopWordsMap.isPrototypeOf = false;\nStopWordsMap.propertyIsEnumerable = false;\nStopWordsMap.toLocaleString = false;\nStopWordsMap.toString = false;\nStopWordsMap.valueOf = false;\n/**\n * Stop words are very common (e.g. \"a\", \"and\", \"the\") and are often not semantically meaningful in the context of a\n * search. This tokenizer removes stop words from a set of tokens before passing the remaining tokens along for\n * indexing or searching purposes.\n */\n\nvar StopWordsTokenizer = /*#__PURE__*/function () {\n  /**\n   * Constructor.\n   *\n   * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n   */\n  function StopWordsTokenizer(decoratedTokenizer) {\n    this._tokenizer = decoratedTokenizer;\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = StopWordsTokenizer.prototype;\n\n  _proto.tokenize = function tokenize(text) {\n    return this._tokenizer.tokenize(text).filter(function (token) {\n      return !StopWordsMap[token];\n    });\n  };\n\n  return StopWordsTokenizer;\n}();\n\nfunction _defineProperties(target, props) {\n  for (var i = 0; i < props.length; i++) {\n    var descriptor = props[i];\n    descriptor.enumerable = descriptor.enumerable || false;\n    descriptor.configurable = true;\n    if (\"value\" in descriptor) descriptor.writable = true;\n    Object.defineProperty(target, descriptor.key, descriptor);\n  }\n}\n\nfunction _createClass(Constructor, protoProps, staticProps) {\n  if (protoProps) _defineProperties(Constructor.prototype, protoProps);\n  if (staticProps) _defineProperties(Constructor, staticProps);\n  return Constructor;\n}\n/**\n * Simple client-side searching within a set of documents.\n *\n * <p>Documents can be searched by any number of fields. Indexing and search strategies are highly customizable.\n */\n\n\nvar Search = /*#__PURE__*/function () {\n  /**\n   * Array containing either a property name or a path (list of property names) to a nested value\n   */\n\n  /**\n   * Constructor.\n   * @param uidFieldName Field containing values that uniquely identify search documents; this field's values are used\n   *                     to ensure that a search result set does not contain duplicate objects.\n   */\n  function Search(uidFieldName) {\n    if (!uidFieldName) {\n      throw Error('js-search requires a uid field name constructor parameter');\n    }\n\n    this._uidFieldName = uidFieldName; // Set default/recommended strategies\n\n    this._indexStrategy = new PrefixIndexStrategy();\n    this._searchIndex = new TfIdfSearchIndex(uidFieldName);\n    this._sanitizer = new LowerCaseSanitizer();\n    this._tokenizer = new SimpleTokenizer();\n    this._documents = [];\n    this._searchableFields = [];\n  }\n  /**\n   * Override the default index strategy.\n   * @param value Custom index strategy\n   * @throws Error if documents have already been indexed by this search instance\n   */\n\n\n  var _proto = Search.prototype;\n  /**\n   * Add a searchable document to the index. Document will automatically be indexed for search.\n   * @param document\n   */\n\n  _proto.addDocument = function addDocument(document) {\n    this.addDocuments([document]);\n  }\n  /**\n   * Adds searchable documents to the index. Documents will automatically be indexed for search.\n   * @param document\n   */\n  ;\n\n  _proto.addDocuments = function addDocuments(documents) {\n    this._documents = this._documents.concat(documents);\n    this.indexDocuments_(documents, this._searchableFields);\n  }\n  /**\n   * Add a new searchable field to the index. Existing documents will automatically be indexed using this new field.\n   *\n   * @param field Searchable field or field path. Pass a string to index a top-level field and an array of strings for nested fields.\n   */\n  ;\n\n  _proto.addIndex = function addIndex(field) {\n    this._searchableFields.push(field);\n\n    this.indexDocuments_(this._documents, [field]);\n  }\n  /**\n   * Search all documents for ones matching the specified query text.\n   * @param query\n   * @returns {Array<Object>}\n   */\n  ;\n\n  _proto.search = function search(query) {\n    var tokens = this._tokenizer.tokenize(this._sanitizer.sanitize(query));\n\n    return this._searchIndex.search(tokens, this._documents);\n  }\n  /**\n   * @param documents\n   * @param _searchableFields Array containing property names and paths (lists of property names) to nested values\n   * @private\n   */\n  ;\n\n  _proto.indexDocuments_ = function indexDocuments_(documents, _searchableFields) {\n    this._initialized = true;\n    var indexStrategy = this._indexStrategy;\n    var sanitizer = this._sanitizer;\n    var searchIndex = this._searchIndex;\n    var tokenizer = this._tokenizer;\n    var uidFieldName = this._uidFieldName;\n\n    for (var di = 0, numDocuments = documents.length; di < numDocuments; di++) {\n      var doc = documents[di];\n      var uid;\n\n      if (uidFieldName instanceof Array) {\n        uid = getNestedFieldValue(doc, uidFieldName);\n      } else {\n        uid = doc[uidFieldName];\n      }\n\n      for (var sfi = 0, numSearchableFields = _searchableFields.length; sfi < numSearchableFields; sfi++) {\n        var fieldValue;\n        var searchableField = _searchableFields[sfi];\n\n        if (searchableField instanceof Array) {\n          fieldValue = getNestedFieldValue(doc, searchableField);\n        } else {\n          fieldValue = doc[searchableField];\n        }\n\n        if (fieldValue != null && typeof fieldValue !== 'string' && fieldValue.toString) {\n          fieldValue = fieldValue.toString();\n        }\n\n        if (typeof fieldValue === 'string') {\n          var fieldTokens = tokenizer.tokenize(sanitizer.sanitize(fieldValue));\n\n          for (var fti = 0, numFieldValues = fieldTokens.length; fti < numFieldValues; fti++) {\n            var fieldToken = fieldTokens[fti];\n            var expandedTokens = indexStrategy.expandToken(fieldToken);\n\n            for (var eti = 0, nummExpandedTokens = expandedTokens.length; eti < nummExpandedTokens; eti++) {\n              var expandedToken = expandedTokens[eti];\n              searchIndex.indexDocument(expandedToken, uid, doc);\n            }\n          }\n        }\n      }\n    }\n  };\n\n  _createClass(Search, [{\n    key: \"indexStrategy\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('IIndexStrategy cannot be set after initialization');\n      }\n\n      this._indexStrategy = value;\n    },\n    get: function get() {\n      return this._indexStrategy;\n    }\n    /**\n     * Override the default text sanitizing strategy.\n     * @param value Custom text sanitizing strategy\n     * @throws Error if documents have already been indexed by this search instance\n     */\n\n  }, {\n    key: \"sanitizer\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('ISanitizer cannot be set after initialization');\n      }\n\n      this._sanitizer = value;\n    },\n    get: function get() {\n      return this._sanitizer;\n    }\n    /**\n     * Override the default search index strategy.\n     * @param value Custom search index strategy\n     * @throws Error if documents have already been indexed\n     */\n\n  }, {\n    key: \"searchIndex\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('ISearchIndex cannot be set after initialization');\n      }\n\n      this._searchIndex = value;\n    },\n    get: function get() {\n      return this._searchIndex;\n    }\n    /**\n     * Override the default text tokenizing strategy.\n     * @param value Custom text tokenizing strategy\n     * @throws Error if documents have already been indexed by this search instance\n     */\n\n  }, {\n    key: \"tokenizer\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('ITokenizer cannot be set after initialization');\n      }\n\n      this._tokenizer = value;\n    },\n    get: function get() {\n      return this._tokenizer;\n    }\n  }]);\n\n  return Search;\n}();\n/**\n * This utility highlights the occurrences of tokens within a string of text. It can be used to give visual indicators\n * of match criteria within searchable fields.\n *\n * <p>For performance purposes this highlighter only works with full-word or prefix token indexes.\n */\n\n\nvar TokenHighlighter = /*#__PURE__*/function () {\n  /**\n   * Constructor.\n   *\n   * @param opt_indexStrategy Index strategy used by Search\n   * @param opt_sanitizer Sanitizer used by Search\n   * @param opt_wrapperTagName Optional wrapper tag name; defaults to 'mark' (e.g. <mark>)\n   */\n  function TokenHighlighter(opt_indexStrategy, opt_sanitizer, opt_wrapperTagName) {\n    this._indexStrategy = opt_indexStrategy || new PrefixIndexStrategy();\n    this._sanitizer = opt_sanitizer || new LowerCaseSanitizer();\n    this._wrapperTagName = opt_wrapperTagName || 'mark';\n  }\n  /**\n   * Highlights token occurrences within a string by wrapping them with a DOM element.\n   *\n   * @param text e.g. \"john wayne\"\n   * @param tokens e.g. [\"wa\"]\n   * @returns {string} e.g. \"john <mark>wa</mark>yne\"\n   */\n\n\n  var _proto = TokenHighlighter.prototype;\n\n  _proto.highlight = function highlight(text, tokens) {\n    var tagsLength = this._wrapText('').length;\n\n    var tokenDictionary = Object.create(null); // Create a token map for easier lookup below.\n\n    for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n      var token = this._sanitizer.sanitize(tokens[i]);\n\n      var expandedTokens = this._indexStrategy.expandToken(token);\n\n      for (var j = 0, numExpandedTokens = expandedTokens.length; j < numExpandedTokens; j++) {\n        var expandedToken = expandedTokens[j];\n\n        if (!tokenDictionary[expandedToken]) {\n          tokenDictionary[expandedToken] = [token];\n        } else {\n          tokenDictionary[expandedToken].push(token);\n        }\n      }\n    } // Track actualCurrentWord and sanitizedCurrentWord separately in case we encounter nested tags.\n\n\n    var actualCurrentWord = '';\n    var sanitizedCurrentWord = '';\n    var currentWordStartIndex = 0; // Note this assumes either prefix or full word matching.\n\n    for (var i = 0, textLength = text.length; i < textLength; i++) {\n      var character = text.charAt(i);\n\n      if (character === ' ') {\n        actualCurrentWord = '';\n        sanitizedCurrentWord = '';\n        currentWordStartIndex = i + 1;\n      } else {\n        actualCurrentWord += character;\n        sanitizedCurrentWord += this._sanitizer.sanitize(character);\n      }\n\n      if (tokenDictionary[sanitizedCurrentWord] && tokenDictionary[sanitizedCurrentWord].indexOf(sanitizedCurrentWord) >= 0) {\n        actualCurrentWord = this._wrapText(actualCurrentWord);\n        text = text.substring(0, currentWordStartIndex) + actualCurrentWord + text.substring(i + 1);\n        i += tagsLength;\n        textLength += tagsLength;\n      }\n    }\n\n    return text;\n  }\n  /**\n   * @param text to wrap\n   * @returns Text wrapped by wrapper tag (e.g. \"foo\" becomes \"<mark>foo</mark>\")\n   * @private\n   */\n  ;\n\n  _proto._wrapText = function _wrapText(text) {\n    var tagName = this._wrapperTagName;\n    return \"<\" + tagName + \">\" + text + \"</\" + tagName + \">\";\n  };\n\n  return TokenHighlighter;\n}();\n\nexport { AllSubstringsIndexStrategy, CaseSensitiveSanitizer, ExactWordIndexStrategy, LowerCaseSanitizer, PrefixIndexStrategy, Search, SimpleTokenizer, StemmingTokenizer, StopWordsMap, StopWordsTokenizer, TfIdfSearchIndex, TokenHighlighter, UnorderedSearchIndex };","map":{"version":3,"sources":["C:/Users/jaker/Desktop/SES-2A-Team2/Frontend/node_modules/js-search/dist/esm/js-search.js"],"names":["AllSubstringsIndexStrategy","_proto","prototype","expandToken","token","expandedTokens","string","i","length","j","charAt","push","ExactWordIndexStrategy","PrefixIndexStrategy","CaseSensitiveSanitizer","sanitize","text","trim","LowerCaseSanitizer","toLocaleLowerCase","getNestedFieldValue","object","path","value","TfIdfSearchIndex","uidFieldName","_uidFieldName","_tokenToIdfCache","_tokenMap","indexDocument","uid","doc","tokenMap","tokenDatum","$numDocumentOccurrences","$totalNumOccurrences","$uidMap","uidMap","$document","$numTokenOccurrences","search","tokens","corpus","uidToDocumentMap","numTokens","tokenMetadata","keys","Object","numKeys","documents","calculateTfIdf","_createCalculateTfIdf","sort","documentA","documentB","_createCalculateIdf","tokenToIdfCache","calculateIdf","numDocumentsWithToken","Math","log","document","score","inverseDocumentFrequency","Infinity","Array","termFrequency","UnorderedSearchIndex","_tokenToUidToDocumentMap","intersectingDocumentMap","tokenToUidToDocumentMap","documentMap","REGEX","SimpleTokenizer","tokenize","split","filter","StemmingTokenizer","stemmingFunction","decoratedTokenizer","_stemmingFunction","_tokenizer","map","StopWordsMap","a","able","about","across","after","all","almost","also","am","among","an","and","any","are","as","at","be","because","been","but","by","can","cannot","could","dear","did","does","either","ever","every","from","got","had","has","have","he","her","hers","him","his","how","however","into","is","it","its","just","least","like","likely","may","me","might","most","must","my","neither","no","nor","not","of","off","often","on","only","or","other","our","own","rather","said","say","says","she","should","since","so","some","than","that","the","their","them","then","there","these","they","tis","to","too","twas","us","wants","was","we","were","what","when","where","which","who","whom","why","will","would","yet","you","your","constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf","StopWordsTokenizer","_defineProperties","target","props","descriptor","enumerable","configurable","writable","defineProperty","key","_createClass","Constructor","protoProps","staticProps","Search","Error","_indexStrategy","_searchIndex","_sanitizer","_documents","_searchableFields","addDocument","addDocuments","concat","indexDocuments_","addIndex","field","query","_initialized","indexStrategy","sanitizer","searchIndex","tokenizer","di","numDocuments","sfi","numSearchableFields","fieldValue","searchableField","fieldTokens","fti","numFieldValues","fieldToken","eti","nummExpandedTokens","expandedToken","set","get","TokenHighlighter","opt_indexStrategy","opt_sanitizer","opt_wrapperTagName","_wrapperTagName","highlight","tagsLength","_wrapText","tokenDictionary","create","numExpandedTokens","actualCurrentWord","sanitizedCurrentWord","currentWordStartIndex","textLength","character","indexOf","substring","tagName"],"mappings":"AAAA;AACA;AACA;AACA,IAAIA,0BAA0B,GAAG,aAAa,YAAY;AACxD,WAASA,0BAAT,GAAsC,CAAE;;AAExC,MAAIC,MAAM,GAAGD,0BAA0B,CAACE,SAAxC;AAEA;AACF;AACA;;AACED,EAAAA,MAAM,CAACE,WAAP,GAAqB,SAASA,WAAT,CAAqBC,KAArB,EAA4B;AAC/C,QAAIC,cAAc,GAAG,EAArB;AACA,QAAIC,MAAJ;;AAEA,SAAK,IAAIC,CAAC,GAAG,CAAR,EAAWC,MAAM,GAAGJ,KAAK,CAACI,MAA/B,EAAuCD,CAAC,GAAGC,MAA3C,EAAmD,EAAED,CAArD,EAAwD;AACtDD,MAAAA,MAAM,GAAG,EAAT;;AAEA,WAAK,IAAIG,CAAC,GAAGF,CAAb,EAAgBE,CAAC,GAAGD,MAApB,EAA4B,EAAEC,CAA9B,EAAiC;AAC/BH,QAAAA,MAAM,IAAIF,KAAK,CAACM,MAAN,CAAaD,CAAb,CAAV;AACAJ,QAAAA,cAAc,CAACM,IAAf,CAAoBL,MAApB;AACD;AACF;;AAED,WAAOD,cAAP;AACD,GAdD;;AAgBA,SAAOL,0BAAP;AACD,CAzB6C,EAA9C;AA2BA;AACA;AACA;;;AACA,IAAIY,sBAAsB,GAAG,aAAa,YAAY;AACpD,WAASA,sBAAT,GAAkC,CAAE;;AAEpC,MAAIX,MAAM,GAAGW,sBAAsB,CAACV,SAApC;AAEA;AACF;AACA;;AACED,EAAAA,MAAM,CAACE,WAAP,GAAqB,SAASA,WAAT,CAAqBC,KAArB,EAA4B;AAC/C,WAAOA,KAAK,GAAG,CAACA,KAAD,CAAH,GAAa,EAAzB;AACD,GAFD;;AAIA,SAAOQ,sBAAP;AACD,CAbyC,EAA1C;AAeA;AACA;AACA;;;AACA,IAAIC,mBAAmB,GAAG,aAAa,YAAY;AACjD,WAASA,mBAAT,GAA+B,CAAE;;AAEjC,MAAIZ,MAAM,GAAGY,mBAAmB,CAACX,SAAjC;AAEA;AACF;AACA;;AACED,EAAAA,MAAM,CAACE,WAAP,GAAqB,SAASA,WAAT,CAAqBC,KAArB,EAA4B;AAC/C,QAAIC,cAAc,GAAG,EAArB;AACA,QAAIC,MAAM,GAAG,EAAb;;AAEA,SAAK,IAAIC,CAAC,GAAG,CAAR,EAAWC,MAAM,GAAGJ,KAAK,CAACI,MAA/B,EAAuCD,CAAC,GAAGC,MAA3C,EAAmD,EAAED,CAArD,EAAwD;AACtDD,MAAAA,MAAM,IAAIF,KAAK,CAACM,MAAN,CAAaH,CAAb,CAAV;AACAF,MAAAA,cAAc,CAACM,IAAf,CAAoBL,MAApB;AACD;;AAED,WAAOD,cAAP;AACD,GAVD;;AAYA,SAAOQ,mBAAP;AACD,CArBsC,EAAvC;AAuBA;AACA;AACA;;;AACA,IAAIC,sBAAsB,GAAG,aAAa,YAAY;AACpD,WAASA,sBAAT,GAAkC,CAAE;;AAEpC,MAAIb,MAAM,GAAGa,sBAAsB,CAACZ,SAApC;AAEA;AACF;AACA;;AACED,EAAAA,MAAM,CAACc,QAAP,GAAkB,SAASA,QAAT,CAAkBC,IAAlB,EAAwB;AACxC,WAAOA,IAAI,GAAGA,IAAI,CAACC,IAAL,EAAH,GAAiB,EAA5B;AACD,GAFD;;AAIA,SAAOH,sBAAP;AACD,CAbyC,EAA1C;AAeA;AACA;AACA;;;AACA,IAAII,kBAAkB,GAAG,aAAa,YAAY;AAChD,WAASA,kBAAT,GAA8B,CAAE;;AAEhC,MAAIjB,MAAM,GAAGiB,kBAAkB,CAAChB,SAAhC;AAEA;AACF;AACA;;AACED,EAAAA,MAAM,CAACc,QAAP,GAAkB,SAASA,QAAT,CAAkBC,IAAlB,EAAwB;AACxC,WAAOA,IAAI,GAAGA,IAAI,CAACG,iBAAL,GAAyBF,IAAzB,EAAH,GAAqC,EAAhD;AACD,GAFD;;AAIA,SAAOC,kBAAP;AACD,CAbqC,EAAtC;AAeA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,SAASE,mBAAT,CAA6BC,MAA7B,EAAqCC,IAArC,EAA2C;AACzCA,EAAAA,IAAI,GAAGA,IAAI,IAAI,EAAf;AACAD,EAAAA,MAAM,GAAGA,MAAM,IAAI,EAAnB;AACA,MAAIE,KAAK,GAAGF,MAAZ,CAHyC,CAGrB;;AAEpB,OAAK,IAAId,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGe,IAAI,CAACd,MAAzB,EAAiCD,CAAC,EAAlC,EAAsC;AACpCgB,IAAAA,KAAK,GAAGA,KAAK,CAACD,IAAI,CAACf,CAAD,CAAL,CAAb;;AAEA,QAAIgB,KAAK,IAAI,IAAb,EAAmB;AACjB,aAAO,IAAP;AACD;AACF;;AAED,SAAOA,KAAP;AACD;AAED;AACA;AACA;;;AACA,IAAIC,gBAAgB,GAAG,aAAa,YAAY;AAC9C,WAASA,gBAAT,CAA0BC,YAA1B,EAAwC;AACtC,SAAKC,aAAL,GAAqBD,YAArB;AACA,SAAKE,gBAAL,GAAwB,EAAxB;AACA,SAAKC,SAAL,GAAiB,EAAjB;AACD;AACD;AACF;AACA;;;AAGE,MAAI3B,MAAM,GAAGuB,gBAAgB,CAACtB,SAA9B;;AAEAD,EAAAA,MAAM,CAAC4B,aAAP,GAAuB,SAASA,aAAT,CAAuBzB,KAAvB,EAA8B0B,GAA9B,EAAmCC,GAAnC,EAAwC;AAC7D,SAAKJ,gBAAL,GAAwB,EAAxB,CAD6D,CACjC;;AAE5B,QAAIK,QAAQ,GAAG,KAAKJ,SAApB;AACA,QAAIK,UAAJ;;AAEA,QAAI,OAAOD,QAAQ,CAAC5B,KAAD,CAAf,KAA2B,QAA/B,EAAyC;AACvC4B,MAAAA,QAAQ,CAAC5B,KAAD,CAAR,GAAkB6B,UAAU,GAAG;AAC7BC,QAAAA,uBAAuB,EAAE,CADI;AAE7BC,QAAAA,oBAAoB,EAAE,CAFO;AAG7BC,QAAAA,OAAO,EAAE;AAHoB,OAA/B;AAKD,KAND,MAMO;AACLH,MAAAA,UAAU,GAAGD,QAAQ,CAAC5B,KAAD,CAArB;AACA6B,MAAAA,UAAU,CAACE,oBAAX;AACD;;AAED,QAAIE,MAAM,GAAGJ,UAAU,CAACG,OAAxB;;AAEA,QAAI,OAAOC,MAAM,CAACP,GAAD,CAAb,KAAuB,QAA3B,EAAqC;AACnCG,MAAAA,UAAU,CAACC,uBAAX;AACAG,MAAAA,MAAM,CAACP,GAAD,CAAN,GAAc;AACZQ,QAAAA,SAAS,EAAEP,GADC;AAEZQ,QAAAA,oBAAoB,EAAE;AAFV,OAAd;AAID,KAND,MAMO;AACLF,MAAAA,MAAM,CAACP,GAAD,CAAN,CAAYS,oBAAZ;AACD;AACF;AACD;AACF;AACA;AA/BE;;AAkCAtC,EAAAA,MAAM,CAACuC,MAAP,GAAgB,SAASA,MAAT,CAAgBC,MAAhB,EAAwBC,MAAxB,EAAgC;AAC9C,QAAIC,gBAAgB,GAAG,EAAvB;;AAEA,SAAK,IAAIpC,CAAC,GAAG,CAAR,EAAWqC,SAAS,GAAGH,MAAM,CAACjC,MAAnC,EAA2CD,CAAC,GAAGqC,SAA/C,EAA0DrC,CAAC,EAA3D,EAA+D;AAC7D,UAAIH,KAAK,GAAGqC,MAAM,CAAClC,CAAD,CAAlB;AACA,UAAIsC,aAAa,GAAG,KAAKjB,SAAL,CAAexB,KAAf,CAApB,CAF6D,CAElB;;AAE3C,UAAI,CAACyC,aAAL,EAAoB;AAClB,eAAO,EAAP;AACD;;AAED,UAAItC,CAAC,KAAK,CAAV,EAAa;AACX,YAAIuC,IAAI,GAAGC,MAAM,CAACD,IAAP,CAAYD,aAAa,CAACT,OAA1B,CAAX;;AAEA,aAAK,IAAI3B,CAAC,GAAG,CAAR,EAAWuC,OAAO,GAAGF,IAAI,CAACtC,MAA/B,EAAuCC,CAAC,GAAGuC,OAA3C,EAAoDvC,CAAC,EAArD,EAAyD;AACvD,cAAIqB,GAAG,GAAGgB,IAAI,CAACrC,CAAD,CAAd;AACAkC,UAAAA,gBAAgB,CAACb,GAAD,CAAhB,GAAwBe,aAAa,CAACT,OAAd,CAAsBN,GAAtB,EAA2BQ,SAAnD;AACD;AACF,OAPD,MAOO;AACL,YAAIQ,IAAI,GAAGC,MAAM,CAACD,IAAP,CAAYH,gBAAZ,CAAX;;AAEA,aAAK,IAAIlC,CAAC,GAAG,CAAR,EAAWuC,OAAO,GAAGF,IAAI,CAACtC,MAA/B,EAAuCC,CAAC,GAAGuC,OAA3C,EAAoDvC,CAAC,EAArD,EAAyD;AACvD,cAAIqB,GAAG,GAAGgB,IAAI,CAACrC,CAAD,CAAd;;AAEA,cAAI,OAAOoC,aAAa,CAACT,OAAd,CAAsBN,GAAtB,CAAP,KAAsC,QAA1C,EAAoD;AAClD,mBAAOa,gBAAgB,CAACb,GAAD,CAAvB;AACD;AACF;AACF;AACF;;AAED,QAAImB,SAAS,GAAG,EAAhB;;AAEA,SAAK,IAAInB,GAAT,IAAgBa,gBAAhB,EAAkC;AAChCM,MAAAA,SAAS,CAACtC,IAAV,CAAegC,gBAAgB,CAACb,GAAD,CAA/B;AACD;;AAED,QAAIoB,cAAc,GAAG,KAAKC,qBAAL,EAArB,CArC8C,CAqCK;;;AAGnD,WAAOF,SAAS,CAACG,IAAV,CAAe,UAAUC,SAAV,EAAqBC,SAArB,EAAgC;AACpD,aAAOJ,cAAc,CAACT,MAAD,EAASa,SAAT,EAAoBZ,MAApB,CAAd,GAA4CQ,cAAc,CAACT,MAAD,EAASY,SAAT,EAAoBX,MAApB,CAAjE;AACD,KAFM,CAAP;AAGD,GA3CD;;AA6CAzC,EAAAA,MAAM,CAACsD,mBAAP,GAA6B,SAASA,mBAAT,GAA+B;AAC1D,QAAIvB,QAAQ,GAAG,KAAKJ,SAApB;AACA,QAAI4B,eAAe,GAAG,KAAK7B,gBAA3B;AACA,WAAO,SAAS8B,YAAT,CAAsBrD,KAAtB,EAA6B6C,SAA7B,EAAwC;AAC7C,UAAI,CAACO,eAAe,CAACpD,KAAD,CAApB,EAA6B;AAC3B,YAAIsD,qBAAqB,GAAG,OAAO1B,QAAQ,CAAC5B,KAAD,CAAf,KAA2B,WAA3B,GAAyC4B,QAAQ,CAAC5B,KAAD,CAAR,CAAgB8B,uBAAzD,GAAmF,CAA/G;AACAsB,QAAAA,eAAe,CAACpD,KAAD,CAAf,GAAyB,IAAIuD,IAAI,CAACC,GAAL,CAASX,SAAS,CAACzC,MAAV,IAAoB,IAAIkD,qBAAxB,CAAT,CAA7B;AACD;;AAED,aAAOF,eAAe,CAACpD,KAAD,CAAtB;AACD,KAPD;AAQD,GAXD;;AAaAH,EAAAA,MAAM,CAACkD,qBAAP,GAA+B,SAASA,qBAAT,GAAiC;AAC9D,QAAInB,QAAQ,GAAG,KAAKJ,SAApB;AACA,QAAIH,YAAY,GAAG,KAAKC,aAAxB;;AAEA,QAAI+B,YAAY,GAAG,KAAKF,mBAAL,EAAnB;;AAEA,WAAO,SAASL,cAAT,CAAwBT,MAAxB,EAAgCoB,QAAhC,EAA0CZ,SAA1C,EAAqD;AAC1D,UAAIa,KAAK,GAAG,CAAZ;;AAEA,WAAK,IAAIvD,CAAC,GAAG,CAAR,EAAWqC,SAAS,GAAGH,MAAM,CAACjC,MAAnC,EAA2CD,CAAC,GAAGqC,SAA/C,EAA0D,EAAErC,CAA5D,EAA+D;AAC7D,YAAIH,KAAK,GAAGqC,MAAM,CAAClC,CAAD,CAAlB;AACA,YAAIwD,wBAAwB,GAAGN,YAAY,CAACrD,KAAD,EAAQ6C,SAAR,CAA3C;;AAEA,YAAIc,wBAAwB,KAAKC,QAAjC,EAA2C;AACzCD,UAAAA,wBAAwB,GAAG,CAA3B;AACD;;AAED,YAAIjC,GAAJ;;AAEA,YAAIL,YAAY,YAAYwC,KAA5B,EAAmC;AACjCnC,UAAAA,GAAG,GAAG+B,QAAQ,IAAIzC,mBAAmB,CAACyC,QAAD,EAAWpC,YAAX,CAArC;AACD,SAFD,MAEO;AACLK,UAAAA,GAAG,GAAG+B,QAAQ,IAAIA,QAAQ,CAACpC,YAAD,CAA1B;AACD;;AAED,YAAIyC,aAAa,GAAG,OAAOlC,QAAQ,CAAC5B,KAAD,CAAf,KAA2B,WAA3B,IAA0C,OAAO4B,QAAQ,CAAC5B,KAAD,CAAR,CAAgBgC,OAAhB,CAAwBN,GAAxB,CAAP,KAAwC,WAAlF,GAAgGE,QAAQ,CAAC5B,KAAD,CAAR,CAAgBgC,OAAhB,CAAwBN,GAAxB,EAA6BS,oBAA7H,GAAoJ,CAAxK;AACAuB,QAAAA,KAAK,IAAII,aAAa,GAAGH,wBAAzB;AACD;;AAED,aAAOD,KAAP;AACD,KAxBD;AAyBD,GA/BD;;AAiCA,SAAOtC,gBAAP;AACD,CA3ImC,EAApC;AA6IA;AACA;AACA;;;AACA,IAAI2C,oBAAoB,GAAG,aAAa,YAAY;AAClD,WAASA,oBAAT,GAAgC;AAC9B,SAAKC,wBAAL,GAAgC,EAAhC;AACD;AACD;AACF;AACA;;;AAGE,MAAInE,MAAM,GAAGkE,oBAAoB,CAACjE,SAAlC;;AAEAD,EAAAA,MAAM,CAAC4B,aAAP,GAAuB,SAASA,aAAT,CAAuBzB,KAAvB,EAA8B0B,GAA9B,EAAmCC,GAAnC,EAAwC;AAC7D,QAAI,OAAO,KAAKqC,wBAAL,CAA8BhE,KAA9B,CAAP,KAAgD,QAApD,EAA8D;AAC5D,WAAKgE,wBAAL,CAA8BhE,KAA9B,IAAuC,EAAvC;AACD;;AAED,SAAKgE,wBAAL,CAA8BhE,KAA9B,EAAqC0B,GAArC,IAA4CC,GAA5C;AACD;AACD;AACF;AACA;AATE;;AAYA9B,EAAAA,MAAM,CAACuC,MAAP,GAAgB,SAASA,MAAT,CAAgBC,MAAhB,EAAwBC,MAAxB,EAAgC;AAC9C,QAAI2B,uBAAuB,GAAG,EAA9B;AACA,QAAIC,uBAAuB,GAAG,KAAKF,wBAAnC;;AAEA,SAAK,IAAI7D,CAAC,GAAG,CAAR,EAAWqC,SAAS,GAAGH,MAAM,CAACjC,MAAnC,EAA2CD,CAAC,GAAGqC,SAA/C,EAA0DrC,CAAC,EAA3D,EAA+D;AAC7D,UAAIH,KAAK,GAAGqC,MAAM,CAAClC,CAAD,CAAlB;AACA,UAAIgE,WAAW,GAAGD,uBAAuB,CAAClE,KAAD,CAAzC,CAF6D,CAEX;;AAElD,UAAI,CAACmE,WAAL,EAAkB;AAChB,eAAO,EAAP;AACD;;AAED,UAAIhE,CAAC,KAAK,CAAV,EAAa;AACX,YAAIuC,IAAI,GAAGC,MAAM,CAACD,IAAP,CAAYyB,WAAZ,CAAX;;AAEA,aAAK,IAAI9D,CAAC,GAAG,CAAR,EAAWuC,OAAO,GAAGF,IAAI,CAACtC,MAA/B,EAAuCC,CAAC,GAAGuC,OAA3C,EAAoDvC,CAAC,EAArD,EAAyD;AACvD,cAAIqB,GAAG,GAAGgB,IAAI,CAACrC,CAAD,CAAd;AACA4D,UAAAA,uBAAuB,CAACvC,GAAD,CAAvB,GAA+ByC,WAAW,CAACzC,GAAD,CAA1C;AACD;AACF,OAPD,MAOO;AACL,YAAIgB,IAAI,GAAGC,MAAM,CAACD,IAAP,CAAYuB,uBAAZ,CAAX;;AAEA,aAAK,IAAI5D,CAAC,GAAG,CAAR,EAAWuC,OAAO,GAAGF,IAAI,CAACtC,MAA/B,EAAuCC,CAAC,GAAGuC,OAA3C,EAAoDvC,CAAC,EAArD,EAAyD;AACvD,cAAIqB,GAAG,GAAGgB,IAAI,CAACrC,CAAD,CAAd;;AAEA,cAAI,OAAO8D,WAAW,CAACzC,GAAD,CAAlB,KAA4B,QAAhC,EAA0C;AACxC,mBAAOuC,uBAAuB,CAACvC,GAAD,CAA9B;AACD;AACF;AACF;AACF;;AAED,QAAIgB,IAAI,GAAGC,MAAM,CAACD,IAAP,CAAYuB,uBAAZ,CAAX;AACA,QAAIpB,SAAS,GAAG,EAAhB;;AAEA,SAAK,IAAI1C,CAAC,GAAG,CAAR,EAAWyC,OAAO,GAAGF,IAAI,CAACtC,MAA/B,EAAuCD,CAAC,GAAGyC,OAA3C,EAAoDzC,CAAC,EAArD,EAAyD;AACvD,UAAIuB,GAAG,GAAGgB,IAAI,CAACvC,CAAD,CAAd;AACA0C,MAAAA,SAAS,CAACtC,IAAV,CAAe0D,uBAAuB,CAACvC,GAAD,CAAtC;AACD;;AAED,WAAOmB,SAAP;AACD,GAzCD;;AA2CA,SAAOkB,oBAAP;AACD,CAnEuC,EAAxC;;AAqEA,IAAIK,KAAK,GAAG,oBAAZ;AACA;AACA;AACA;;AAEA,IAAIC,eAAe,GAAG,aAAa,YAAY;AAC7C,WAASA,eAAT,GAA2B,CAAE;;AAE7B,MAAIxE,MAAM,GAAGwE,eAAe,CAACvE,SAA7B;AAEA;AACF;AACA;;AACED,EAAAA,MAAM,CAACyE,QAAP,GAAkB,SAASA,QAAT,CAAkB1D,IAAlB,EAAwB;AACxC,WAAOA,IAAI,CAAC2D,KAAL,CAAWH,KAAX,EAAkBI,MAAlB,CAAyB,UAAU5D,IAAV,EAAgB;AAC9C,aAAOA,IAAP;AACD,KAFM,CAEL;AAFK,KAAP;AAID,GALD;;AAOA,SAAOyD,eAAP;AACD,CAhBkC,EAAnC;AAkBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACA,IAAII,iBAAiB,GAAG,aAAa,YAAY;AAC/C;AACF;AACA;AACA;AACA;AACA;AACE,WAASA,iBAAT,CAA2BC,gBAA3B,EAA6CC,kBAA7C,EAAiE;AAC/D,SAAKC,iBAAL,GAAyBF,gBAAzB;AACA,SAAKG,UAAL,GAAkBF,kBAAlB;AACD;AACD;AACF;AACA;;;AAGE,MAAI9E,MAAM,GAAG4E,iBAAiB,CAAC3E,SAA/B;;AAEAD,EAAAA,MAAM,CAACyE,QAAP,GAAkB,SAASA,QAAT,CAAkB1D,IAAlB,EAAwB;AACxC,WAAO,KAAKiE,UAAL,CAAgBP,QAAhB,CAAyB1D,IAAzB,EAA+BkE,GAA/B,CAAmC,KAAKF,iBAAxC,CAAP;AACD,GAFD;;AAIA,SAAOH,iBAAP;AACD,CAvBoC,EAArC;AAyBA;AACA;AACA;;;AACA,IAAIM,YAAY,GAAG;AACjBC,EAAAA,CAAC,EAAE,IADc;AAEjBC,EAAAA,IAAI,EAAE,IAFW;AAGjBC,EAAAA,KAAK,EAAE,IAHU;AAIjBC,EAAAA,MAAM,EAAE,IAJS;AAKjBC,EAAAA,KAAK,EAAE,IALU;AAMjBC,EAAAA,GAAG,EAAE,IANY;AAOjBC,EAAAA,MAAM,EAAE,IAPS;AAQjBC,EAAAA,IAAI,EAAE,IARW;AASjBC,EAAAA,EAAE,EAAE,IATa;AAUjBC,EAAAA,KAAK,EAAE,IAVU;AAWjBC,EAAAA,EAAE,EAAE,IAXa;AAYjBC,EAAAA,GAAG,EAAE,IAZY;AAajBC,EAAAA,GAAG,EAAE,IAbY;AAcjBC,EAAAA,GAAG,EAAE,IAdY;AAejBC,EAAAA,EAAE,EAAE,IAfa;AAgBjBC,EAAAA,EAAE,EAAE,IAhBa;AAiBjBC,EAAAA,EAAE,EAAE,IAjBa;AAkBjBC,EAAAA,OAAO,EAAE,IAlBQ;AAmBjBC,EAAAA,IAAI,EAAE,IAnBW;AAoBjBC,EAAAA,GAAG,EAAE,IApBY;AAqBjBC,EAAAA,EAAE,EAAE,IArBa;AAsBjBC,EAAAA,GAAG,EAAE,IAtBY;AAuBjBC,EAAAA,MAAM,EAAE,IAvBS;AAwBjBC,EAAAA,KAAK,EAAE,IAxBU;AAyBjBC,EAAAA,IAAI,EAAE,IAzBW;AA0BjBC,EAAAA,GAAG,EAAE,IA1BY;AA2BjB,QAAM,IA3BW;AA4BjBC,EAAAA,IAAI,EAAE,IA5BW;AA6BjBC,EAAAA,MAAM,EAAE,IA7BS;AA8BjB,UAAQ,IA9BS;AA+BjBC,EAAAA,IAAI,EAAE,IA/BW;AAgCjBC,EAAAA,KAAK,EAAE,IAhCU;AAiCjB,SAAO,IAjCU;AAkCjBC,EAAAA,IAAI,EAAE,IAlCW;AAmCjB,SAAO,IAnCU;AAoCjBC,EAAAA,GAAG,EAAE,IApCY;AAqCjBC,EAAAA,GAAG,EAAE,IArCY;AAsCjBC,EAAAA,GAAG,EAAE,IAtCY;AAuCjBC,EAAAA,IAAI,EAAE,IAvCW;AAwCjBC,EAAAA,EAAE,EAAE,IAxCa;AAyCjBC,EAAAA,GAAG,EAAE,IAzCY;AA0CjBC,EAAAA,IAAI,EAAE,IA1CW;AA2CjBC,EAAAA,GAAG,EAAE,IA3CY;AA4CjBC,EAAAA,GAAG,EAAE,IA5CY;AA6CjBC,EAAAA,GAAG,EAAE,IA7CY;AA8CjBC,EAAAA,OAAO,EAAE,IA9CQ;AA+CjBtH,EAAAA,CAAC,EAAE,IA/Cc;AAgDjB,QAAM,IAhDW;AAiDjB,QAAM,IAjDW;AAkDjBuH,EAAAA,IAAI,EAAE,IAlDW;AAmDjBC,EAAAA,EAAE,EAAE,IAnDa;AAoDjBC,EAAAA,EAAE,EAAE,IApDa;AAqDjBC,EAAAA,GAAG,EAAE,IArDY;AAsDjBC,EAAAA,IAAI,EAAE,IAtDW;AAuDjBC,EAAAA,KAAK,EAAE,IAvDU;AAwDjB,SAAO,IAxDU;AAyDjBC,EAAAA,IAAI,EAAE,IAzDW;AA0DjBC,EAAAA,MAAM,EAAE,IA1DS;AA2DjBC,EAAAA,GAAG,EAAE,IA3DY;AA4DjBC,EAAAA,EAAE,EAAE,IA5Da;AA6DjBC,EAAAA,KAAK,EAAE,IA7DU;AA8DjBC,EAAAA,IAAI,EAAE,IA9DW;AA+DjBC,EAAAA,IAAI,EAAE,IA/DW;AAgEjBC,EAAAA,EAAE,EAAE,IAhEa;AAiEjBC,EAAAA,OAAO,EAAE,IAjEQ;AAkEjBC,EAAAA,EAAE,EAAE,IAlEa;AAmEjBC,EAAAA,GAAG,EAAE,IAnEY;AAoEjBC,EAAAA,GAAG,EAAE,IApEY;AAqEjBC,EAAAA,EAAE,EAAE,IArEa;AAsEjBC,EAAAA,GAAG,EAAE,IAtEY;AAuEjBC,EAAAA,KAAK,EAAE,IAvEU;AAwEjBC,EAAAA,EAAE,EAAE,IAxEa;AAyEjBC,EAAAA,IAAI,EAAE,IAzEW;AA0EjBC,EAAAA,EAAE,EAAE,IA1Ea;AA2EjBC,EAAAA,KAAK,EAAE,IA3EU;AA4EjBC,EAAAA,GAAG,EAAE,IA5EY;AA6EjBC,EAAAA,GAAG,EAAE,IA7EY;AA8EjBC,EAAAA,MAAM,EAAE,IA9ES;AA+EjBC,EAAAA,IAAI,EAAE,IA/EW;AAgFjBC,EAAAA,GAAG,EAAE,IAhFY;AAiFjBC,EAAAA,IAAI,EAAE,IAjFW;AAkFjBC,EAAAA,GAAG,EAAE,IAlFY;AAmFjBC,EAAAA,MAAM,EAAE,IAnFS;AAoFjBC,EAAAA,KAAK,EAAE,IApFU;AAqFjBC,EAAAA,EAAE,EAAE,IArFa;AAsFjBC,EAAAA,IAAI,EAAE,IAtFW;AAuFjBC,EAAAA,IAAI,EAAE,IAvFW;AAwFjBC,EAAAA,IAAI,EAAE,IAxFW;AAyFjBC,EAAAA,GAAG,EAAE,IAzFY;AA0FjBC,EAAAA,KAAK,EAAE,IA1FU;AA2FjBC,EAAAA,IAAI,EAAE,IA3FW;AA4FjBC,EAAAA,IAAI,EAAE,IA5FW;AA6FjBC,EAAAA,KAAK,EAAE,IA7FU;AA8FjBC,EAAAA,KAAK,EAAE,IA9FU;AA+FjBC,EAAAA,IAAI,EAAE,IA/FW;AAgGjB,UAAQ,IAhGS;AAiGjBC,EAAAA,GAAG,EAAE,IAjGY;AAkGjBC,EAAAA,EAAE,EAAE,IAlGa;AAmGjBC,EAAAA,GAAG,EAAE,IAnGY;AAoGjBC,EAAAA,IAAI,EAAE,IApGW;AAqGjBC,EAAAA,EAAE,EAAE,IArGa;AAsGjBC,EAAAA,KAAK,EAAE,IAtGU;AAuGjBC,EAAAA,GAAG,EAAE,IAvGY;AAwGjBC,EAAAA,EAAE,EAAE,IAxGa;AAyGjBC,EAAAA,IAAI,EAAE,IAzGW;AA0GjBC,EAAAA,IAAI,EAAE,IA1GW;AA2GjBC,EAAAA,IAAI,EAAE,IA3GW;AA4GjBC,EAAAA,KAAK,EAAE,IA5GU;AA6GjBC,EAAAA,KAAK,EAAE,IA7GU;AA8GjB,WAAS,IA9GQ;AA+GjBC,EAAAA,GAAG,EAAE,IA/GY;AAgHjBC,EAAAA,IAAI,EAAE,IAhHW;AAiHjBC,EAAAA,GAAG,EAAE,IAjHY;AAkHjBC,EAAAA,IAAI,EAAE,IAlHW;AAmHjB,UAAQ,IAnHS;AAoHjBC,EAAAA,KAAK,EAAE,IApHU;AAqHjBC,EAAAA,GAAG,EAAE,IArHY;AAsHjBC,EAAAA,GAAG,EAAE,IAtHY;AAuHjBC,EAAAA,IAAI,EAAE;AAvHW,CAAnB,C,CAwHG;;AAEH5G,YAAY,CAAC6G,WAAb,GAA2B,KAA3B;AACA7G,YAAY,CAAC8G,cAAb,GAA8B,KAA9B;AACA9G,YAAY,CAAC+G,aAAb,GAA6B,KAA7B;AACA/G,YAAY,CAACgH,oBAAb,GAAoC,KAApC;AACAhH,YAAY,CAACiH,cAAb,GAA8B,KAA9B;AACAjH,YAAY,CAACkH,QAAb,GAAwB,KAAxB;AACAlH,YAAY,CAACmH,OAAb,GAAuB,KAAvB;AAEA;AACA;AACA;AACA;AACA;;AAEA,IAAIC,kBAAkB,GAAG,aAAa,YAAY;AAChD;AACF;AACA;AACA;AACA;AACE,WAASA,kBAAT,CAA4BxH,kBAA5B,EAAgD;AAC9C,SAAKE,UAAL,GAAkBF,kBAAlB;AACD;AACD;AACF;AACA;;;AAGE,MAAI9E,MAAM,GAAGsM,kBAAkB,CAACrM,SAAhC;;AAEAD,EAAAA,MAAM,CAACyE,QAAP,GAAkB,SAASA,QAAT,CAAkB1D,IAAlB,EAAwB;AACxC,WAAO,KAAKiE,UAAL,CAAgBP,QAAhB,CAAyB1D,IAAzB,EAA+B4D,MAA/B,CAAsC,UAAUxE,KAAV,EAAiB;AAC5D,aAAO,CAAC+E,YAAY,CAAC/E,KAAD,CAApB;AACD,KAFM,CAAP;AAGD,GAJD;;AAMA,SAAOmM,kBAAP;AACD,CAvBqC,EAAtC;;AAyBA,SAASC,iBAAT,CAA2BC,MAA3B,EAAmCC,KAAnC,EAA0C;AACxC,OAAK,IAAInM,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGmM,KAAK,CAAClM,MAA1B,EAAkCD,CAAC,EAAnC,EAAuC;AACrC,QAAIoM,UAAU,GAAGD,KAAK,CAACnM,CAAD,CAAtB;AACAoM,IAAAA,UAAU,CAACC,UAAX,GAAwBD,UAAU,CAACC,UAAX,IAAyB,KAAjD;AACAD,IAAAA,UAAU,CAACE,YAAX,GAA0B,IAA1B;AACA,QAAI,WAAWF,UAAf,EAA2BA,UAAU,CAACG,QAAX,GAAsB,IAAtB;AAC3B/J,IAAAA,MAAM,CAACgK,cAAP,CAAsBN,MAAtB,EAA8BE,UAAU,CAACK,GAAzC,EAA8CL,UAA9C;AACD;AACF;;AAED,SAASM,YAAT,CAAsBC,WAAtB,EAAmCC,UAAnC,EAA+CC,WAA/C,EAA4D;AAC1D,MAAID,UAAJ,EAAgBX,iBAAiB,CAACU,WAAW,CAAChN,SAAb,EAAwBiN,UAAxB,CAAjB;AAChB,MAAIC,WAAJ,EAAiBZ,iBAAiB,CAACU,WAAD,EAAcE,WAAd,CAAjB;AACjB,SAAOF,WAAP;AACD;AAED;AACA;AACA;AACA;AACA;;;AACA,IAAIG,MAAM,GAAG,aAAa,YAAY;AACpC;AACF;AACA;;AAEE;AACF;AACA;AACA;AACA;AACE,WAASA,MAAT,CAAgB5L,YAAhB,EAA8B;AAC5B,QAAI,CAACA,YAAL,EAAmB;AACjB,YAAM6L,KAAK,CAAC,2DAAD,CAAX;AACD;;AAED,SAAK5L,aAAL,GAAqBD,YAArB,CAL4B,CAKO;;AAEnC,SAAK8L,cAAL,GAAsB,IAAI1M,mBAAJ,EAAtB;AACA,SAAK2M,YAAL,GAAoB,IAAIhM,gBAAJ,CAAqBC,YAArB,CAApB;AACA,SAAKgM,UAAL,GAAkB,IAAIvM,kBAAJ,EAAlB;AACA,SAAK+D,UAAL,GAAkB,IAAIR,eAAJ,EAAlB;AACA,SAAKiJ,UAAL,GAAkB,EAAlB;AACA,SAAKC,iBAAL,GAAyB,EAAzB;AACD;AACD;AACF;AACA;AACA;AACA;;;AAGE,MAAI1N,MAAM,GAAGoN,MAAM,CAACnN,SAApB;AAEA;AACF;AACA;AACA;;AACED,EAAAA,MAAM,CAAC2N,WAAP,GAAqB,SAASA,WAAT,CAAqB/J,QAArB,EAA+B;AAClD,SAAKgK,YAAL,CAAkB,CAAChK,QAAD,CAAlB;AACD;AACD;AACF;AACA;AACA;AANE;;AASA5D,EAAAA,MAAM,CAAC4N,YAAP,GAAsB,SAASA,YAAT,CAAsB5K,SAAtB,EAAiC;AACrD,SAAKyK,UAAL,GAAkB,KAAKA,UAAL,CAAgBI,MAAhB,CAAuB7K,SAAvB,CAAlB;AACA,SAAK8K,eAAL,CAAqB9K,SAArB,EAAgC,KAAK0K,iBAArC;AACD;AACD;AACF;AACA;AACA;AACA;AARE;;AAWA1N,EAAAA,MAAM,CAAC+N,QAAP,GAAkB,SAASA,QAAT,CAAkBC,KAAlB,EAAyB;AACzC,SAAKN,iBAAL,CAAuBhN,IAAvB,CAA4BsN,KAA5B;;AAEA,SAAKF,eAAL,CAAqB,KAAKL,UAA1B,EAAsC,CAACO,KAAD,CAAtC;AACD;AACD;AACF;AACA;AACA;AACA;AATE;;AAYAhO,EAAAA,MAAM,CAACuC,MAAP,GAAgB,SAASA,MAAT,CAAgB0L,KAAhB,EAAuB;AACrC,QAAIzL,MAAM,GAAG,KAAKwC,UAAL,CAAgBP,QAAhB,CAAyB,KAAK+I,UAAL,CAAgB1M,QAAhB,CAAyBmN,KAAzB,CAAzB,CAAb;;AAEA,WAAO,KAAKV,YAAL,CAAkBhL,MAAlB,CAAyBC,MAAzB,EAAiC,KAAKiL,UAAtC,CAAP;AACD;AACD;AACF;AACA;AACA;AACA;AATE;;AAYAzN,EAAAA,MAAM,CAAC8N,eAAP,GAAyB,SAASA,eAAT,CAAyB9K,SAAzB,EAAoC0K,iBAApC,EAAuD;AAC9E,SAAKQ,YAAL,GAAoB,IAApB;AACA,QAAIC,aAAa,GAAG,KAAKb,cAAzB;AACA,QAAIc,SAAS,GAAG,KAAKZ,UAArB;AACA,QAAIa,WAAW,GAAG,KAAKd,YAAvB;AACA,QAAIe,SAAS,GAAG,KAAKtJ,UAArB;AACA,QAAIxD,YAAY,GAAG,KAAKC,aAAxB;;AAEA,SAAK,IAAI8M,EAAE,GAAG,CAAT,EAAYC,YAAY,GAAGxL,SAAS,CAACzC,MAA1C,EAAkDgO,EAAE,GAAGC,YAAvD,EAAqED,EAAE,EAAvE,EAA2E;AACzE,UAAIzM,GAAG,GAAGkB,SAAS,CAACuL,EAAD,CAAnB;AACA,UAAI1M,GAAJ;;AAEA,UAAIL,YAAY,YAAYwC,KAA5B,EAAmC;AACjCnC,QAAAA,GAAG,GAAGV,mBAAmB,CAACW,GAAD,EAAMN,YAAN,CAAzB;AACD,OAFD,MAEO;AACLK,QAAAA,GAAG,GAAGC,GAAG,CAACN,YAAD,CAAT;AACD;;AAED,WAAK,IAAIiN,GAAG,GAAG,CAAV,EAAaC,mBAAmB,GAAGhB,iBAAiB,CAACnN,MAA1D,EAAkEkO,GAAG,GAAGC,mBAAxE,EAA6FD,GAAG,EAAhG,EAAoG;AAClG,YAAIE,UAAJ;AACA,YAAIC,eAAe,GAAGlB,iBAAiB,CAACe,GAAD,CAAvC;;AAEA,YAAIG,eAAe,YAAY5K,KAA/B,EAAsC;AACpC2K,UAAAA,UAAU,GAAGxN,mBAAmB,CAACW,GAAD,EAAM8M,eAAN,CAAhC;AACD,SAFD,MAEO;AACLD,UAAAA,UAAU,GAAG7M,GAAG,CAAC8M,eAAD,CAAhB;AACD;;AAED,YAAID,UAAU,IAAI,IAAd,IAAsB,OAAOA,UAAP,KAAsB,QAA5C,IAAwDA,UAAU,CAACvC,QAAvE,EAAiF;AAC/EuC,UAAAA,UAAU,GAAGA,UAAU,CAACvC,QAAX,EAAb;AACD;;AAED,YAAI,OAAOuC,UAAP,KAAsB,QAA1B,EAAoC;AAClC,cAAIE,WAAW,GAAGP,SAAS,CAAC7J,QAAV,CAAmB2J,SAAS,CAACtN,QAAV,CAAmB6N,UAAnB,CAAnB,CAAlB;;AAEA,eAAK,IAAIG,GAAG,GAAG,CAAV,EAAaC,cAAc,GAAGF,WAAW,CAACtO,MAA/C,EAAuDuO,GAAG,GAAGC,cAA7D,EAA6ED,GAAG,EAAhF,EAAoF;AAClF,gBAAIE,UAAU,GAAGH,WAAW,CAACC,GAAD,CAA5B;AACA,gBAAI1O,cAAc,GAAG+N,aAAa,CAACjO,WAAd,CAA0B8O,UAA1B,CAArB;;AAEA,iBAAK,IAAIC,GAAG,GAAG,CAAV,EAAaC,kBAAkB,GAAG9O,cAAc,CAACG,MAAtD,EAA8D0O,GAAG,GAAGC,kBAApE,EAAwFD,GAAG,EAA3F,EAA+F;AAC7F,kBAAIE,aAAa,GAAG/O,cAAc,CAAC6O,GAAD,CAAlC;AACAZ,cAAAA,WAAW,CAACzM,aAAZ,CAA0BuN,aAA1B,EAAyCtN,GAAzC,EAA8CC,GAA9C;AACD;AACF;AACF;AACF;AACF;AACF,GA/CD;;AAiDAkL,EAAAA,YAAY,CAACI,MAAD,EAAS,CAAC;AACpBL,IAAAA,GAAG,EAAE,eADe;AAEpBqC,IAAAA,GAAG,EAAE,SAASA,GAAT,CAAa9N,KAAb,EAAoB;AACvB,UAAI,KAAK4M,YAAT,EAAuB;AACrB,cAAMb,KAAK,CAAC,mDAAD,CAAX;AACD;;AAED,WAAKC,cAAL,GAAsBhM,KAAtB;AACD,KARmB;AASpB+N,IAAAA,GAAG,EAAE,SAASA,GAAT,GAAe;AAClB,aAAO,KAAK/B,cAAZ;AACD;AACD;AACJ;AACA;AACA;AACA;;AAhBwB,GAAD,EAkBlB;AACDP,IAAAA,GAAG,EAAE,WADJ;AAEDqC,IAAAA,GAAG,EAAE,SAASA,GAAT,CAAa9N,KAAb,EAAoB;AACvB,UAAI,KAAK4M,YAAT,EAAuB;AACrB,cAAMb,KAAK,CAAC,+CAAD,CAAX;AACD;;AAED,WAAKG,UAAL,GAAkBlM,KAAlB;AACD,KARA;AASD+N,IAAAA,GAAG,EAAE,SAASA,GAAT,GAAe;AAClB,aAAO,KAAK7B,UAAZ;AACD;AACD;AACJ;AACA;AACA;AACA;;AAhBK,GAlBkB,EAoClB;AACDT,IAAAA,GAAG,EAAE,aADJ;AAEDqC,IAAAA,GAAG,EAAE,SAASA,GAAT,CAAa9N,KAAb,EAAoB;AACvB,UAAI,KAAK4M,YAAT,EAAuB;AACrB,cAAMb,KAAK,CAAC,iDAAD,CAAX;AACD;;AAED,WAAKE,YAAL,GAAoBjM,KAApB;AACD,KARA;AASD+N,IAAAA,GAAG,EAAE,SAASA,GAAT,GAAe;AAClB,aAAO,KAAK9B,YAAZ;AACD;AACD;AACJ;AACA;AACA;AACA;;AAhBK,GApCkB,EAsDlB;AACDR,IAAAA,GAAG,EAAE,WADJ;AAEDqC,IAAAA,GAAG,EAAE,SAASA,GAAT,CAAa9N,KAAb,EAAoB;AACvB,UAAI,KAAK4M,YAAT,EAAuB;AACrB,cAAMb,KAAK,CAAC,+CAAD,CAAX;AACD;;AAED,WAAKrI,UAAL,GAAkB1D,KAAlB;AACD,KARA;AASD+N,IAAAA,GAAG,EAAE,SAASA,GAAT,GAAe;AAClB,aAAO,KAAKrK,UAAZ;AACD;AAXA,GAtDkB,CAAT,CAAZ;;AAoEA,SAAOoI,MAAP;AACD,CAvMyB,EAA1B;AAyMA;AACA;AACA;AACA;AACA;AACA;;;AACA,IAAIkC,gBAAgB,GAAG,aAAa,YAAY;AAC9C;AACF;AACA;AACA;AACA;AACA;AACA;AACE,WAASA,gBAAT,CAA0BC,iBAA1B,EAA6CC,aAA7C,EAA4DC,kBAA5D,EAAgF;AAC9E,SAAKnC,cAAL,GAAsBiC,iBAAiB,IAAI,IAAI3O,mBAAJ,EAA3C;AACA,SAAK4M,UAAL,GAAkBgC,aAAa,IAAI,IAAIvO,kBAAJ,EAAnC;AACA,SAAKyO,eAAL,GAAuBD,kBAAkB,IAAI,MAA7C;AACD;AACD;AACF;AACA;AACA;AACA;AACA;AACA;;;AAGE,MAAIzP,MAAM,GAAGsP,gBAAgB,CAACrP,SAA9B;;AAEAD,EAAAA,MAAM,CAAC2P,SAAP,GAAmB,SAASA,SAAT,CAAmB5O,IAAnB,EAAyByB,MAAzB,EAAiC;AAClD,QAAIoN,UAAU,GAAG,KAAKC,SAAL,CAAe,EAAf,EAAmBtP,MAApC;;AAEA,QAAIuP,eAAe,GAAGhN,MAAM,CAACiN,MAAP,CAAc,IAAd,CAAtB,CAHkD,CAGP;;AAE3C,SAAK,IAAIzP,CAAC,GAAG,CAAR,EAAWqC,SAAS,GAAGH,MAAM,CAACjC,MAAnC,EAA2CD,CAAC,GAAGqC,SAA/C,EAA0DrC,CAAC,EAA3D,EAA+D;AAC7D,UAAIH,KAAK,GAAG,KAAKqN,UAAL,CAAgB1M,QAAhB,CAAyB0B,MAAM,CAAClC,CAAD,CAA/B,CAAZ;;AAEA,UAAIF,cAAc,GAAG,KAAKkN,cAAL,CAAoBpN,WAApB,CAAgCC,KAAhC,CAArB;;AAEA,WAAK,IAAIK,CAAC,GAAG,CAAR,EAAWwP,iBAAiB,GAAG5P,cAAc,CAACG,MAAnD,EAA2DC,CAAC,GAAGwP,iBAA/D,EAAkFxP,CAAC,EAAnF,EAAuF;AACrF,YAAI2O,aAAa,GAAG/O,cAAc,CAACI,CAAD,CAAlC;;AAEA,YAAI,CAACsP,eAAe,CAACX,aAAD,CAApB,EAAqC;AACnCW,UAAAA,eAAe,CAACX,aAAD,CAAf,GAAiC,CAAChP,KAAD,CAAjC;AACD,SAFD,MAEO;AACL2P,UAAAA,eAAe,CAACX,aAAD,CAAf,CAA+BzO,IAA/B,CAAoCP,KAApC;AACD;AACF;AACF,KAnBiD,CAmBhD;;;AAGF,QAAI8P,iBAAiB,GAAG,EAAxB;AACA,QAAIC,oBAAoB,GAAG,EAA3B;AACA,QAAIC,qBAAqB,GAAG,CAA5B,CAxBkD,CAwBnB;;AAE/B,SAAK,IAAI7P,CAAC,GAAG,CAAR,EAAW8P,UAAU,GAAGrP,IAAI,CAACR,MAAlC,EAA0CD,CAAC,GAAG8P,UAA9C,EAA0D9P,CAAC,EAA3D,EAA+D;AAC7D,UAAI+P,SAAS,GAAGtP,IAAI,CAACN,MAAL,CAAYH,CAAZ,CAAhB;;AAEA,UAAI+P,SAAS,KAAK,GAAlB,EAAuB;AACrBJ,QAAAA,iBAAiB,GAAG,EAApB;AACAC,QAAAA,oBAAoB,GAAG,EAAvB;AACAC,QAAAA,qBAAqB,GAAG7P,CAAC,GAAG,CAA5B;AACD,OAJD,MAIO;AACL2P,QAAAA,iBAAiB,IAAII,SAArB;AACAH,QAAAA,oBAAoB,IAAI,KAAK1C,UAAL,CAAgB1M,QAAhB,CAAyBuP,SAAzB,CAAxB;AACD;;AAED,UAAIP,eAAe,CAACI,oBAAD,CAAf,IAAyCJ,eAAe,CAACI,oBAAD,CAAf,CAAsCI,OAAtC,CAA8CJ,oBAA9C,KAAuE,CAApH,EAAuH;AACrHD,QAAAA,iBAAiB,GAAG,KAAKJ,SAAL,CAAeI,iBAAf,CAApB;AACAlP,QAAAA,IAAI,GAAGA,IAAI,CAACwP,SAAL,CAAe,CAAf,EAAkBJ,qBAAlB,IAA2CF,iBAA3C,GAA+DlP,IAAI,CAACwP,SAAL,CAAejQ,CAAC,GAAG,CAAnB,CAAtE;AACAA,QAAAA,CAAC,IAAIsP,UAAL;AACAQ,QAAAA,UAAU,IAAIR,UAAd;AACD;AACF;;AAED,WAAO7O,IAAP;AACD;AACD;AACF;AACA;AACA;AACA;AApDE;;AAuDAf,EAAAA,MAAM,CAAC6P,SAAP,GAAmB,SAASA,SAAT,CAAmB9O,IAAnB,EAAyB;AAC1C,QAAIyP,OAAO,GAAG,KAAKd,eAAnB;AACA,WAAO,MAAMc,OAAN,GAAgB,GAAhB,GAAsBzP,IAAtB,GAA6B,IAA7B,GAAoCyP,OAApC,GAA8C,GAArD;AACD,GAHD;;AAKA,SAAOlB,gBAAP;AACD,CArFmC,EAApC;;AAuFA,SAASvP,0BAAT,EAAqCc,sBAArC,EAA6DF,sBAA7D,EAAqFM,kBAArF,EAAyGL,mBAAzG,EAA8HwM,MAA9H,EAAsI5I,eAAtI,EAAuJI,iBAAvJ,EAA0KM,YAA1K,EAAwLoH,kBAAxL,EAA4M/K,gBAA5M,EAA8N+N,gBAA9N,EAAgPpL,oBAAhP","sourcesContent":["/**\n * Indexes for all substring searches (e.g. the term \"cat\" is indexed as \"c\", \"ca\", \"cat\", \"a\", \"at\", and \"t\").\n */\nvar AllSubstringsIndexStrategy = /*#__PURE__*/function () {\n  function AllSubstringsIndexStrategy() {}\n\n  var _proto = AllSubstringsIndexStrategy.prototype;\n\n  /**\n   * @inheritDocs\n   */\n  _proto.expandToken = function expandToken(token) {\n    var expandedTokens = [];\n    var string;\n\n    for (var i = 0, length = token.length; i < length; ++i) {\n      string = '';\n\n      for (var j = i; j < length; ++j) {\n        string += token.charAt(j);\n        expandedTokens.push(string);\n      }\n    }\n\n    return expandedTokens;\n  };\n\n  return AllSubstringsIndexStrategy;\n}();\n\n/**\n * Indexes for exact word matches.\n */\nvar ExactWordIndexStrategy = /*#__PURE__*/function () {\n  function ExactWordIndexStrategy() {}\n\n  var _proto = ExactWordIndexStrategy.prototype;\n\n  /**\n   * @inheritDocs\n   */\n  _proto.expandToken = function expandToken(token) {\n    return token ? [token] : [];\n  };\n\n  return ExactWordIndexStrategy;\n}();\n\n/**\n * Indexes for prefix searches (e.g. the term \"cat\" is indexed as \"c\", \"ca\", and \"cat\" allowing prefix search lookups).\n */\nvar PrefixIndexStrategy = /*#__PURE__*/function () {\n  function PrefixIndexStrategy() {}\n\n  var _proto = PrefixIndexStrategy.prototype;\n\n  /**\n   * @inheritDocs\n   */\n  _proto.expandToken = function expandToken(token) {\n    var expandedTokens = [];\n    var string = '';\n\n    for (var i = 0, length = token.length; i < length; ++i) {\n      string += token.charAt(i);\n      expandedTokens.push(string);\n    }\n\n    return expandedTokens;\n  };\n\n  return PrefixIndexStrategy;\n}();\n\n/**\n * Enforces case-sensitive text matches.\n */\nvar CaseSensitiveSanitizer = /*#__PURE__*/function () {\n  function CaseSensitiveSanitizer() {}\n\n  var _proto = CaseSensitiveSanitizer.prototype;\n\n  /**\n   * @inheritDocs\n   */\n  _proto.sanitize = function sanitize(text) {\n    return text ? text.trim() : '';\n  };\n\n  return CaseSensitiveSanitizer;\n}();\n\n/**\n * Sanitizes text by converting to a locale-friendly lower-case version and triming leading and trailing whitespace.\n */\nvar LowerCaseSanitizer = /*#__PURE__*/function () {\n  function LowerCaseSanitizer() {}\n\n  var _proto = LowerCaseSanitizer.prototype;\n\n  /**\n   * @inheritDocs\n   */\n  _proto.sanitize = function sanitize(text) {\n    return text ? text.toLocaleLowerCase().trim() : '';\n  };\n\n  return LowerCaseSanitizer;\n}();\n\n/**\n * Find and return a nested object value.\n *\n * @param object to crawl\n * @param path Property path\n * @returns {any}\n */\nfunction getNestedFieldValue(object, path) {\n  path = path || [];\n  object = object || {};\n  var value = object; // walk down the property path\n\n  for (var i = 0; i < path.length; i++) {\n    value = value[path[i]];\n\n    if (value == null) {\n      return null;\n    }\n  }\n\n  return value;\n}\n\n/**\n * Search index capable of returning results matching a set of tokens and ranked according to TF-IDF.\n */\nvar TfIdfSearchIndex = /*#__PURE__*/function () {\n  function TfIdfSearchIndex(uidFieldName) {\n    this._uidFieldName = uidFieldName;\n    this._tokenToIdfCache = {};\n    this._tokenMap = {};\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = TfIdfSearchIndex.prototype;\n\n  _proto.indexDocument = function indexDocument(token, uid, doc) {\n    this._tokenToIdfCache = {}; // New index invalidates previous IDF caches\n\n    var tokenMap = this._tokenMap;\n    var tokenDatum;\n\n    if (typeof tokenMap[token] !== 'object') {\n      tokenMap[token] = tokenDatum = {\n        $numDocumentOccurrences: 0,\n        $totalNumOccurrences: 1,\n        $uidMap: {}\n      };\n    } else {\n      tokenDatum = tokenMap[token];\n      tokenDatum.$totalNumOccurrences++;\n    }\n\n    var uidMap = tokenDatum.$uidMap;\n\n    if (typeof uidMap[uid] !== 'object') {\n      tokenDatum.$numDocumentOccurrences++;\n      uidMap[uid] = {\n        $document: doc,\n        $numTokenOccurrences: 1\n      };\n    } else {\n      uidMap[uid].$numTokenOccurrences++;\n    }\n  }\n  /**\n   * @inheritDocs\n   */\n  ;\n\n  _proto.search = function search(tokens, corpus) {\n    var uidToDocumentMap = {};\n\n    for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n      var token = tokens[i];\n      var tokenMetadata = this._tokenMap[token]; // Short circuit if no matches were found for any given token.\n\n      if (!tokenMetadata) {\n        return [];\n      }\n\n      if (i === 0) {\n        var keys = Object.keys(tokenMetadata.$uidMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n          uidToDocumentMap[uid] = tokenMetadata.$uidMap[uid].$document;\n        }\n      } else {\n        var keys = Object.keys(uidToDocumentMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n\n          if (typeof tokenMetadata.$uidMap[uid] !== 'object') {\n            delete uidToDocumentMap[uid];\n          }\n        }\n      }\n    }\n\n    var documents = [];\n\n    for (var uid in uidToDocumentMap) {\n      documents.push(uidToDocumentMap[uid]);\n    }\n\n    var calculateTfIdf = this._createCalculateTfIdf(); // Return documents sorted by TF-IDF\n\n\n    return documents.sort(function (documentA, documentB) {\n      return calculateTfIdf(tokens, documentB, corpus) - calculateTfIdf(tokens, documentA, corpus);\n    });\n  };\n\n  _proto._createCalculateIdf = function _createCalculateIdf() {\n    var tokenMap = this._tokenMap;\n    var tokenToIdfCache = this._tokenToIdfCache;\n    return function calculateIdf(token, documents) {\n      if (!tokenToIdfCache[token]) {\n        var numDocumentsWithToken = typeof tokenMap[token] !== 'undefined' ? tokenMap[token].$numDocumentOccurrences : 0;\n        tokenToIdfCache[token] = 1 + Math.log(documents.length / (1 + numDocumentsWithToken));\n      }\n\n      return tokenToIdfCache[token];\n    };\n  };\n\n  _proto._createCalculateTfIdf = function _createCalculateTfIdf() {\n    var tokenMap = this._tokenMap;\n    var uidFieldName = this._uidFieldName;\n\n    var calculateIdf = this._createCalculateIdf();\n\n    return function calculateTfIdf(tokens, document, documents) {\n      var score = 0;\n\n      for (var i = 0, numTokens = tokens.length; i < numTokens; ++i) {\n        var token = tokens[i];\n        var inverseDocumentFrequency = calculateIdf(token, documents);\n\n        if (inverseDocumentFrequency === Infinity) {\n          inverseDocumentFrequency = 0;\n        }\n\n        var uid;\n\n        if (uidFieldName instanceof Array) {\n          uid = document && getNestedFieldValue(document, uidFieldName);\n        } else {\n          uid = document && document[uidFieldName];\n        }\n\n        var termFrequency = typeof tokenMap[token] !== 'undefined' && typeof tokenMap[token].$uidMap[uid] !== 'undefined' ? tokenMap[token].$uidMap[uid].$numTokenOccurrences : 0;\n        score += termFrequency * inverseDocumentFrequency;\n      }\n\n      return score;\n    };\n  };\n\n  return TfIdfSearchIndex;\n}();\n\n/**\n * Search index capable of returning results matching a set of tokens but without any meaningful rank or order.\n */\nvar UnorderedSearchIndex = /*#__PURE__*/function () {\n  function UnorderedSearchIndex() {\n    this._tokenToUidToDocumentMap = {};\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = UnorderedSearchIndex.prototype;\n\n  _proto.indexDocument = function indexDocument(token, uid, doc) {\n    if (typeof this._tokenToUidToDocumentMap[token] !== 'object') {\n      this._tokenToUidToDocumentMap[token] = {};\n    }\n\n    this._tokenToUidToDocumentMap[token][uid] = doc;\n  }\n  /**\n   * @inheritDocs\n   */\n  ;\n\n  _proto.search = function search(tokens, corpus) {\n    var intersectingDocumentMap = {};\n    var tokenToUidToDocumentMap = this._tokenToUidToDocumentMap;\n\n    for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n      var token = tokens[i];\n      var documentMap = tokenToUidToDocumentMap[token]; // Short circuit if no matches were found for any given token.\n\n      if (!documentMap) {\n        return [];\n      }\n\n      if (i === 0) {\n        var keys = Object.keys(documentMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n          intersectingDocumentMap[uid] = documentMap[uid];\n        }\n      } else {\n        var keys = Object.keys(intersectingDocumentMap);\n\n        for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n          var uid = keys[j];\n\n          if (typeof documentMap[uid] !== 'object') {\n            delete intersectingDocumentMap[uid];\n          }\n        }\n      }\n    }\n\n    var keys = Object.keys(intersectingDocumentMap);\n    var documents = [];\n\n    for (var i = 0, numKeys = keys.length; i < numKeys; i++) {\n      var uid = keys[i];\n      documents.push(intersectingDocumentMap[uid]);\n    }\n\n    return documents;\n  };\n\n  return UnorderedSearchIndex;\n}();\n\nvar REGEX = /[^a-zа-яё0-9\\-']+/i;\n/**\n * Simple tokenizer that splits strings on whitespace characters and returns an array of all non-empty substrings.\n */\n\nvar SimpleTokenizer = /*#__PURE__*/function () {\n  function SimpleTokenizer() {}\n\n  var _proto = SimpleTokenizer.prototype;\n\n  /**\n   * @inheritDocs\n   */\n  _proto.tokenize = function tokenize(text) {\n    return text.split(REGEX).filter(function (text) {\n      return text;\n    } // Filter empty tokens\n    );\n  };\n\n  return SimpleTokenizer;\n}();\n\n/**\n * Stemming is the process of reducing search tokens to their root (or stem) so that searches for different forms of a\n * word will match. For example \"search\", \"searching\" and \"searched\" are all reduced to the stem \"search\".\n *\n * <p>This stemming tokenizer converts tokens (words) to their stem forms before returning them. It requires an\n * external stemming function to be provided; for this purpose I recommend the NPM 'porter-stemmer' library.\n *\n * <p>For more information see http : //tartarus.org/~martin/PorterStemmer/\n */\nvar StemmingTokenizer = /*#__PURE__*/function () {\n  /**\n   * Constructor.\n   *\n   * @param stemmingFunction Function capable of accepting a word and returning its stem.\n   * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n   */\n  function StemmingTokenizer(stemmingFunction, decoratedTokenizer) {\n    this._stemmingFunction = stemmingFunction;\n    this._tokenizer = decoratedTokenizer;\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = StemmingTokenizer.prototype;\n\n  _proto.tokenize = function tokenize(text) {\n    return this._tokenizer.tokenize(text).map(this._stemmingFunction);\n  };\n\n  return StemmingTokenizer;\n}();\n\n/**\n * Stop words list copied from Lunr JS.\n */\nvar StopWordsMap = {\n  a: true,\n  able: true,\n  about: true,\n  across: true,\n  after: true,\n  all: true,\n  almost: true,\n  also: true,\n  am: true,\n  among: true,\n  an: true,\n  and: true,\n  any: true,\n  are: true,\n  as: true,\n  at: true,\n  be: true,\n  because: true,\n  been: true,\n  but: true,\n  by: true,\n  can: true,\n  cannot: true,\n  could: true,\n  dear: true,\n  did: true,\n  'do': true,\n  does: true,\n  either: true,\n  'else': true,\n  ever: true,\n  every: true,\n  'for': true,\n  from: true,\n  'get': true,\n  got: true,\n  had: true,\n  has: true,\n  have: true,\n  he: true,\n  her: true,\n  hers: true,\n  him: true,\n  his: true,\n  how: true,\n  however: true,\n  i: true,\n  'if': true,\n  'in': true,\n  into: true,\n  is: true,\n  it: true,\n  its: true,\n  just: true,\n  least: true,\n  \"let\": true,\n  like: true,\n  likely: true,\n  may: true,\n  me: true,\n  might: true,\n  most: true,\n  must: true,\n  my: true,\n  neither: true,\n  no: true,\n  nor: true,\n  not: true,\n  of: true,\n  off: true,\n  often: true,\n  on: true,\n  only: true,\n  or: true,\n  other: true,\n  our: true,\n  own: true,\n  rather: true,\n  said: true,\n  say: true,\n  says: true,\n  she: true,\n  should: true,\n  since: true,\n  so: true,\n  some: true,\n  than: true,\n  that: true,\n  the: true,\n  their: true,\n  them: true,\n  then: true,\n  there: true,\n  these: true,\n  they: true,\n  'this': true,\n  tis: true,\n  to: true,\n  too: true,\n  twas: true,\n  us: true,\n  wants: true,\n  was: true,\n  we: true,\n  were: true,\n  what: true,\n  when: true,\n  where: true,\n  which: true,\n  'while': true,\n  who: true,\n  whom: true,\n  why: true,\n  will: true,\n  'with': true,\n  would: true,\n  yet: true,\n  you: true,\n  your: true\n}; // Prevent false positives for inherited properties\n\nStopWordsMap.constructor = false;\nStopWordsMap.hasOwnProperty = false;\nStopWordsMap.isPrototypeOf = false;\nStopWordsMap.propertyIsEnumerable = false;\nStopWordsMap.toLocaleString = false;\nStopWordsMap.toString = false;\nStopWordsMap.valueOf = false;\n\n/**\n * Stop words are very common (e.g. \"a\", \"and\", \"the\") and are often not semantically meaningful in the context of a\n * search. This tokenizer removes stop words from a set of tokens before passing the remaining tokens along for\n * indexing or searching purposes.\n */\n\nvar StopWordsTokenizer = /*#__PURE__*/function () {\n  /**\n   * Constructor.\n   *\n   * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n   */\n  function StopWordsTokenizer(decoratedTokenizer) {\n    this._tokenizer = decoratedTokenizer;\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  var _proto = StopWordsTokenizer.prototype;\n\n  _proto.tokenize = function tokenize(text) {\n    return this._tokenizer.tokenize(text).filter(function (token) {\n      return !StopWordsMap[token];\n    });\n  };\n\n  return StopWordsTokenizer;\n}();\n\nfunction _defineProperties(target, props) {\n  for (var i = 0; i < props.length; i++) {\n    var descriptor = props[i];\n    descriptor.enumerable = descriptor.enumerable || false;\n    descriptor.configurable = true;\n    if (\"value\" in descriptor) descriptor.writable = true;\n    Object.defineProperty(target, descriptor.key, descriptor);\n  }\n}\n\nfunction _createClass(Constructor, protoProps, staticProps) {\n  if (protoProps) _defineProperties(Constructor.prototype, protoProps);\n  if (staticProps) _defineProperties(Constructor, staticProps);\n  return Constructor;\n}\n\n/**\n * Simple client-side searching within a set of documents.\n *\n * <p>Documents can be searched by any number of fields. Indexing and search strategies are highly customizable.\n */\nvar Search = /*#__PURE__*/function () {\n  /**\n   * Array containing either a property name or a path (list of property names) to a nested value\n   */\n\n  /**\n   * Constructor.\n   * @param uidFieldName Field containing values that uniquely identify search documents; this field's values are used\n   *                     to ensure that a search result set does not contain duplicate objects.\n   */\n  function Search(uidFieldName) {\n    if (!uidFieldName) {\n      throw Error('js-search requires a uid field name constructor parameter');\n    }\n\n    this._uidFieldName = uidFieldName; // Set default/recommended strategies\n\n    this._indexStrategy = new PrefixIndexStrategy();\n    this._searchIndex = new TfIdfSearchIndex(uidFieldName);\n    this._sanitizer = new LowerCaseSanitizer();\n    this._tokenizer = new SimpleTokenizer();\n    this._documents = [];\n    this._searchableFields = [];\n  }\n  /**\n   * Override the default index strategy.\n   * @param value Custom index strategy\n   * @throws Error if documents have already been indexed by this search instance\n   */\n\n\n  var _proto = Search.prototype;\n\n  /**\n   * Add a searchable document to the index. Document will automatically be indexed for search.\n   * @param document\n   */\n  _proto.addDocument = function addDocument(document) {\n    this.addDocuments([document]);\n  }\n  /**\n   * Adds searchable documents to the index. Documents will automatically be indexed for search.\n   * @param document\n   */\n  ;\n\n  _proto.addDocuments = function addDocuments(documents) {\n    this._documents = this._documents.concat(documents);\n    this.indexDocuments_(documents, this._searchableFields);\n  }\n  /**\n   * Add a new searchable field to the index. Existing documents will automatically be indexed using this new field.\n   *\n   * @param field Searchable field or field path. Pass a string to index a top-level field and an array of strings for nested fields.\n   */\n  ;\n\n  _proto.addIndex = function addIndex(field) {\n    this._searchableFields.push(field);\n\n    this.indexDocuments_(this._documents, [field]);\n  }\n  /**\n   * Search all documents for ones matching the specified query text.\n   * @param query\n   * @returns {Array<Object>}\n   */\n  ;\n\n  _proto.search = function search(query) {\n    var tokens = this._tokenizer.tokenize(this._sanitizer.sanitize(query));\n\n    return this._searchIndex.search(tokens, this._documents);\n  }\n  /**\n   * @param documents\n   * @param _searchableFields Array containing property names and paths (lists of property names) to nested values\n   * @private\n   */\n  ;\n\n  _proto.indexDocuments_ = function indexDocuments_(documents, _searchableFields) {\n    this._initialized = true;\n    var indexStrategy = this._indexStrategy;\n    var sanitizer = this._sanitizer;\n    var searchIndex = this._searchIndex;\n    var tokenizer = this._tokenizer;\n    var uidFieldName = this._uidFieldName;\n\n    for (var di = 0, numDocuments = documents.length; di < numDocuments; di++) {\n      var doc = documents[di];\n      var uid;\n\n      if (uidFieldName instanceof Array) {\n        uid = getNestedFieldValue(doc, uidFieldName);\n      } else {\n        uid = doc[uidFieldName];\n      }\n\n      for (var sfi = 0, numSearchableFields = _searchableFields.length; sfi < numSearchableFields; sfi++) {\n        var fieldValue;\n        var searchableField = _searchableFields[sfi];\n\n        if (searchableField instanceof Array) {\n          fieldValue = getNestedFieldValue(doc, searchableField);\n        } else {\n          fieldValue = doc[searchableField];\n        }\n\n        if (fieldValue != null && typeof fieldValue !== 'string' && fieldValue.toString) {\n          fieldValue = fieldValue.toString();\n        }\n\n        if (typeof fieldValue === 'string') {\n          var fieldTokens = tokenizer.tokenize(sanitizer.sanitize(fieldValue));\n\n          for (var fti = 0, numFieldValues = fieldTokens.length; fti < numFieldValues; fti++) {\n            var fieldToken = fieldTokens[fti];\n            var expandedTokens = indexStrategy.expandToken(fieldToken);\n\n            for (var eti = 0, nummExpandedTokens = expandedTokens.length; eti < nummExpandedTokens; eti++) {\n              var expandedToken = expandedTokens[eti];\n              searchIndex.indexDocument(expandedToken, uid, doc);\n            }\n          }\n        }\n      }\n    }\n  };\n\n  _createClass(Search, [{\n    key: \"indexStrategy\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('IIndexStrategy cannot be set after initialization');\n      }\n\n      this._indexStrategy = value;\n    },\n    get: function get() {\n      return this._indexStrategy;\n    }\n    /**\n     * Override the default text sanitizing strategy.\n     * @param value Custom text sanitizing strategy\n     * @throws Error if documents have already been indexed by this search instance\n     */\n\n  }, {\n    key: \"sanitizer\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('ISanitizer cannot be set after initialization');\n      }\n\n      this._sanitizer = value;\n    },\n    get: function get() {\n      return this._sanitizer;\n    }\n    /**\n     * Override the default search index strategy.\n     * @param value Custom search index strategy\n     * @throws Error if documents have already been indexed\n     */\n\n  }, {\n    key: \"searchIndex\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('ISearchIndex cannot be set after initialization');\n      }\n\n      this._searchIndex = value;\n    },\n    get: function get() {\n      return this._searchIndex;\n    }\n    /**\n     * Override the default text tokenizing strategy.\n     * @param value Custom text tokenizing strategy\n     * @throws Error if documents have already been indexed by this search instance\n     */\n\n  }, {\n    key: \"tokenizer\",\n    set: function set(value) {\n      if (this._initialized) {\n        throw Error('ITokenizer cannot be set after initialization');\n      }\n\n      this._tokenizer = value;\n    },\n    get: function get() {\n      return this._tokenizer;\n    }\n  }]);\n\n  return Search;\n}();\n\n/**\n * This utility highlights the occurrences of tokens within a string of text. It can be used to give visual indicators\n * of match criteria within searchable fields.\n *\n * <p>For performance purposes this highlighter only works with full-word or prefix token indexes.\n */\nvar TokenHighlighter = /*#__PURE__*/function () {\n  /**\n   * Constructor.\n   *\n   * @param opt_indexStrategy Index strategy used by Search\n   * @param opt_sanitizer Sanitizer used by Search\n   * @param opt_wrapperTagName Optional wrapper tag name; defaults to 'mark' (e.g. <mark>)\n   */\n  function TokenHighlighter(opt_indexStrategy, opt_sanitizer, opt_wrapperTagName) {\n    this._indexStrategy = opt_indexStrategy || new PrefixIndexStrategy();\n    this._sanitizer = opt_sanitizer || new LowerCaseSanitizer();\n    this._wrapperTagName = opt_wrapperTagName || 'mark';\n  }\n  /**\n   * Highlights token occurrences within a string by wrapping them with a DOM element.\n   *\n   * @param text e.g. \"john wayne\"\n   * @param tokens e.g. [\"wa\"]\n   * @returns {string} e.g. \"john <mark>wa</mark>yne\"\n   */\n\n\n  var _proto = TokenHighlighter.prototype;\n\n  _proto.highlight = function highlight(text, tokens) {\n    var tagsLength = this._wrapText('').length;\n\n    var tokenDictionary = Object.create(null); // Create a token map for easier lookup below.\n\n    for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n      var token = this._sanitizer.sanitize(tokens[i]);\n\n      var expandedTokens = this._indexStrategy.expandToken(token);\n\n      for (var j = 0, numExpandedTokens = expandedTokens.length; j < numExpandedTokens; j++) {\n        var expandedToken = expandedTokens[j];\n\n        if (!tokenDictionary[expandedToken]) {\n          tokenDictionary[expandedToken] = [token];\n        } else {\n          tokenDictionary[expandedToken].push(token);\n        }\n      }\n    } // Track actualCurrentWord and sanitizedCurrentWord separately in case we encounter nested tags.\n\n\n    var actualCurrentWord = '';\n    var sanitizedCurrentWord = '';\n    var currentWordStartIndex = 0; // Note this assumes either prefix or full word matching.\n\n    for (var i = 0, textLength = text.length; i < textLength; i++) {\n      var character = text.charAt(i);\n\n      if (character === ' ') {\n        actualCurrentWord = '';\n        sanitizedCurrentWord = '';\n        currentWordStartIndex = i + 1;\n      } else {\n        actualCurrentWord += character;\n        sanitizedCurrentWord += this._sanitizer.sanitize(character);\n      }\n\n      if (tokenDictionary[sanitizedCurrentWord] && tokenDictionary[sanitizedCurrentWord].indexOf(sanitizedCurrentWord) >= 0) {\n        actualCurrentWord = this._wrapText(actualCurrentWord);\n        text = text.substring(0, currentWordStartIndex) + actualCurrentWord + text.substring(i + 1);\n        i += tagsLength;\n        textLength += tagsLength;\n      }\n    }\n\n    return text;\n  }\n  /**\n   * @param text to wrap\n   * @returns Text wrapped by wrapper tag (e.g. \"foo\" becomes \"<mark>foo</mark>\")\n   * @private\n   */\n  ;\n\n  _proto._wrapText = function _wrapText(text) {\n    var tagName = this._wrapperTagName;\n    return \"<\" + tagName + \">\" + text + \"</\" + tagName + \">\";\n  };\n\n  return TokenHighlighter;\n}();\n\nexport { AllSubstringsIndexStrategy, CaseSensitiveSanitizer, ExactWordIndexStrategy, LowerCaseSanitizer, PrefixIndexStrategy, Search, SimpleTokenizer, StemmingTokenizer, StopWordsMap, StopWordsTokenizer, TfIdfSearchIndex, TokenHighlighter, UnorderedSearchIndex };\n"]},"metadata":{},"sourceType":"module"}