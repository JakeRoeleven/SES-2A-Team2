{"ast":null,"code":"(function (global, factory) {\n  typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports) : typeof define === 'function' && define.amd ? define(['exports'], factory) : (global = global || self, factory(global.JsSearch = {}));\n})(this, function (exports) {\n  'use strict';\n  /**\n   * Indexes for all substring searches (e.g. the term \"cat\" is indexed as \"c\", \"ca\", \"cat\", \"a\", \"at\", and \"t\").\n   */\n\n  var AllSubstringsIndexStrategy = /*#__PURE__*/function () {\n    function AllSubstringsIndexStrategy() {}\n\n    var _proto = AllSubstringsIndexStrategy.prototype;\n    /**\n     * @inheritDocs\n     */\n\n    _proto.expandToken = function expandToken(token) {\n      var expandedTokens = [];\n      var string;\n\n      for (var i = 0, length = token.length; i < length; ++i) {\n        string = '';\n\n        for (var j = i; j < length; ++j) {\n          string += token.charAt(j);\n          expandedTokens.push(string);\n        }\n      }\n\n      return expandedTokens;\n    };\n\n    return AllSubstringsIndexStrategy;\n  }();\n  /**\n   * Indexes for exact word matches.\n   */\n\n\n  var ExactWordIndexStrategy = /*#__PURE__*/function () {\n    function ExactWordIndexStrategy() {}\n\n    var _proto = ExactWordIndexStrategy.prototype;\n    /**\n     * @inheritDocs\n     */\n\n    _proto.expandToken = function expandToken(token) {\n      return token ? [token] : [];\n    };\n\n    return ExactWordIndexStrategy;\n  }();\n  /**\n   * Indexes for prefix searches (e.g. the term \"cat\" is indexed as \"c\", \"ca\", and \"cat\" allowing prefix search lookups).\n   */\n\n\n  var PrefixIndexStrategy = /*#__PURE__*/function () {\n    function PrefixIndexStrategy() {}\n\n    var _proto = PrefixIndexStrategy.prototype;\n    /**\n     * @inheritDocs\n     */\n\n    _proto.expandToken = function expandToken(token) {\n      var expandedTokens = [];\n      var string = '';\n\n      for (var i = 0, length = token.length; i < length; ++i) {\n        string += token.charAt(i);\n        expandedTokens.push(string);\n      }\n\n      return expandedTokens;\n    };\n\n    return PrefixIndexStrategy;\n  }();\n  /**\n   * Enforces case-sensitive text matches.\n   */\n\n\n  var CaseSensitiveSanitizer = /*#__PURE__*/function () {\n    function CaseSensitiveSanitizer() {}\n\n    var _proto = CaseSensitiveSanitizer.prototype;\n    /**\n     * @inheritDocs\n     */\n\n    _proto.sanitize = function sanitize(text) {\n      return text ? text.trim() : '';\n    };\n\n    return CaseSensitiveSanitizer;\n  }();\n  /**\n   * Sanitizes text by converting to a locale-friendly lower-case version and triming leading and trailing whitespace.\n   */\n\n\n  var LowerCaseSanitizer = /*#__PURE__*/function () {\n    function LowerCaseSanitizer() {}\n\n    var _proto = LowerCaseSanitizer.prototype;\n    /**\n     * @inheritDocs\n     */\n\n    _proto.sanitize = function sanitize(text) {\n      return text ? text.toLocaleLowerCase().trim() : '';\n    };\n\n    return LowerCaseSanitizer;\n  }();\n  /**\n   * Find and return a nested object value.\n   *\n   * @param object to crawl\n   * @param path Property path\n   * @returns {any}\n   */\n\n\n  function getNestedFieldValue(object, path) {\n    path = path || [];\n    object = object || {};\n    var value = object; // walk down the property path\n\n    for (var i = 0; i < path.length; i++) {\n      value = value[path[i]];\n\n      if (value == null) {\n        return null;\n      }\n    }\n\n    return value;\n  }\n  /**\n   * Search index capable of returning results matching a set of tokens and ranked according to TF-IDF.\n   */\n\n\n  var TfIdfSearchIndex = /*#__PURE__*/function () {\n    function TfIdfSearchIndex(uidFieldName) {\n      this._uidFieldName = uidFieldName;\n      this._tokenToIdfCache = {};\n      this._tokenMap = {};\n    }\n    /**\n     * @inheritDocs\n     */\n\n\n    var _proto = TfIdfSearchIndex.prototype;\n\n    _proto.indexDocument = function indexDocument(token, uid, doc) {\n      this._tokenToIdfCache = {}; // New index invalidates previous IDF caches\n\n      var tokenMap = this._tokenMap;\n      var tokenDatum;\n\n      if (typeof tokenMap[token] !== 'object') {\n        tokenMap[token] = tokenDatum = {\n          $numDocumentOccurrences: 0,\n          $totalNumOccurrences: 1,\n          $uidMap: {}\n        };\n      } else {\n        tokenDatum = tokenMap[token];\n        tokenDatum.$totalNumOccurrences++;\n      }\n\n      var uidMap = tokenDatum.$uidMap;\n\n      if (typeof uidMap[uid] !== 'object') {\n        tokenDatum.$numDocumentOccurrences++;\n        uidMap[uid] = {\n          $document: doc,\n          $numTokenOccurrences: 1\n        };\n      } else {\n        uidMap[uid].$numTokenOccurrences++;\n      }\n    }\n    /**\n     * @inheritDocs\n     */\n    ;\n\n    _proto.search = function search(tokens, corpus) {\n      var uidToDocumentMap = {};\n\n      for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n        var token = tokens[i];\n        var tokenMetadata = this._tokenMap[token]; // Short circuit if no matches were found for any given token.\n\n        if (!tokenMetadata) {\n          return [];\n        }\n\n        if (i === 0) {\n          var keys = Object.keys(tokenMetadata.$uidMap);\n\n          for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n            var uid = keys[j];\n            uidToDocumentMap[uid] = tokenMetadata.$uidMap[uid].$document;\n          }\n        } else {\n          var keys = Object.keys(uidToDocumentMap);\n\n          for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n            var uid = keys[j];\n\n            if (typeof tokenMetadata.$uidMap[uid] !== 'object') {\n              delete uidToDocumentMap[uid];\n            }\n          }\n        }\n      }\n\n      var documents = [];\n\n      for (var uid in uidToDocumentMap) {\n        documents.push(uidToDocumentMap[uid]);\n      }\n\n      var calculateTfIdf = this._createCalculateTfIdf(); // Return documents sorted by TF-IDF\n\n\n      return documents.sort(function (documentA, documentB) {\n        return calculateTfIdf(tokens, documentB, corpus) - calculateTfIdf(tokens, documentA, corpus);\n      });\n    };\n\n    _proto._createCalculateIdf = function _createCalculateIdf() {\n      var tokenMap = this._tokenMap;\n      var tokenToIdfCache = this._tokenToIdfCache;\n      return function calculateIdf(token, documents) {\n        if (!tokenToIdfCache[token]) {\n          var numDocumentsWithToken = typeof tokenMap[token] !== 'undefined' ? tokenMap[token].$numDocumentOccurrences : 0;\n          tokenToIdfCache[token] = 1 + Math.log(documents.length / (1 + numDocumentsWithToken));\n        }\n\n        return tokenToIdfCache[token];\n      };\n    };\n\n    _proto._createCalculateTfIdf = function _createCalculateTfIdf() {\n      var tokenMap = this._tokenMap;\n      var uidFieldName = this._uidFieldName;\n\n      var calculateIdf = this._createCalculateIdf();\n\n      return function calculateTfIdf(tokens, document, documents) {\n        var score = 0;\n\n        for (var i = 0, numTokens = tokens.length; i < numTokens; ++i) {\n          var token = tokens[i];\n          var inverseDocumentFrequency = calculateIdf(token, documents);\n\n          if (inverseDocumentFrequency === Infinity) {\n            inverseDocumentFrequency = 0;\n          }\n\n          var uid;\n\n          if (uidFieldName instanceof Array) {\n            uid = document && getNestedFieldValue(document, uidFieldName);\n          } else {\n            uid = document && document[uidFieldName];\n          }\n\n          var termFrequency = typeof tokenMap[token] !== 'undefined' && typeof tokenMap[token].$uidMap[uid] !== 'undefined' ? tokenMap[token].$uidMap[uid].$numTokenOccurrences : 0;\n          score += termFrequency * inverseDocumentFrequency;\n        }\n\n        return score;\n      };\n    };\n\n    return TfIdfSearchIndex;\n  }();\n  /**\n   * Search index capable of returning results matching a set of tokens but without any meaningful rank or order.\n   */\n\n\n  var UnorderedSearchIndex = /*#__PURE__*/function () {\n    function UnorderedSearchIndex() {\n      this._tokenToUidToDocumentMap = {};\n    }\n    /**\n     * @inheritDocs\n     */\n\n\n    var _proto = UnorderedSearchIndex.prototype;\n\n    _proto.indexDocument = function indexDocument(token, uid, doc) {\n      if (typeof this._tokenToUidToDocumentMap[token] !== 'object') {\n        this._tokenToUidToDocumentMap[token] = {};\n      }\n\n      this._tokenToUidToDocumentMap[token][uid] = doc;\n    }\n    /**\n     * @inheritDocs\n     */\n    ;\n\n    _proto.search = function search(tokens, corpus) {\n      var intersectingDocumentMap = {};\n      var tokenToUidToDocumentMap = this._tokenToUidToDocumentMap;\n\n      for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n        var token = tokens[i];\n        var documentMap = tokenToUidToDocumentMap[token]; // Short circuit if no matches were found for any given token.\n\n        if (!documentMap) {\n          return [];\n        }\n\n        if (i === 0) {\n          var keys = Object.keys(documentMap);\n\n          for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n            var uid = keys[j];\n            intersectingDocumentMap[uid] = documentMap[uid];\n          }\n        } else {\n          var keys = Object.keys(intersectingDocumentMap);\n\n          for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n            var uid = keys[j];\n\n            if (typeof documentMap[uid] !== 'object') {\n              delete intersectingDocumentMap[uid];\n            }\n          }\n        }\n      }\n\n      var keys = Object.keys(intersectingDocumentMap);\n      var documents = [];\n\n      for (var i = 0, numKeys = keys.length; i < numKeys; i++) {\n        var uid = keys[i];\n        documents.push(intersectingDocumentMap[uid]);\n      }\n\n      return documents;\n    };\n\n    return UnorderedSearchIndex;\n  }();\n\n  var REGEX = /[^a-zа-яё0-9\\-']+/i;\n  /**\n   * Simple tokenizer that splits strings on whitespace characters and returns an array of all non-empty substrings.\n   */\n\n  var SimpleTokenizer = /*#__PURE__*/function () {\n    function SimpleTokenizer() {}\n\n    var _proto = SimpleTokenizer.prototype;\n    /**\n     * @inheritDocs\n     */\n\n    _proto.tokenize = function tokenize(text) {\n      return text.split(REGEX).filter(function (text) {\n        return text;\n      } // Filter empty tokens\n      );\n    };\n\n    return SimpleTokenizer;\n  }();\n  /**\n   * Stemming is the process of reducing search tokens to their root (or stem) so that searches for different forms of a\n   * word will match. For example \"search\", \"searching\" and \"searched\" are all reduced to the stem \"search\".\n   *\n   * <p>This stemming tokenizer converts tokens (words) to their stem forms before returning them. It requires an\n   * external stemming function to be provided; for this purpose I recommend the NPM 'porter-stemmer' library.\n   *\n   * <p>For more information see http : //tartarus.org/~martin/PorterStemmer/\n   */\n\n\n  var StemmingTokenizer = /*#__PURE__*/function () {\n    /**\n     * Constructor.\n     *\n     * @param stemmingFunction Function capable of accepting a word and returning its stem.\n     * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n     */\n    function StemmingTokenizer(stemmingFunction, decoratedTokenizer) {\n      this._stemmingFunction = stemmingFunction;\n      this._tokenizer = decoratedTokenizer;\n    }\n    /**\n     * @inheritDocs\n     */\n\n\n    var _proto = StemmingTokenizer.prototype;\n\n    _proto.tokenize = function tokenize(text) {\n      return this._tokenizer.tokenize(text).map(this._stemmingFunction);\n    };\n\n    return StemmingTokenizer;\n  }();\n  /**\n   * Stop words list copied from Lunr JS.\n   */\n\n\n  var StopWordsMap = {\n    a: true,\n    able: true,\n    about: true,\n    across: true,\n    after: true,\n    all: true,\n    almost: true,\n    also: true,\n    am: true,\n    among: true,\n    an: true,\n    and: true,\n    any: true,\n    are: true,\n    as: true,\n    at: true,\n    be: true,\n    because: true,\n    been: true,\n    but: true,\n    by: true,\n    can: true,\n    cannot: true,\n    could: true,\n    dear: true,\n    did: true,\n    'do': true,\n    does: true,\n    either: true,\n    'else': true,\n    ever: true,\n    every: true,\n    'for': true,\n    from: true,\n    'get': true,\n    got: true,\n    had: true,\n    has: true,\n    have: true,\n    he: true,\n    her: true,\n    hers: true,\n    him: true,\n    his: true,\n    how: true,\n    however: true,\n    i: true,\n    'if': true,\n    'in': true,\n    into: true,\n    is: true,\n    it: true,\n    its: true,\n    just: true,\n    least: true,\n    \"let\": true,\n    like: true,\n    likely: true,\n    may: true,\n    me: true,\n    might: true,\n    most: true,\n    must: true,\n    my: true,\n    neither: true,\n    no: true,\n    nor: true,\n    not: true,\n    of: true,\n    off: true,\n    often: true,\n    on: true,\n    only: true,\n    or: true,\n    other: true,\n    our: true,\n    own: true,\n    rather: true,\n    said: true,\n    say: true,\n    says: true,\n    she: true,\n    should: true,\n    since: true,\n    so: true,\n    some: true,\n    than: true,\n    that: true,\n    the: true,\n    their: true,\n    them: true,\n    then: true,\n    there: true,\n    these: true,\n    they: true,\n    'this': true,\n    tis: true,\n    to: true,\n    too: true,\n    twas: true,\n    us: true,\n    wants: true,\n    was: true,\n    we: true,\n    were: true,\n    what: true,\n    when: true,\n    where: true,\n    which: true,\n    'while': true,\n    who: true,\n    whom: true,\n    why: true,\n    will: true,\n    'with': true,\n    would: true,\n    yet: true,\n    you: true,\n    your: true\n  }; // Prevent false positives for inherited properties\n\n  StopWordsMap.constructor = false;\n  StopWordsMap.hasOwnProperty = false;\n  StopWordsMap.isPrototypeOf = false;\n  StopWordsMap.propertyIsEnumerable = false;\n  StopWordsMap.toLocaleString = false;\n  StopWordsMap.toString = false;\n  StopWordsMap.valueOf = false;\n  /**\n   * Stop words are very common (e.g. \"a\", \"and\", \"the\") and are often not semantically meaningful in the context of a\n   * search. This tokenizer removes stop words from a set of tokens before passing the remaining tokens along for\n   * indexing or searching purposes.\n   */\n\n  var StopWordsTokenizer = /*#__PURE__*/function () {\n    /**\n     * Constructor.\n     *\n     * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n     */\n    function StopWordsTokenizer(decoratedTokenizer) {\n      this._tokenizer = decoratedTokenizer;\n    }\n    /**\n     * @inheritDocs\n     */\n\n\n    var _proto = StopWordsTokenizer.prototype;\n\n    _proto.tokenize = function tokenize(text) {\n      return this._tokenizer.tokenize(text).filter(function (token) {\n        return !StopWordsMap[token];\n      });\n    };\n\n    return StopWordsTokenizer;\n  }();\n\n  function _defineProperties(target, props) {\n    for (var i = 0; i < props.length; i++) {\n      var descriptor = props[i];\n      descriptor.enumerable = descriptor.enumerable || false;\n      descriptor.configurable = true;\n      if (\"value\" in descriptor) descriptor.writable = true;\n      Object.defineProperty(target, descriptor.key, descriptor);\n    }\n  }\n\n  function _createClass(Constructor, protoProps, staticProps) {\n    if (protoProps) _defineProperties(Constructor.prototype, protoProps);\n    if (staticProps) _defineProperties(Constructor, staticProps);\n    return Constructor;\n  }\n  /**\n   * Simple client-side searching within a set of documents.\n   *\n   * <p>Documents can be searched by any number of fields. Indexing and search strategies are highly customizable.\n   */\n\n\n  var Search = /*#__PURE__*/function () {\n    /**\n     * Array containing either a property name or a path (list of property names) to a nested value\n     */\n\n    /**\n     * Constructor.\n     * @param uidFieldName Field containing values that uniquely identify search documents; this field's values are used\n     *                     to ensure that a search result set does not contain duplicate objects.\n     */\n    function Search(uidFieldName) {\n      if (!uidFieldName) {\n        throw Error('js-search requires a uid field name constructor parameter');\n      }\n\n      this._uidFieldName = uidFieldName; // Set default/recommended strategies\n\n      this._indexStrategy = new PrefixIndexStrategy();\n      this._searchIndex = new TfIdfSearchIndex(uidFieldName);\n      this._sanitizer = new LowerCaseSanitizer();\n      this._tokenizer = new SimpleTokenizer();\n      this._documents = [];\n      this._searchableFields = [];\n    }\n    /**\n     * Override the default index strategy.\n     * @param value Custom index strategy\n     * @throws Error if documents have already been indexed by this search instance\n     */\n\n\n    var _proto = Search.prototype;\n    /**\n     * Add a searchable document to the index. Document will automatically be indexed for search.\n     * @param document\n     */\n\n    _proto.addDocument = function addDocument(document) {\n      this.addDocuments([document]);\n    }\n    /**\n     * Adds searchable documents to the index. Documents will automatically be indexed for search.\n     * @param document\n     */\n    ;\n\n    _proto.addDocuments = function addDocuments(documents) {\n      this._documents = this._documents.concat(documents);\n      this.indexDocuments_(documents, this._searchableFields);\n    }\n    /**\n     * Add a new searchable field to the index. Existing documents will automatically be indexed using this new field.\n     *\n     * @param field Searchable field or field path. Pass a string to index a top-level field and an array of strings for nested fields.\n     */\n    ;\n\n    _proto.addIndex = function addIndex(field) {\n      this._searchableFields.push(field);\n\n      this.indexDocuments_(this._documents, [field]);\n    }\n    /**\n     * Search all documents for ones matching the specified query text.\n     * @param query\n     * @returns {Array<Object>}\n     */\n    ;\n\n    _proto.search = function search(query) {\n      var tokens = this._tokenizer.tokenize(this._sanitizer.sanitize(query));\n\n      return this._searchIndex.search(tokens, this._documents);\n    }\n    /**\n     * @param documents\n     * @param _searchableFields Array containing property names and paths (lists of property names) to nested values\n     * @private\n     */\n    ;\n\n    _proto.indexDocuments_ = function indexDocuments_(documents, _searchableFields) {\n      this._initialized = true;\n      var indexStrategy = this._indexStrategy;\n      var sanitizer = this._sanitizer;\n      var searchIndex = this._searchIndex;\n      var tokenizer = this._tokenizer;\n      var uidFieldName = this._uidFieldName;\n\n      for (var di = 0, numDocuments = documents.length; di < numDocuments; di++) {\n        var doc = documents[di];\n        var uid;\n\n        if (uidFieldName instanceof Array) {\n          uid = getNestedFieldValue(doc, uidFieldName);\n        } else {\n          uid = doc[uidFieldName];\n        }\n\n        for (var sfi = 0, numSearchableFields = _searchableFields.length; sfi < numSearchableFields; sfi++) {\n          var fieldValue;\n          var searchableField = _searchableFields[sfi];\n\n          if (searchableField instanceof Array) {\n            fieldValue = getNestedFieldValue(doc, searchableField);\n          } else {\n            fieldValue = doc[searchableField];\n          }\n\n          if (fieldValue != null && typeof fieldValue !== 'string' && fieldValue.toString) {\n            fieldValue = fieldValue.toString();\n          }\n\n          if (typeof fieldValue === 'string') {\n            var fieldTokens = tokenizer.tokenize(sanitizer.sanitize(fieldValue));\n\n            for (var fti = 0, numFieldValues = fieldTokens.length; fti < numFieldValues; fti++) {\n              var fieldToken = fieldTokens[fti];\n              var expandedTokens = indexStrategy.expandToken(fieldToken);\n\n              for (var eti = 0, nummExpandedTokens = expandedTokens.length; eti < nummExpandedTokens; eti++) {\n                var expandedToken = expandedTokens[eti];\n                searchIndex.indexDocument(expandedToken, uid, doc);\n              }\n            }\n          }\n        }\n      }\n    };\n\n    _createClass(Search, [{\n      key: \"indexStrategy\",\n      set: function set(value) {\n        if (this._initialized) {\n          throw Error('IIndexStrategy cannot be set after initialization');\n        }\n\n        this._indexStrategy = value;\n      },\n      get: function get() {\n        return this._indexStrategy;\n      }\n      /**\n       * Override the default text sanitizing strategy.\n       * @param value Custom text sanitizing strategy\n       * @throws Error if documents have already been indexed by this search instance\n       */\n\n    }, {\n      key: \"sanitizer\",\n      set: function set(value) {\n        if (this._initialized) {\n          throw Error('ISanitizer cannot be set after initialization');\n        }\n\n        this._sanitizer = value;\n      },\n      get: function get() {\n        return this._sanitizer;\n      }\n      /**\n       * Override the default search index strategy.\n       * @param value Custom search index strategy\n       * @throws Error if documents have already been indexed\n       */\n\n    }, {\n      key: \"searchIndex\",\n      set: function set(value) {\n        if (this._initialized) {\n          throw Error('ISearchIndex cannot be set after initialization');\n        }\n\n        this._searchIndex = value;\n      },\n      get: function get() {\n        return this._searchIndex;\n      }\n      /**\n       * Override the default text tokenizing strategy.\n       * @param value Custom text tokenizing strategy\n       * @throws Error if documents have already been indexed by this search instance\n       */\n\n    }, {\n      key: \"tokenizer\",\n      set: function set(value) {\n        if (this._initialized) {\n          throw Error('ITokenizer cannot be set after initialization');\n        }\n\n        this._tokenizer = value;\n      },\n      get: function get() {\n        return this._tokenizer;\n      }\n    }]);\n\n    return Search;\n  }();\n  /**\n   * This utility highlights the occurrences of tokens within a string of text. It can be used to give visual indicators\n   * of match criteria within searchable fields.\n   *\n   * <p>For performance purposes this highlighter only works with full-word or prefix token indexes.\n   */\n\n\n  var TokenHighlighter = /*#__PURE__*/function () {\n    /**\n     * Constructor.\n     *\n     * @param opt_indexStrategy Index strategy used by Search\n     * @param opt_sanitizer Sanitizer used by Search\n     * @param opt_wrapperTagName Optional wrapper tag name; defaults to 'mark' (e.g. <mark>)\n     */\n    function TokenHighlighter(opt_indexStrategy, opt_sanitizer, opt_wrapperTagName) {\n      this._indexStrategy = opt_indexStrategy || new PrefixIndexStrategy();\n      this._sanitizer = opt_sanitizer || new LowerCaseSanitizer();\n      this._wrapperTagName = opt_wrapperTagName || 'mark';\n    }\n    /**\n     * Highlights token occurrences within a string by wrapping them with a DOM element.\n     *\n     * @param text e.g. \"john wayne\"\n     * @param tokens e.g. [\"wa\"]\n     * @returns {string} e.g. \"john <mark>wa</mark>yne\"\n     */\n\n\n    var _proto = TokenHighlighter.prototype;\n\n    _proto.highlight = function highlight(text, tokens) {\n      var tagsLength = this._wrapText('').length;\n\n      var tokenDictionary = Object.create(null); // Create a token map for easier lookup below.\n\n      for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n        var token = this._sanitizer.sanitize(tokens[i]);\n\n        var expandedTokens = this._indexStrategy.expandToken(token);\n\n        for (var j = 0, numExpandedTokens = expandedTokens.length; j < numExpandedTokens; j++) {\n          var expandedToken = expandedTokens[j];\n\n          if (!tokenDictionary[expandedToken]) {\n            tokenDictionary[expandedToken] = [token];\n          } else {\n            tokenDictionary[expandedToken].push(token);\n          }\n        }\n      } // Track actualCurrentWord and sanitizedCurrentWord separately in case we encounter nested tags.\n\n\n      var actualCurrentWord = '';\n      var sanitizedCurrentWord = '';\n      var currentWordStartIndex = 0; // Note this assumes either prefix or full word matching.\n\n      for (var i = 0, textLength = text.length; i < textLength; i++) {\n        var character = text.charAt(i);\n\n        if (character === ' ') {\n          actualCurrentWord = '';\n          sanitizedCurrentWord = '';\n          currentWordStartIndex = i + 1;\n        } else {\n          actualCurrentWord += character;\n          sanitizedCurrentWord += this._sanitizer.sanitize(character);\n        }\n\n        if (tokenDictionary[sanitizedCurrentWord] && tokenDictionary[sanitizedCurrentWord].indexOf(sanitizedCurrentWord) >= 0) {\n          actualCurrentWord = this._wrapText(actualCurrentWord);\n          text = text.substring(0, currentWordStartIndex) + actualCurrentWord + text.substring(i + 1);\n          i += tagsLength;\n          textLength += tagsLength;\n        }\n      }\n\n      return text;\n    }\n    /**\n     * @param text to wrap\n     * @returns Text wrapped by wrapper tag (e.g. \"foo\" becomes \"<mark>foo</mark>\")\n     * @private\n     */\n    ;\n\n    _proto._wrapText = function _wrapText(text) {\n      var tagName = this._wrapperTagName;\n      return \"<\" + tagName + \">\" + text + \"</\" + tagName + \">\";\n    };\n\n    return TokenHighlighter;\n  }();\n\n  exports.AllSubstringsIndexStrategy = AllSubstringsIndexStrategy;\n  exports.CaseSensitiveSanitizer = CaseSensitiveSanitizer;\n  exports.ExactWordIndexStrategy = ExactWordIndexStrategy;\n  exports.LowerCaseSanitizer = LowerCaseSanitizer;\n  exports.PrefixIndexStrategy = PrefixIndexStrategy;\n  exports.Search = Search;\n  exports.SimpleTokenizer = SimpleTokenizer;\n  exports.StemmingTokenizer = StemmingTokenizer;\n  exports.StopWordsMap = StopWordsMap;\n  exports.StopWordsTokenizer = StopWordsTokenizer;\n  exports.TfIdfSearchIndex = TfIdfSearchIndex;\n  exports.TokenHighlighter = TokenHighlighter;\n  exports.UnorderedSearchIndex = UnorderedSearchIndex;\n  Object.defineProperty(exports, '__esModule', {\n    value: true\n  });\n});","map":{"version":3,"sources":["C:/Users/jaker/Desktop/SES-2A-Team2/Frontend/node_modules/js-search/dist/umd/js-search.js"],"names":["global","factory","exports","module","define","amd","self","JsSearch","AllSubstringsIndexStrategy","_proto","prototype","expandToken","token","expandedTokens","string","i","length","j","charAt","push","ExactWordIndexStrategy","PrefixIndexStrategy","CaseSensitiveSanitizer","sanitize","text","trim","LowerCaseSanitizer","toLocaleLowerCase","getNestedFieldValue","object","path","value","TfIdfSearchIndex","uidFieldName","_uidFieldName","_tokenToIdfCache","_tokenMap","indexDocument","uid","doc","tokenMap","tokenDatum","$numDocumentOccurrences","$totalNumOccurrences","$uidMap","uidMap","$document","$numTokenOccurrences","search","tokens","corpus","uidToDocumentMap","numTokens","tokenMetadata","keys","Object","numKeys","documents","calculateTfIdf","_createCalculateTfIdf","sort","documentA","documentB","_createCalculateIdf","tokenToIdfCache","calculateIdf","numDocumentsWithToken","Math","log","document","score","inverseDocumentFrequency","Infinity","Array","termFrequency","UnorderedSearchIndex","_tokenToUidToDocumentMap","intersectingDocumentMap","tokenToUidToDocumentMap","documentMap","REGEX","SimpleTokenizer","tokenize","split","filter","StemmingTokenizer","stemmingFunction","decoratedTokenizer","_stemmingFunction","_tokenizer","map","StopWordsMap","a","able","about","across","after","all","almost","also","am","among","an","and","any","are","as","at","be","because","been","but","by","can","cannot","could","dear","did","does","either","ever","every","from","got","had","has","have","he","her","hers","him","his","how","however","into","is","it","its","just","least","like","likely","may","me","might","most","must","my","neither","no","nor","not","of","off","often","on","only","or","other","our","own","rather","said","say","says","she","should","since","so","some","than","that","the","their","them","then","there","these","they","tis","to","too","twas","us","wants","was","we","were","what","when","where","which","who","whom","why","will","would","yet","you","your","constructor","hasOwnProperty","isPrototypeOf","propertyIsEnumerable","toLocaleString","toString","valueOf","StopWordsTokenizer","_defineProperties","target","props","descriptor","enumerable","configurable","writable","defineProperty","key","_createClass","Constructor","protoProps","staticProps","Search","Error","_indexStrategy","_searchIndex","_sanitizer","_documents","_searchableFields","addDocument","addDocuments","concat","indexDocuments_","addIndex","field","query","_initialized","indexStrategy","sanitizer","searchIndex","tokenizer","di","numDocuments","sfi","numSearchableFields","fieldValue","searchableField","fieldTokens","fti","numFieldValues","fieldToken","eti","nummExpandedTokens","expandedToken","set","get","TokenHighlighter","opt_indexStrategy","opt_sanitizer","opt_wrapperTagName","_wrapperTagName","highlight","tagsLength","_wrapText","tokenDictionary","create","numExpandedTokens","actualCurrentWord","sanitizedCurrentWord","currentWordStartIndex","textLength","character","indexOf","substring","tagName"],"mappings":"AAAC,WAAUA,MAAV,EAAkBC,OAAlB,EAA2B;AAC1B,SAAOC,OAAP,KAAmB,QAAnB,IAA+B,OAAOC,MAAP,KAAkB,WAAjD,GAA+DF,OAAO,CAACC,OAAD,CAAtE,GACA,OAAOE,MAAP,KAAkB,UAAlB,IAAgCA,MAAM,CAACC,GAAvC,GAA6CD,MAAM,CAAC,CAAC,SAAD,CAAD,EAAcH,OAAd,CAAnD,IACCD,MAAM,GAAGA,MAAM,IAAIM,IAAnB,EAAyBL,OAAO,CAACD,MAAM,CAACO,QAAP,GAAkB,EAAnB,CADjC,CADA;AAGD,CAJA,EAIC,IAJD,EAIQ,UAAUL,OAAV,EAAmB;AAAE;AAE5B;AACF;AACA;;AACE,MAAIM,0BAA0B,GAAG,aAAa,YAAY;AACxD,aAASA,0BAAT,GAAsC,CAAE;;AAExC,QAAIC,MAAM,GAAGD,0BAA0B,CAACE,SAAxC;AAEA;AACJ;AACA;;AACID,IAAAA,MAAM,CAACE,WAAP,GAAqB,SAASA,WAAT,CAAqBC,KAArB,EAA4B;AAC/C,UAAIC,cAAc,GAAG,EAArB;AACA,UAAIC,MAAJ;;AAEA,WAAK,IAAIC,CAAC,GAAG,CAAR,EAAWC,MAAM,GAAGJ,KAAK,CAACI,MAA/B,EAAuCD,CAAC,GAAGC,MAA3C,EAAmD,EAAED,CAArD,EAAwD;AACtDD,QAAAA,MAAM,GAAG,EAAT;;AAEA,aAAK,IAAIG,CAAC,GAAGF,CAAb,EAAgBE,CAAC,GAAGD,MAApB,EAA4B,EAAEC,CAA9B,EAAiC;AAC/BH,UAAAA,MAAM,IAAIF,KAAK,CAACM,MAAN,CAAaD,CAAb,CAAV;AACAJ,UAAAA,cAAc,CAACM,IAAf,CAAoBL,MAApB;AACD;AACF;;AAED,aAAOD,cAAP;AACD,KAdD;;AAgBA,WAAOL,0BAAP;AACD,GAzB6C,EAA9C;AA2BA;AACF;AACA;;;AACE,MAAIY,sBAAsB,GAAG,aAAa,YAAY;AACpD,aAASA,sBAAT,GAAkC,CAAE;;AAEpC,QAAIX,MAAM,GAAGW,sBAAsB,CAACV,SAApC;AAEA;AACJ;AACA;;AACID,IAAAA,MAAM,CAACE,WAAP,GAAqB,SAASA,WAAT,CAAqBC,KAArB,EAA4B;AAC/C,aAAOA,KAAK,GAAG,CAACA,KAAD,CAAH,GAAa,EAAzB;AACD,KAFD;;AAIA,WAAOQ,sBAAP;AACD,GAbyC,EAA1C;AAeA;AACF;AACA;;;AACE,MAAIC,mBAAmB,GAAG,aAAa,YAAY;AACjD,aAASA,mBAAT,GAA+B,CAAE;;AAEjC,QAAIZ,MAAM,GAAGY,mBAAmB,CAACX,SAAjC;AAEA;AACJ;AACA;;AACID,IAAAA,MAAM,CAACE,WAAP,GAAqB,SAASA,WAAT,CAAqBC,KAArB,EAA4B;AAC/C,UAAIC,cAAc,GAAG,EAArB;AACA,UAAIC,MAAM,GAAG,EAAb;;AAEA,WAAK,IAAIC,CAAC,GAAG,CAAR,EAAWC,MAAM,GAAGJ,KAAK,CAACI,MAA/B,EAAuCD,CAAC,GAAGC,MAA3C,EAAmD,EAAED,CAArD,EAAwD;AACtDD,QAAAA,MAAM,IAAIF,KAAK,CAACM,MAAN,CAAaH,CAAb,CAAV;AACAF,QAAAA,cAAc,CAACM,IAAf,CAAoBL,MAApB;AACD;;AAED,aAAOD,cAAP;AACD,KAVD;;AAYA,WAAOQ,mBAAP;AACD,GArBsC,EAAvC;AAuBA;AACF;AACA;;;AACE,MAAIC,sBAAsB,GAAG,aAAa,YAAY;AACpD,aAASA,sBAAT,GAAkC,CAAE;;AAEpC,QAAIb,MAAM,GAAGa,sBAAsB,CAACZ,SAApC;AAEA;AACJ;AACA;;AACID,IAAAA,MAAM,CAACc,QAAP,GAAkB,SAASA,QAAT,CAAkBC,IAAlB,EAAwB;AACxC,aAAOA,IAAI,GAAGA,IAAI,CAACC,IAAL,EAAH,GAAiB,EAA5B;AACD,KAFD;;AAIA,WAAOH,sBAAP;AACD,GAbyC,EAA1C;AAeA;AACF;AACA;;;AACE,MAAII,kBAAkB,GAAG,aAAa,YAAY;AAChD,aAASA,kBAAT,GAA8B,CAAE;;AAEhC,QAAIjB,MAAM,GAAGiB,kBAAkB,CAAChB,SAAhC;AAEA;AACJ;AACA;;AACID,IAAAA,MAAM,CAACc,QAAP,GAAkB,SAASA,QAAT,CAAkBC,IAAlB,EAAwB;AACxC,aAAOA,IAAI,GAAGA,IAAI,CAACG,iBAAL,GAAyBF,IAAzB,EAAH,GAAqC,EAAhD;AACD,KAFD;;AAIA,WAAOC,kBAAP;AACD,GAbqC,EAAtC;AAeA;AACF;AACA;AACA;AACA;AACA;AACA;;;AACE,WAASE,mBAAT,CAA6BC,MAA7B,EAAqCC,IAArC,EAA2C;AACzCA,IAAAA,IAAI,GAAGA,IAAI,IAAI,EAAf;AACAD,IAAAA,MAAM,GAAGA,MAAM,IAAI,EAAnB;AACA,QAAIE,KAAK,GAAGF,MAAZ,CAHyC,CAGrB;;AAEpB,SAAK,IAAId,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGe,IAAI,CAACd,MAAzB,EAAiCD,CAAC,EAAlC,EAAsC;AACpCgB,MAAAA,KAAK,GAAGA,KAAK,CAACD,IAAI,CAACf,CAAD,CAAL,CAAb;;AAEA,UAAIgB,KAAK,IAAI,IAAb,EAAmB;AACjB,eAAO,IAAP;AACD;AACF;;AAED,WAAOA,KAAP;AACD;AAED;AACF;AACA;;;AACE,MAAIC,gBAAgB,GAAG,aAAa,YAAY;AAC9C,aAASA,gBAAT,CAA0BC,YAA1B,EAAwC;AACtC,WAAKC,aAAL,GAAqBD,YAArB;AACA,WAAKE,gBAAL,GAAwB,EAAxB;AACA,WAAKC,SAAL,GAAiB,EAAjB;AACD;AACD;AACJ;AACA;;;AAGI,QAAI3B,MAAM,GAAGuB,gBAAgB,CAACtB,SAA9B;;AAEAD,IAAAA,MAAM,CAAC4B,aAAP,GAAuB,SAASA,aAAT,CAAuBzB,KAAvB,EAA8B0B,GAA9B,EAAmCC,GAAnC,EAAwC;AAC7D,WAAKJ,gBAAL,GAAwB,EAAxB,CAD6D,CACjC;;AAE5B,UAAIK,QAAQ,GAAG,KAAKJ,SAApB;AACA,UAAIK,UAAJ;;AAEA,UAAI,OAAOD,QAAQ,CAAC5B,KAAD,CAAf,KAA2B,QAA/B,EAAyC;AACvC4B,QAAAA,QAAQ,CAAC5B,KAAD,CAAR,GAAkB6B,UAAU,GAAG;AAC7BC,UAAAA,uBAAuB,EAAE,CADI;AAE7BC,UAAAA,oBAAoB,EAAE,CAFO;AAG7BC,UAAAA,OAAO,EAAE;AAHoB,SAA/B;AAKD,OAND,MAMO;AACLH,QAAAA,UAAU,GAAGD,QAAQ,CAAC5B,KAAD,CAArB;AACA6B,QAAAA,UAAU,CAACE,oBAAX;AACD;;AAED,UAAIE,MAAM,GAAGJ,UAAU,CAACG,OAAxB;;AAEA,UAAI,OAAOC,MAAM,CAACP,GAAD,CAAb,KAAuB,QAA3B,EAAqC;AACnCG,QAAAA,UAAU,CAACC,uBAAX;AACAG,QAAAA,MAAM,CAACP,GAAD,CAAN,GAAc;AACZQ,UAAAA,SAAS,EAAEP,GADC;AAEZQ,UAAAA,oBAAoB,EAAE;AAFV,SAAd;AAID,OAND,MAMO;AACLF,QAAAA,MAAM,CAACP,GAAD,CAAN,CAAYS,oBAAZ;AACD;AACF;AACD;AACJ;AACA;AA/BI;;AAkCAtC,IAAAA,MAAM,CAACuC,MAAP,GAAgB,SAASA,MAAT,CAAgBC,MAAhB,EAAwBC,MAAxB,EAAgC;AAC9C,UAAIC,gBAAgB,GAAG,EAAvB;;AAEA,WAAK,IAAIpC,CAAC,GAAG,CAAR,EAAWqC,SAAS,GAAGH,MAAM,CAACjC,MAAnC,EAA2CD,CAAC,GAAGqC,SAA/C,EAA0DrC,CAAC,EAA3D,EAA+D;AAC7D,YAAIH,KAAK,GAAGqC,MAAM,CAAClC,CAAD,CAAlB;AACA,YAAIsC,aAAa,GAAG,KAAKjB,SAAL,CAAexB,KAAf,CAApB,CAF6D,CAElB;;AAE3C,YAAI,CAACyC,aAAL,EAAoB;AAClB,iBAAO,EAAP;AACD;;AAED,YAAItC,CAAC,KAAK,CAAV,EAAa;AACX,cAAIuC,IAAI,GAAGC,MAAM,CAACD,IAAP,CAAYD,aAAa,CAACT,OAA1B,CAAX;;AAEA,eAAK,IAAI3B,CAAC,GAAG,CAAR,EAAWuC,OAAO,GAAGF,IAAI,CAACtC,MAA/B,EAAuCC,CAAC,GAAGuC,OAA3C,EAAoDvC,CAAC,EAArD,EAAyD;AACvD,gBAAIqB,GAAG,GAAGgB,IAAI,CAACrC,CAAD,CAAd;AACAkC,YAAAA,gBAAgB,CAACb,GAAD,CAAhB,GAAwBe,aAAa,CAACT,OAAd,CAAsBN,GAAtB,EAA2BQ,SAAnD;AACD;AACF,SAPD,MAOO;AACL,cAAIQ,IAAI,GAAGC,MAAM,CAACD,IAAP,CAAYH,gBAAZ,CAAX;;AAEA,eAAK,IAAIlC,CAAC,GAAG,CAAR,EAAWuC,OAAO,GAAGF,IAAI,CAACtC,MAA/B,EAAuCC,CAAC,GAAGuC,OAA3C,EAAoDvC,CAAC,EAArD,EAAyD;AACvD,gBAAIqB,GAAG,GAAGgB,IAAI,CAACrC,CAAD,CAAd;;AAEA,gBAAI,OAAOoC,aAAa,CAACT,OAAd,CAAsBN,GAAtB,CAAP,KAAsC,QAA1C,EAAoD;AAClD,qBAAOa,gBAAgB,CAACb,GAAD,CAAvB;AACD;AACF;AACF;AACF;;AAED,UAAImB,SAAS,GAAG,EAAhB;;AAEA,WAAK,IAAInB,GAAT,IAAgBa,gBAAhB,EAAkC;AAChCM,QAAAA,SAAS,CAACtC,IAAV,CAAegC,gBAAgB,CAACb,GAAD,CAA/B;AACD;;AAED,UAAIoB,cAAc,GAAG,KAAKC,qBAAL,EAArB,CArC8C,CAqCK;;;AAGnD,aAAOF,SAAS,CAACG,IAAV,CAAe,UAAUC,SAAV,EAAqBC,SAArB,EAAgC;AACpD,eAAOJ,cAAc,CAACT,MAAD,EAASa,SAAT,EAAoBZ,MAApB,CAAd,GAA4CQ,cAAc,CAACT,MAAD,EAASY,SAAT,EAAoBX,MAApB,CAAjE;AACD,OAFM,CAAP;AAGD,KA3CD;;AA6CAzC,IAAAA,MAAM,CAACsD,mBAAP,GAA6B,SAASA,mBAAT,GAA+B;AAC1D,UAAIvB,QAAQ,GAAG,KAAKJ,SAApB;AACA,UAAI4B,eAAe,GAAG,KAAK7B,gBAA3B;AACA,aAAO,SAAS8B,YAAT,CAAsBrD,KAAtB,EAA6B6C,SAA7B,EAAwC;AAC7C,YAAI,CAACO,eAAe,CAACpD,KAAD,CAApB,EAA6B;AAC3B,cAAIsD,qBAAqB,GAAG,OAAO1B,QAAQ,CAAC5B,KAAD,CAAf,KAA2B,WAA3B,GAAyC4B,QAAQ,CAAC5B,KAAD,CAAR,CAAgB8B,uBAAzD,GAAmF,CAA/G;AACAsB,UAAAA,eAAe,CAACpD,KAAD,CAAf,GAAyB,IAAIuD,IAAI,CAACC,GAAL,CAASX,SAAS,CAACzC,MAAV,IAAoB,IAAIkD,qBAAxB,CAAT,CAA7B;AACD;;AAED,eAAOF,eAAe,CAACpD,KAAD,CAAtB;AACD,OAPD;AAQD,KAXD;;AAaAH,IAAAA,MAAM,CAACkD,qBAAP,GAA+B,SAASA,qBAAT,GAAiC;AAC9D,UAAInB,QAAQ,GAAG,KAAKJ,SAApB;AACA,UAAIH,YAAY,GAAG,KAAKC,aAAxB;;AAEA,UAAI+B,YAAY,GAAG,KAAKF,mBAAL,EAAnB;;AAEA,aAAO,SAASL,cAAT,CAAwBT,MAAxB,EAAgCoB,QAAhC,EAA0CZ,SAA1C,EAAqD;AAC1D,YAAIa,KAAK,GAAG,CAAZ;;AAEA,aAAK,IAAIvD,CAAC,GAAG,CAAR,EAAWqC,SAAS,GAAGH,MAAM,CAACjC,MAAnC,EAA2CD,CAAC,GAAGqC,SAA/C,EAA0D,EAAErC,CAA5D,EAA+D;AAC7D,cAAIH,KAAK,GAAGqC,MAAM,CAAClC,CAAD,CAAlB;AACA,cAAIwD,wBAAwB,GAAGN,YAAY,CAACrD,KAAD,EAAQ6C,SAAR,CAA3C;;AAEA,cAAIc,wBAAwB,KAAKC,QAAjC,EAA2C;AACzCD,YAAAA,wBAAwB,GAAG,CAA3B;AACD;;AAED,cAAIjC,GAAJ;;AAEA,cAAIL,YAAY,YAAYwC,KAA5B,EAAmC;AACjCnC,YAAAA,GAAG,GAAG+B,QAAQ,IAAIzC,mBAAmB,CAACyC,QAAD,EAAWpC,YAAX,CAArC;AACD,WAFD,MAEO;AACLK,YAAAA,GAAG,GAAG+B,QAAQ,IAAIA,QAAQ,CAACpC,YAAD,CAA1B;AACD;;AAED,cAAIyC,aAAa,GAAG,OAAOlC,QAAQ,CAAC5B,KAAD,CAAf,KAA2B,WAA3B,IAA0C,OAAO4B,QAAQ,CAAC5B,KAAD,CAAR,CAAgBgC,OAAhB,CAAwBN,GAAxB,CAAP,KAAwC,WAAlF,GAAgGE,QAAQ,CAAC5B,KAAD,CAAR,CAAgBgC,OAAhB,CAAwBN,GAAxB,EAA6BS,oBAA7H,GAAoJ,CAAxK;AACAuB,UAAAA,KAAK,IAAII,aAAa,GAAGH,wBAAzB;AACD;;AAED,eAAOD,KAAP;AACD,OAxBD;AAyBD,KA/BD;;AAiCA,WAAOtC,gBAAP;AACD,GA3ImC,EAApC;AA6IA;AACF;AACA;;;AACE,MAAI2C,oBAAoB,GAAG,aAAa,YAAY;AAClD,aAASA,oBAAT,GAAgC;AAC9B,WAAKC,wBAAL,GAAgC,EAAhC;AACD;AACD;AACJ;AACA;;;AAGI,QAAInE,MAAM,GAAGkE,oBAAoB,CAACjE,SAAlC;;AAEAD,IAAAA,MAAM,CAAC4B,aAAP,GAAuB,SAASA,aAAT,CAAuBzB,KAAvB,EAA8B0B,GAA9B,EAAmCC,GAAnC,EAAwC;AAC7D,UAAI,OAAO,KAAKqC,wBAAL,CAA8BhE,KAA9B,CAAP,KAAgD,QAApD,EAA8D;AAC5D,aAAKgE,wBAAL,CAA8BhE,KAA9B,IAAuC,EAAvC;AACD;;AAED,WAAKgE,wBAAL,CAA8BhE,KAA9B,EAAqC0B,GAArC,IAA4CC,GAA5C;AACD;AACD;AACJ;AACA;AATI;;AAYA9B,IAAAA,MAAM,CAACuC,MAAP,GAAgB,SAASA,MAAT,CAAgBC,MAAhB,EAAwBC,MAAxB,EAAgC;AAC9C,UAAI2B,uBAAuB,GAAG,EAA9B;AACA,UAAIC,uBAAuB,GAAG,KAAKF,wBAAnC;;AAEA,WAAK,IAAI7D,CAAC,GAAG,CAAR,EAAWqC,SAAS,GAAGH,MAAM,CAACjC,MAAnC,EAA2CD,CAAC,GAAGqC,SAA/C,EAA0DrC,CAAC,EAA3D,EAA+D;AAC7D,YAAIH,KAAK,GAAGqC,MAAM,CAAClC,CAAD,CAAlB;AACA,YAAIgE,WAAW,GAAGD,uBAAuB,CAAClE,KAAD,CAAzC,CAF6D,CAEX;;AAElD,YAAI,CAACmE,WAAL,EAAkB;AAChB,iBAAO,EAAP;AACD;;AAED,YAAIhE,CAAC,KAAK,CAAV,EAAa;AACX,cAAIuC,IAAI,GAAGC,MAAM,CAACD,IAAP,CAAYyB,WAAZ,CAAX;;AAEA,eAAK,IAAI9D,CAAC,GAAG,CAAR,EAAWuC,OAAO,GAAGF,IAAI,CAACtC,MAA/B,EAAuCC,CAAC,GAAGuC,OAA3C,EAAoDvC,CAAC,EAArD,EAAyD;AACvD,gBAAIqB,GAAG,GAAGgB,IAAI,CAACrC,CAAD,CAAd;AACA4D,YAAAA,uBAAuB,CAACvC,GAAD,CAAvB,GAA+ByC,WAAW,CAACzC,GAAD,CAA1C;AACD;AACF,SAPD,MAOO;AACL,cAAIgB,IAAI,GAAGC,MAAM,CAACD,IAAP,CAAYuB,uBAAZ,CAAX;;AAEA,eAAK,IAAI5D,CAAC,GAAG,CAAR,EAAWuC,OAAO,GAAGF,IAAI,CAACtC,MAA/B,EAAuCC,CAAC,GAAGuC,OAA3C,EAAoDvC,CAAC,EAArD,EAAyD;AACvD,gBAAIqB,GAAG,GAAGgB,IAAI,CAACrC,CAAD,CAAd;;AAEA,gBAAI,OAAO8D,WAAW,CAACzC,GAAD,CAAlB,KAA4B,QAAhC,EAA0C;AACxC,qBAAOuC,uBAAuB,CAACvC,GAAD,CAA9B;AACD;AACF;AACF;AACF;;AAED,UAAIgB,IAAI,GAAGC,MAAM,CAACD,IAAP,CAAYuB,uBAAZ,CAAX;AACA,UAAIpB,SAAS,GAAG,EAAhB;;AAEA,WAAK,IAAI1C,CAAC,GAAG,CAAR,EAAWyC,OAAO,GAAGF,IAAI,CAACtC,MAA/B,EAAuCD,CAAC,GAAGyC,OAA3C,EAAoDzC,CAAC,EAArD,EAAyD;AACvD,YAAIuB,GAAG,GAAGgB,IAAI,CAACvC,CAAD,CAAd;AACA0C,QAAAA,SAAS,CAACtC,IAAV,CAAe0D,uBAAuB,CAACvC,GAAD,CAAtC;AACD;;AAED,aAAOmB,SAAP;AACD,KAzCD;;AA2CA,WAAOkB,oBAAP;AACD,GAnEuC,EAAxC;;AAqEA,MAAIK,KAAK,GAAG,oBAAZ;AACA;AACF;AACA;;AAEE,MAAIC,eAAe,GAAG,aAAa,YAAY;AAC7C,aAASA,eAAT,GAA2B,CAAE;;AAE7B,QAAIxE,MAAM,GAAGwE,eAAe,CAACvE,SAA7B;AAEA;AACJ;AACA;;AACID,IAAAA,MAAM,CAACyE,QAAP,GAAkB,SAASA,QAAT,CAAkB1D,IAAlB,EAAwB;AACxC,aAAOA,IAAI,CAAC2D,KAAL,CAAWH,KAAX,EAAkBI,MAAlB,CAAyB,UAAU5D,IAAV,EAAgB;AAC9C,eAAOA,IAAP;AACD,OAFM,CAEL;AAFK,OAAP;AAID,KALD;;AAOA,WAAOyD,eAAP;AACD,GAhBkC,EAAnC;AAkBA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AACE,MAAII,iBAAiB,GAAG,aAAa,YAAY;AAC/C;AACJ;AACA;AACA;AACA;AACA;AACI,aAASA,iBAAT,CAA2BC,gBAA3B,EAA6CC,kBAA7C,EAAiE;AAC/D,WAAKC,iBAAL,GAAyBF,gBAAzB;AACA,WAAKG,UAAL,GAAkBF,kBAAlB;AACD;AACD;AACJ;AACA;;;AAGI,QAAI9E,MAAM,GAAG4E,iBAAiB,CAAC3E,SAA/B;;AAEAD,IAAAA,MAAM,CAACyE,QAAP,GAAkB,SAASA,QAAT,CAAkB1D,IAAlB,EAAwB;AACxC,aAAO,KAAKiE,UAAL,CAAgBP,QAAhB,CAAyB1D,IAAzB,EAA+BkE,GAA/B,CAAmC,KAAKF,iBAAxC,CAAP;AACD,KAFD;;AAIA,WAAOH,iBAAP;AACD,GAvBoC,EAArC;AAyBA;AACF;AACA;;;AACE,MAAIM,YAAY,GAAG;AACjBC,IAAAA,CAAC,EAAE,IADc;AAEjBC,IAAAA,IAAI,EAAE,IAFW;AAGjBC,IAAAA,KAAK,EAAE,IAHU;AAIjBC,IAAAA,MAAM,EAAE,IAJS;AAKjBC,IAAAA,KAAK,EAAE,IALU;AAMjBC,IAAAA,GAAG,EAAE,IANY;AAOjBC,IAAAA,MAAM,EAAE,IAPS;AAQjBC,IAAAA,IAAI,EAAE,IARW;AASjBC,IAAAA,EAAE,EAAE,IATa;AAUjBC,IAAAA,KAAK,EAAE,IAVU;AAWjBC,IAAAA,EAAE,EAAE,IAXa;AAYjBC,IAAAA,GAAG,EAAE,IAZY;AAajBC,IAAAA,GAAG,EAAE,IAbY;AAcjBC,IAAAA,GAAG,EAAE,IAdY;AAejBC,IAAAA,EAAE,EAAE,IAfa;AAgBjBC,IAAAA,EAAE,EAAE,IAhBa;AAiBjBC,IAAAA,EAAE,EAAE,IAjBa;AAkBjBC,IAAAA,OAAO,EAAE,IAlBQ;AAmBjBC,IAAAA,IAAI,EAAE,IAnBW;AAoBjBC,IAAAA,GAAG,EAAE,IApBY;AAqBjBC,IAAAA,EAAE,EAAE,IArBa;AAsBjBC,IAAAA,GAAG,EAAE,IAtBY;AAuBjBC,IAAAA,MAAM,EAAE,IAvBS;AAwBjBC,IAAAA,KAAK,EAAE,IAxBU;AAyBjBC,IAAAA,IAAI,EAAE,IAzBW;AA0BjBC,IAAAA,GAAG,EAAE,IA1BY;AA2BjB,UAAM,IA3BW;AA4BjBC,IAAAA,IAAI,EAAE,IA5BW;AA6BjBC,IAAAA,MAAM,EAAE,IA7BS;AA8BjB,YAAQ,IA9BS;AA+BjBC,IAAAA,IAAI,EAAE,IA/BW;AAgCjBC,IAAAA,KAAK,EAAE,IAhCU;AAiCjB,WAAO,IAjCU;AAkCjBC,IAAAA,IAAI,EAAE,IAlCW;AAmCjB,WAAO,IAnCU;AAoCjBC,IAAAA,GAAG,EAAE,IApCY;AAqCjBC,IAAAA,GAAG,EAAE,IArCY;AAsCjBC,IAAAA,GAAG,EAAE,IAtCY;AAuCjBC,IAAAA,IAAI,EAAE,IAvCW;AAwCjBC,IAAAA,EAAE,EAAE,IAxCa;AAyCjBC,IAAAA,GAAG,EAAE,IAzCY;AA0CjBC,IAAAA,IAAI,EAAE,IA1CW;AA2CjBC,IAAAA,GAAG,EAAE,IA3CY;AA4CjBC,IAAAA,GAAG,EAAE,IA5CY;AA6CjBC,IAAAA,GAAG,EAAE,IA7CY;AA8CjBC,IAAAA,OAAO,EAAE,IA9CQ;AA+CjBtH,IAAAA,CAAC,EAAE,IA/Cc;AAgDjB,UAAM,IAhDW;AAiDjB,UAAM,IAjDW;AAkDjBuH,IAAAA,IAAI,EAAE,IAlDW;AAmDjBC,IAAAA,EAAE,EAAE,IAnDa;AAoDjBC,IAAAA,EAAE,EAAE,IApDa;AAqDjBC,IAAAA,GAAG,EAAE,IArDY;AAsDjBC,IAAAA,IAAI,EAAE,IAtDW;AAuDjBC,IAAAA,KAAK,EAAE,IAvDU;AAwDjB,WAAO,IAxDU;AAyDjBC,IAAAA,IAAI,EAAE,IAzDW;AA0DjBC,IAAAA,MAAM,EAAE,IA1DS;AA2DjBC,IAAAA,GAAG,EAAE,IA3DY;AA4DjBC,IAAAA,EAAE,EAAE,IA5Da;AA6DjBC,IAAAA,KAAK,EAAE,IA7DU;AA8DjBC,IAAAA,IAAI,EAAE,IA9DW;AA+DjBC,IAAAA,IAAI,EAAE,IA/DW;AAgEjBC,IAAAA,EAAE,EAAE,IAhEa;AAiEjBC,IAAAA,OAAO,EAAE,IAjEQ;AAkEjBC,IAAAA,EAAE,EAAE,IAlEa;AAmEjBC,IAAAA,GAAG,EAAE,IAnEY;AAoEjBC,IAAAA,GAAG,EAAE,IApEY;AAqEjBC,IAAAA,EAAE,EAAE,IArEa;AAsEjBC,IAAAA,GAAG,EAAE,IAtEY;AAuEjBC,IAAAA,KAAK,EAAE,IAvEU;AAwEjBC,IAAAA,EAAE,EAAE,IAxEa;AAyEjBC,IAAAA,IAAI,EAAE,IAzEW;AA0EjBC,IAAAA,EAAE,EAAE,IA1Ea;AA2EjBC,IAAAA,KAAK,EAAE,IA3EU;AA4EjBC,IAAAA,GAAG,EAAE,IA5EY;AA6EjBC,IAAAA,GAAG,EAAE,IA7EY;AA8EjBC,IAAAA,MAAM,EAAE,IA9ES;AA+EjBC,IAAAA,IAAI,EAAE,IA/EW;AAgFjBC,IAAAA,GAAG,EAAE,IAhFY;AAiFjBC,IAAAA,IAAI,EAAE,IAjFW;AAkFjBC,IAAAA,GAAG,EAAE,IAlFY;AAmFjBC,IAAAA,MAAM,EAAE,IAnFS;AAoFjBC,IAAAA,KAAK,EAAE,IApFU;AAqFjBC,IAAAA,EAAE,EAAE,IArFa;AAsFjBC,IAAAA,IAAI,EAAE,IAtFW;AAuFjBC,IAAAA,IAAI,EAAE,IAvFW;AAwFjBC,IAAAA,IAAI,EAAE,IAxFW;AAyFjBC,IAAAA,GAAG,EAAE,IAzFY;AA0FjBC,IAAAA,KAAK,EAAE,IA1FU;AA2FjBC,IAAAA,IAAI,EAAE,IA3FW;AA4FjBC,IAAAA,IAAI,EAAE,IA5FW;AA6FjBC,IAAAA,KAAK,EAAE,IA7FU;AA8FjBC,IAAAA,KAAK,EAAE,IA9FU;AA+FjBC,IAAAA,IAAI,EAAE,IA/FW;AAgGjB,YAAQ,IAhGS;AAiGjBC,IAAAA,GAAG,EAAE,IAjGY;AAkGjBC,IAAAA,EAAE,EAAE,IAlGa;AAmGjBC,IAAAA,GAAG,EAAE,IAnGY;AAoGjBC,IAAAA,IAAI,EAAE,IApGW;AAqGjBC,IAAAA,EAAE,EAAE,IArGa;AAsGjBC,IAAAA,KAAK,EAAE,IAtGU;AAuGjBC,IAAAA,GAAG,EAAE,IAvGY;AAwGjBC,IAAAA,EAAE,EAAE,IAxGa;AAyGjBC,IAAAA,IAAI,EAAE,IAzGW;AA0GjBC,IAAAA,IAAI,EAAE,IA1GW;AA2GjBC,IAAAA,IAAI,EAAE,IA3GW;AA4GjBC,IAAAA,KAAK,EAAE,IA5GU;AA6GjBC,IAAAA,KAAK,EAAE,IA7GU;AA8GjB,aAAS,IA9GQ;AA+GjBC,IAAAA,GAAG,EAAE,IA/GY;AAgHjBC,IAAAA,IAAI,EAAE,IAhHW;AAiHjBC,IAAAA,GAAG,EAAE,IAjHY;AAkHjBC,IAAAA,IAAI,EAAE,IAlHW;AAmHjB,YAAQ,IAnHS;AAoHjBC,IAAAA,KAAK,EAAE,IApHU;AAqHjBC,IAAAA,GAAG,EAAE,IArHY;AAsHjBC,IAAAA,GAAG,EAAE,IAtHY;AAuHjBC,IAAAA,IAAI,EAAE;AAvHW,GAAnB,CA3Z0B,CAmhBvB;;AAEH5G,EAAAA,YAAY,CAAC6G,WAAb,GAA2B,KAA3B;AACA7G,EAAAA,YAAY,CAAC8G,cAAb,GAA8B,KAA9B;AACA9G,EAAAA,YAAY,CAAC+G,aAAb,GAA6B,KAA7B;AACA/G,EAAAA,YAAY,CAACgH,oBAAb,GAAoC,KAApC;AACAhH,EAAAA,YAAY,CAACiH,cAAb,GAA8B,KAA9B;AACAjH,EAAAA,YAAY,CAACkH,QAAb,GAAwB,KAAxB;AACAlH,EAAAA,YAAY,CAACmH,OAAb,GAAuB,KAAvB;AAEA;AACF;AACA;AACA;AACA;;AAEE,MAAIC,kBAAkB,GAAG,aAAa,YAAY;AAChD;AACJ;AACA;AACA;AACA;AACI,aAASA,kBAAT,CAA4BxH,kBAA5B,EAAgD;AAC9C,WAAKE,UAAL,GAAkBF,kBAAlB;AACD;AACD;AACJ;AACA;;;AAGI,QAAI9E,MAAM,GAAGsM,kBAAkB,CAACrM,SAAhC;;AAEAD,IAAAA,MAAM,CAACyE,QAAP,GAAkB,SAASA,QAAT,CAAkB1D,IAAlB,EAAwB;AACxC,aAAO,KAAKiE,UAAL,CAAgBP,QAAhB,CAAyB1D,IAAzB,EAA+B4D,MAA/B,CAAsC,UAAUxE,KAAV,EAAiB;AAC5D,eAAO,CAAC+E,YAAY,CAAC/E,KAAD,CAApB;AACD,OAFM,CAAP;AAGD,KAJD;;AAMA,WAAOmM,kBAAP;AACD,GAvBqC,EAAtC;;AAyBA,WAASC,iBAAT,CAA2BC,MAA3B,EAAmCC,KAAnC,EAA0C;AACxC,SAAK,IAAInM,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGmM,KAAK,CAAClM,MAA1B,EAAkCD,CAAC,EAAnC,EAAuC;AACrC,UAAIoM,UAAU,GAAGD,KAAK,CAACnM,CAAD,CAAtB;AACAoM,MAAAA,UAAU,CAACC,UAAX,GAAwBD,UAAU,CAACC,UAAX,IAAyB,KAAjD;AACAD,MAAAA,UAAU,CAACE,YAAX,GAA0B,IAA1B;AACA,UAAI,WAAWF,UAAf,EAA2BA,UAAU,CAACG,QAAX,GAAsB,IAAtB;AAC3B/J,MAAAA,MAAM,CAACgK,cAAP,CAAsBN,MAAtB,EAA8BE,UAAU,CAACK,GAAzC,EAA8CL,UAA9C;AACD;AACF;;AAED,WAASM,YAAT,CAAsBC,WAAtB,EAAmCC,UAAnC,EAA+CC,WAA/C,EAA4D;AAC1D,QAAID,UAAJ,EAAgBX,iBAAiB,CAACU,WAAW,CAAChN,SAAb,EAAwBiN,UAAxB,CAAjB;AAChB,QAAIC,WAAJ,EAAiBZ,iBAAiB,CAACU,WAAD,EAAcE,WAAd,CAAjB;AACjB,WAAOF,WAAP;AACD;AAED;AACF;AACA;AACA;AACA;;;AACE,MAAIG,MAAM,GAAG,aAAa,YAAY;AACpC;AACJ;AACA;;AAEI;AACJ;AACA;AACA;AACA;AACI,aAASA,MAAT,CAAgB5L,YAAhB,EAA8B;AAC5B,UAAI,CAACA,YAAL,EAAmB;AACjB,cAAM6L,KAAK,CAAC,2DAAD,CAAX;AACD;;AAED,WAAK5L,aAAL,GAAqBD,YAArB,CAL4B,CAKO;;AAEnC,WAAK8L,cAAL,GAAsB,IAAI1M,mBAAJ,EAAtB;AACA,WAAK2M,YAAL,GAAoB,IAAIhM,gBAAJ,CAAqBC,YAArB,CAApB;AACA,WAAKgM,UAAL,GAAkB,IAAIvM,kBAAJ,EAAlB;AACA,WAAK+D,UAAL,GAAkB,IAAIR,eAAJ,EAAlB;AACA,WAAKiJ,UAAL,GAAkB,EAAlB;AACA,WAAKC,iBAAL,GAAyB,EAAzB;AACD;AACD;AACJ;AACA;AACA;AACA;;;AAGI,QAAI1N,MAAM,GAAGoN,MAAM,CAACnN,SAApB;AAEA;AACJ;AACA;AACA;;AACID,IAAAA,MAAM,CAAC2N,WAAP,GAAqB,SAASA,WAAT,CAAqB/J,QAArB,EAA+B;AAClD,WAAKgK,YAAL,CAAkB,CAAChK,QAAD,CAAlB;AACD;AACD;AACJ;AACA;AACA;AANI;;AASA5D,IAAAA,MAAM,CAAC4N,YAAP,GAAsB,SAASA,YAAT,CAAsB5K,SAAtB,EAAiC;AACrD,WAAKyK,UAAL,GAAkB,KAAKA,UAAL,CAAgBI,MAAhB,CAAuB7K,SAAvB,CAAlB;AACA,WAAK8K,eAAL,CAAqB9K,SAArB,EAAgC,KAAK0K,iBAArC;AACD;AACD;AACJ;AACA;AACA;AACA;AARI;;AAWA1N,IAAAA,MAAM,CAAC+N,QAAP,GAAkB,SAASA,QAAT,CAAkBC,KAAlB,EAAyB;AACzC,WAAKN,iBAAL,CAAuBhN,IAAvB,CAA4BsN,KAA5B;;AAEA,WAAKF,eAAL,CAAqB,KAAKL,UAA1B,EAAsC,CAACO,KAAD,CAAtC;AACD;AACD;AACJ;AACA;AACA;AACA;AATI;;AAYAhO,IAAAA,MAAM,CAACuC,MAAP,GAAgB,SAASA,MAAT,CAAgB0L,KAAhB,EAAuB;AACrC,UAAIzL,MAAM,GAAG,KAAKwC,UAAL,CAAgBP,QAAhB,CAAyB,KAAK+I,UAAL,CAAgB1M,QAAhB,CAAyBmN,KAAzB,CAAzB,CAAb;;AAEA,aAAO,KAAKV,YAAL,CAAkBhL,MAAlB,CAAyBC,MAAzB,EAAiC,KAAKiL,UAAtC,CAAP;AACD;AACD;AACJ;AACA;AACA;AACA;AATI;;AAYAzN,IAAAA,MAAM,CAAC8N,eAAP,GAAyB,SAASA,eAAT,CAAyB9K,SAAzB,EAAoC0K,iBAApC,EAAuD;AAC9E,WAAKQ,YAAL,GAAoB,IAApB;AACA,UAAIC,aAAa,GAAG,KAAKb,cAAzB;AACA,UAAIc,SAAS,GAAG,KAAKZ,UAArB;AACA,UAAIa,WAAW,GAAG,KAAKd,YAAvB;AACA,UAAIe,SAAS,GAAG,KAAKtJ,UAArB;AACA,UAAIxD,YAAY,GAAG,KAAKC,aAAxB;;AAEA,WAAK,IAAI8M,EAAE,GAAG,CAAT,EAAYC,YAAY,GAAGxL,SAAS,CAACzC,MAA1C,EAAkDgO,EAAE,GAAGC,YAAvD,EAAqED,EAAE,EAAvE,EAA2E;AACzE,YAAIzM,GAAG,GAAGkB,SAAS,CAACuL,EAAD,CAAnB;AACA,YAAI1M,GAAJ;;AAEA,YAAIL,YAAY,YAAYwC,KAA5B,EAAmC;AACjCnC,UAAAA,GAAG,GAAGV,mBAAmB,CAACW,GAAD,EAAMN,YAAN,CAAzB;AACD,SAFD,MAEO;AACLK,UAAAA,GAAG,GAAGC,GAAG,CAACN,YAAD,CAAT;AACD;;AAED,aAAK,IAAIiN,GAAG,GAAG,CAAV,EAAaC,mBAAmB,GAAGhB,iBAAiB,CAACnN,MAA1D,EAAkEkO,GAAG,GAAGC,mBAAxE,EAA6FD,GAAG,EAAhG,EAAoG;AAClG,cAAIE,UAAJ;AACA,cAAIC,eAAe,GAAGlB,iBAAiB,CAACe,GAAD,CAAvC;;AAEA,cAAIG,eAAe,YAAY5K,KAA/B,EAAsC;AACpC2K,YAAAA,UAAU,GAAGxN,mBAAmB,CAACW,GAAD,EAAM8M,eAAN,CAAhC;AACD,WAFD,MAEO;AACLD,YAAAA,UAAU,GAAG7M,GAAG,CAAC8M,eAAD,CAAhB;AACD;;AAED,cAAID,UAAU,IAAI,IAAd,IAAsB,OAAOA,UAAP,KAAsB,QAA5C,IAAwDA,UAAU,CAACvC,QAAvE,EAAiF;AAC/EuC,YAAAA,UAAU,GAAGA,UAAU,CAACvC,QAAX,EAAb;AACD;;AAED,cAAI,OAAOuC,UAAP,KAAsB,QAA1B,EAAoC;AAClC,gBAAIE,WAAW,GAAGP,SAAS,CAAC7J,QAAV,CAAmB2J,SAAS,CAACtN,QAAV,CAAmB6N,UAAnB,CAAnB,CAAlB;;AAEA,iBAAK,IAAIG,GAAG,GAAG,CAAV,EAAaC,cAAc,GAAGF,WAAW,CAACtO,MAA/C,EAAuDuO,GAAG,GAAGC,cAA7D,EAA6ED,GAAG,EAAhF,EAAoF;AAClF,kBAAIE,UAAU,GAAGH,WAAW,CAACC,GAAD,CAA5B;AACA,kBAAI1O,cAAc,GAAG+N,aAAa,CAACjO,WAAd,CAA0B8O,UAA1B,CAArB;;AAEA,mBAAK,IAAIC,GAAG,GAAG,CAAV,EAAaC,kBAAkB,GAAG9O,cAAc,CAACG,MAAtD,EAA8D0O,GAAG,GAAGC,kBAApE,EAAwFD,GAAG,EAA3F,EAA+F;AAC7F,oBAAIE,aAAa,GAAG/O,cAAc,CAAC6O,GAAD,CAAlC;AACAZ,gBAAAA,WAAW,CAACzM,aAAZ,CAA0BuN,aAA1B,EAAyCtN,GAAzC,EAA8CC,GAA9C;AACD;AACF;AACF;AACF;AACF;AACF,KA/CD;;AAiDAkL,IAAAA,YAAY,CAACI,MAAD,EAAS,CAAC;AACpBL,MAAAA,GAAG,EAAE,eADe;AAEpBqC,MAAAA,GAAG,EAAE,SAASA,GAAT,CAAa9N,KAAb,EAAoB;AACvB,YAAI,KAAK4M,YAAT,EAAuB;AACrB,gBAAMb,KAAK,CAAC,mDAAD,CAAX;AACD;;AAED,aAAKC,cAAL,GAAsBhM,KAAtB;AACD,OARmB;AASpB+N,MAAAA,GAAG,EAAE,SAASA,GAAT,GAAe;AAClB,eAAO,KAAK/B,cAAZ;AACD;AACD;AACN;AACA;AACA;AACA;;AAhB0B,KAAD,EAkBlB;AACDP,MAAAA,GAAG,EAAE,WADJ;AAEDqC,MAAAA,GAAG,EAAE,SAASA,GAAT,CAAa9N,KAAb,EAAoB;AACvB,YAAI,KAAK4M,YAAT,EAAuB;AACrB,gBAAMb,KAAK,CAAC,+CAAD,CAAX;AACD;;AAED,aAAKG,UAAL,GAAkBlM,KAAlB;AACD,OARA;AASD+N,MAAAA,GAAG,EAAE,SAASA,GAAT,GAAe;AAClB,eAAO,KAAK7B,UAAZ;AACD;AACD;AACN;AACA;AACA;AACA;;AAhBO,KAlBkB,EAoClB;AACDT,MAAAA,GAAG,EAAE,aADJ;AAEDqC,MAAAA,GAAG,EAAE,SAASA,GAAT,CAAa9N,KAAb,EAAoB;AACvB,YAAI,KAAK4M,YAAT,EAAuB;AACrB,gBAAMb,KAAK,CAAC,iDAAD,CAAX;AACD;;AAED,aAAKE,YAAL,GAAoBjM,KAApB;AACD,OARA;AASD+N,MAAAA,GAAG,EAAE,SAASA,GAAT,GAAe;AAClB,eAAO,KAAK9B,YAAZ;AACD;AACD;AACN;AACA;AACA;AACA;;AAhBO,KApCkB,EAsDlB;AACDR,MAAAA,GAAG,EAAE,WADJ;AAEDqC,MAAAA,GAAG,EAAE,SAASA,GAAT,CAAa9N,KAAb,EAAoB;AACvB,YAAI,KAAK4M,YAAT,EAAuB;AACrB,gBAAMb,KAAK,CAAC,+CAAD,CAAX;AACD;;AAED,aAAKrI,UAAL,GAAkB1D,KAAlB;AACD,OARA;AASD+N,MAAAA,GAAG,EAAE,SAASA,GAAT,GAAe;AAClB,eAAO,KAAKrK,UAAZ;AACD;AAXA,KAtDkB,CAAT,CAAZ;;AAoEA,WAAOoI,MAAP;AACD,GAvMyB,EAA1B;AAyMA;AACF;AACA;AACA;AACA;AACA;;;AACE,MAAIkC,gBAAgB,GAAG,aAAa,YAAY;AAC9C;AACJ;AACA;AACA;AACA;AACA;AACA;AACI,aAASA,gBAAT,CAA0BC,iBAA1B,EAA6CC,aAA7C,EAA4DC,kBAA5D,EAAgF;AAC9E,WAAKnC,cAAL,GAAsBiC,iBAAiB,IAAI,IAAI3O,mBAAJ,EAA3C;AACA,WAAK4M,UAAL,GAAkBgC,aAAa,IAAI,IAAIvO,kBAAJ,EAAnC;AACA,WAAKyO,eAAL,GAAuBD,kBAAkB,IAAI,MAA7C;AACD;AACD;AACJ;AACA;AACA;AACA;AACA;AACA;;;AAGI,QAAIzP,MAAM,GAAGsP,gBAAgB,CAACrP,SAA9B;;AAEAD,IAAAA,MAAM,CAAC2P,SAAP,GAAmB,SAASA,SAAT,CAAmB5O,IAAnB,EAAyByB,MAAzB,EAAiC;AAClD,UAAIoN,UAAU,GAAG,KAAKC,SAAL,CAAe,EAAf,EAAmBtP,MAApC;;AAEA,UAAIuP,eAAe,GAAGhN,MAAM,CAACiN,MAAP,CAAc,IAAd,CAAtB,CAHkD,CAGP;;AAE3C,WAAK,IAAIzP,CAAC,GAAG,CAAR,EAAWqC,SAAS,GAAGH,MAAM,CAACjC,MAAnC,EAA2CD,CAAC,GAAGqC,SAA/C,EAA0DrC,CAAC,EAA3D,EAA+D;AAC7D,YAAIH,KAAK,GAAG,KAAKqN,UAAL,CAAgB1M,QAAhB,CAAyB0B,MAAM,CAAClC,CAAD,CAA/B,CAAZ;;AAEA,YAAIF,cAAc,GAAG,KAAKkN,cAAL,CAAoBpN,WAApB,CAAgCC,KAAhC,CAArB;;AAEA,aAAK,IAAIK,CAAC,GAAG,CAAR,EAAWwP,iBAAiB,GAAG5P,cAAc,CAACG,MAAnD,EAA2DC,CAAC,GAAGwP,iBAA/D,EAAkFxP,CAAC,EAAnF,EAAuF;AACrF,cAAI2O,aAAa,GAAG/O,cAAc,CAACI,CAAD,CAAlC;;AAEA,cAAI,CAACsP,eAAe,CAACX,aAAD,CAApB,EAAqC;AACnCW,YAAAA,eAAe,CAACX,aAAD,CAAf,GAAiC,CAAChP,KAAD,CAAjC;AACD,WAFD,MAEO;AACL2P,YAAAA,eAAe,CAACX,aAAD,CAAf,CAA+BzO,IAA/B,CAAoCP,KAApC;AACD;AACF;AACF,OAnBiD,CAmBhD;;;AAGF,UAAI8P,iBAAiB,GAAG,EAAxB;AACA,UAAIC,oBAAoB,GAAG,EAA3B;AACA,UAAIC,qBAAqB,GAAG,CAA5B,CAxBkD,CAwBnB;;AAE/B,WAAK,IAAI7P,CAAC,GAAG,CAAR,EAAW8P,UAAU,GAAGrP,IAAI,CAACR,MAAlC,EAA0CD,CAAC,GAAG8P,UAA9C,EAA0D9P,CAAC,EAA3D,EAA+D;AAC7D,YAAI+P,SAAS,GAAGtP,IAAI,CAACN,MAAL,CAAYH,CAAZ,CAAhB;;AAEA,YAAI+P,SAAS,KAAK,GAAlB,EAAuB;AACrBJ,UAAAA,iBAAiB,GAAG,EAApB;AACAC,UAAAA,oBAAoB,GAAG,EAAvB;AACAC,UAAAA,qBAAqB,GAAG7P,CAAC,GAAG,CAA5B;AACD,SAJD,MAIO;AACL2P,UAAAA,iBAAiB,IAAII,SAArB;AACAH,UAAAA,oBAAoB,IAAI,KAAK1C,UAAL,CAAgB1M,QAAhB,CAAyBuP,SAAzB,CAAxB;AACD;;AAED,YAAIP,eAAe,CAACI,oBAAD,CAAf,IAAyCJ,eAAe,CAACI,oBAAD,CAAf,CAAsCI,OAAtC,CAA8CJ,oBAA9C,KAAuE,CAApH,EAAuH;AACrHD,UAAAA,iBAAiB,GAAG,KAAKJ,SAAL,CAAeI,iBAAf,CAApB;AACAlP,UAAAA,IAAI,GAAGA,IAAI,CAACwP,SAAL,CAAe,CAAf,EAAkBJ,qBAAlB,IAA2CF,iBAA3C,GAA+DlP,IAAI,CAACwP,SAAL,CAAejQ,CAAC,GAAG,CAAnB,CAAtE;AACAA,UAAAA,CAAC,IAAIsP,UAAL;AACAQ,UAAAA,UAAU,IAAIR,UAAd;AACD;AACF;;AAED,aAAO7O,IAAP;AACD;AACD;AACJ;AACA;AACA;AACA;AApDI;;AAuDAf,IAAAA,MAAM,CAAC6P,SAAP,GAAmB,SAASA,SAAT,CAAmB9O,IAAnB,EAAyB;AAC1C,UAAIyP,OAAO,GAAG,KAAKd,eAAnB;AACA,aAAO,MAAMc,OAAN,GAAgB,GAAhB,GAAsBzP,IAAtB,GAA6B,IAA7B,GAAoCyP,OAApC,GAA8C,GAArD;AACD,KAHD;;AAKA,WAAOlB,gBAAP;AACD,GArFmC,EAApC;;AAuFA7P,EAAAA,OAAO,CAACM,0BAAR,GAAqCA,0BAArC;AACAN,EAAAA,OAAO,CAACoB,sBAAR,GAAiCA,sBAAjC;AACApB,EAAAA,OAAO,CAACkB,sBAAR,GAAiCA,sBAAjC;AACAlB,EAAAA,OAAO,CAACwB,kBAAR,GAA6BA,kBAA7B;AACAxB,EAAAA,OAAO,CAACmB,mBAAR,GAA8BA,mBAA9B;AACAnB,EAAAA,OAAO,CAAC2N,MAAR,GAAiBA,MAAjB;AACA3N,EAAAA,OAAO,CAAC+E,eAAR,GAA0BA,eAA1B;AACA/E,EAAAA,OAAO,CAACmF,iBAAR,GAA4BA,iBAA5B;AACAnF,EAAAA,OAAO,CAACyF,YAAR,GAAuBA,YAAvB;AACAzF,EAAAA,OAAO,CAAC6M,kBAAR,GAA6BA,kBAA7B;AACA7M,EAAAA,OAAO,CAAC8B,gBAAR,GAA2BA,gBAA3B;AACA9B,EAAAA,OAAO,CAAC6P,gBAAR,GAA2BA,gBAA3B;AACA7P,EAAAA,OAAO,CAACyE,oBAAR,GAA+BA,oBAA/B;AAEApB,EAAAA,MAAM,CAACgK,cAAP,CAAsBrN,OAAtB,EAA+B,YAA/B,EAA6C;AAAE6B,IAAAA,KAAK,EAAE;AAAT,GAA7C;AAED,CA34BA,CAAD","sourcesContent":["(function (global, factory) {\n  typeof exports === 'object' && typeof module !== 'undefined' ? factory(exports) :\n  typeof define === 'function' && define.amd ? define(['exports'], factory) :\n  (global = global || self, factory(global.JsSearch = {}));\n}(this, (function (exports) { 'use strict';\n\n  /**\n   * Indexes for all substring searches (e.g. the term \"cat\" is indexed as \"c\", \"ca\", \"cat\", \"a\", \"at\", and \"t\").\n   */\n  var AllSubstringsIndexStrategy = /*#__PURE__*/function () {\n    function AllSubstringsIndexStrategy() {}\n\n    var _proto = AllSubstringsIndexStrategy.prototype;\n\n    /**\n     * @inheritDocs\n     */\n    _proto.expandToken = function expandToken(token) {\n      var expandedTokens = [];\n      var string;\n\n      for (var i = 0, length = token.length; i < length; ++i) {\n        string = '';\n\n        for (var j = i; j < length; ++j) {\n          string += token.charAt(j);\n          expandedTokens.push(string);\n        }\n      }\n\n      return expandedTokens;\n    };\n\n    return AllSubstringsIndexStrategy;\n  }();\n\n  /**\n   * Indexes for exact word matches.\n   */\n  var ExactWordIndexStrategy = /*#__PURE__*/function () {\n    function ExactWordIndexStrategy() {}\n\n    var _proto = ExactWordIndexStrategy.prototype;\n\n    /**\n     * @inheritDocs\n     */\n    _proto.expandToken = function expandToken(token) {\n      return token ? [token] : [];\n    };\n\n    return ExactWordIndexStrategy;\n  }();\n\n  /**\n   * Indexes for prefix searches (e.g. the term \"cat\" is indexed as \"c\", \"ca\", and \"cat\" allowing prefix search lookups).\n   */\n  var PrefixIndexStrategy = /*#__PURE__*/function () {\n    function PrefixIndexStrategy() {}\n\n    var _proto = PrefixIndexStrategy.prototype;\n\n    /**\n     * @inheritDocs\n     */\n    _proto.expandToken = function expandToken(token) {\n      var expandedTokens = [];\n      var string = '';\n\n      for (var i = 0, length = token.length; i < length; ++i) {\n        string += token.charAt(i);\n        expandedTokens.push(string);\n      }\n\n      return expandedTokens;\n    };\n\n    return PrefixIndexStrategy;\n  }();\n\n  /**\n   * Enforces case-sensitive text matches.\n   */\n  var CaseSensitiveSanitizer = /*#__PURE__*/function () {\n    function CaseSensitiveSanitizer() {}\n\n    var _proto = CaseSensitiveSanitizer.prototype;\n\n    /**\n     * @inheritDocs\n     */\n    _proto.sanitize = function sanitize(text) {\n      return text ? text.trim() : '';\n    };\n\n    return CaseSensitiveSanitizer;\n  }();\n\n  /**\n   * Sanitizes text by converting to a locale-friendly lower-case version and triming leading and trailing whitespace.\n   */\n  var LowerCaseSanitizer = /*#__PURE__*/function () {\n    function LowerCaseSanitizer() {}\n\n    var _proto = LowerCaseSanitizer.prototype;\n\n    /**\n     * @inheritDocs\n     */\n    _proto.sanitize = function sanitize(text) {\n      return text ? text.toLocaleLowerCase().trim() : '';\n    };\n\n    return LowerCaseSanitizer;\n  }();\n\n  /**\n   * Find and return a nested object value.\n   *\n   * @param object to crawl\n   * @param path Property path\n   * @returns {any}\n   */\n  function getNestedFieldValue(object, path) {\n    path = path || [];\n    object = object || {};\n    var value = object; // walk down the property path\n\n    for (var i = 0; i < path.length; i++) {\n      value = value[path[i]];\n\n      if (value == null) {\n        return null;\n      }\n    }\n\n    return value;\n  }\n\n  /**\n   * Search index capable of returning results matching a set of tokens and ranked according to TF-IDF.\n   */\n  var TfIdfSearchIndex = /*#__PURE__*/function () {\n    function TfIdfSearchIndex(uidFieldName) {\n      this._uidFieldName = uidFieldName;\n      this._tokenToIdfCache = {};\n      this._tokenMap = {};\n    }\n    /**\n     * @inheritDocs\n     */\n\n\n    var _proto = TfIdfSearchIndex.prototype;\n\n    _proto.indexDocument = function indexDocument(token, uid, doc) {\n      this._tokenToIdfCache = {}; // New index invalidates previous IDF caches\n\n      var tokenMap = this._tokenMap;\n      var tokenDatum;\n\n      if (typeof tokenMap[token] !== 'object') {\n        tokenMap[token] = tokenDatum = {\n          $numDocumentOccurrences: 0,\n          $totalNumOccurrences: 1,\n          $uidMap: {}\n        };\n      } else {\n        tokenDatum = tokenMap[token];\n        tokenDatum.$totalNumOccurrences++;\n      }\n\n      var uidMap = tokenDatum.$uidMap;\n\n      if (typeof uidMap[uid] !== 'object') {\n        tokenDatum.$numDocumentOccurrences++;\n        uidMap[uid] = {\n          $document: doc,\n          $numTokenOccurrences: 1\n        };\n      } else {\n        uidMap[uid].$numTokenOccurrences++;\n      }\n    }\n    /**\n     * @inheritDocs\n     */\n    ;\n\n    _proto.search = function search(tokens, corpus) {\n      var uidToDocumentMap = {};\n\n      for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n        var token = tokens[i];\n        var tokenMetadata = this._tokenMap[token]; // Short circuit if no matches were found for any given token.\n\n        if (!tokenMetadata) {\n          return [];\n        }\n\n        if (i === 0) {\n          var keys = Object.keys(tokenMetadata.$uidMap);\n\n          for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n            var uid = keys[j];\n            uidToDocumentMap[uid] = tokenMetadata.$uidMap[uid].$document;\n          }\n        } else {\n          var keys = Object.keys(uidToDocumentMap);\n\n          for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n            var uid = keys[j];\n\n            if (typeof tokenMetadata.$uidMap[uid] !== 'object') {\n              delete uidToDocumentMap[uid];\n            }\n          }\n        }\n      }\n\n      var documents = [];\n\n      for (var uid in uidToDocumentMap) {\n        documents.push(uidToDocumentMap[uid]);\n      }\n\n      var calculateTfIdf = this._createCalculateTfIdf(); // Return documents sorted by TF-IDF\n\n\n      return documents.sort(function (documentA, documentB) {\n        return calculateTfIdf(tokens, documentB, corpus) - calculateTfIdf(tokens, documentA, corpus);\n      });\n    };\n\n    _proto._createCalculateIdf = function _createCalculateIdf() {\n      var tokenMap = this._tokenMap;\n      var tokenToIdfCache = this._tokenToIdfCache;\n      return function calculateIdf(token, documents) {\n        if (!tokenToIdfCache[token]) {\n          var numDocumentsWithToken = typeof tokenMap[token] !== 'undefined' ? tokenMap[token].$numDocumentOccurrences : 0;\n          tokenToIdfCache[token] = 1 + Math.log(documents.length / (1 + numDocumentsWithToken));\n        }\n\n        return tokenToIdfCache[token];\n      };\n    };\n\n    _proto._createCalculateTfIdf = function _createCalculateTfIdf() {\n      var tokenMap = this._tokenMap;\n      var uidFieldName = this._uidFieldName;\n\n      var calculateIdf = this._createCalculateIdf();\n\n      return function calculateTfIdf(tokens, document, documents) {\n        var score = 0;\n\n        for (var i = 0, numTokens = tokens.length; i < numTokens; ++i) {\n          var token = tokens[i];\n          var inverseDocumentFrequency = calculateIdf(token, documents);\n\n          if (inverseDocumentFrequency === Infinity) {\n            inverseDocumentFrequency = 0;\n          }\n\n          var uid;\n\n          if (uidFieldName instanceof Array) {\n            uid = document && getNestedFieldValue(document, uidFieldName);\n          } else {\n            uid = document && document[uidFieldName];\n          }\n\n          var termFrequency = typeof tokenMap[token] !== 'undefined' && typeof tokenMap[token].$uidMap[uid] !== 'undefined' ? tokenMap[token].$uidMap[uid].$numTokenOccurrences : 0;\n          score += termFrequency * inverseDocumentFrequency;\n        }\n\n        return score;\n      };\n    };\n\n    return TfIdfSearchIndex;\n  }();\n\n  /**\n   * Search index capable of returning results matching a set of tokens but without any meaningful rank or order.\n   */\n  var UnorderedSearchIndex = /*#__PURE__*/function () {\n    function UnorderedSearchIndex() {\n      this._tokenToUidToDocumentMap = {};\n    }\n    /**\n     * @inheritDocs\n     */\n\n\n    var _proto = UnorderedSearchIndex.prototype;\n\n    _proto.indexDocument = function indexDocument(token, uid, doc) {\n      if (typeof this._tokenToUidToDocumentMap[token] !== 'object') {\n        this._tokenToUidToDocumentMap[token] = {};\n      }\n\n      this._tokenToUidToDocumentMap[token][uid] = doc;\n    }\n    /**\n     * @inheritDocs\n     */\n    ;\n\n    _proto.search = function search(tokens, corpus) {\n      var intersectingDocumentMap = {};\n      var tokenToUidToDocumentMap = this._tokenToUidToDocumentMap;\n\n      for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n        var token = tokens[i];\n        var documentMap = tokenToUidToDocumentMap[token]; // Short circuit if no matches were found for any given token.\n\n        if (!documentMap) {\n          return [];\n        }\n\n        if (i === 0) {\n          var keys = Object.keys(documentMap);\n\n          for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n            var uid = keys[j];\n            intersectingDocumentMap[uid] = documentMap[uid];\n          }\n        } else {\n          var keys = Object.keys(intersectingDocumentMap);\n\n          for (var j = 0, numKeys = keys.length; j < numKeys; j++) {\n            var uid = keys[j];\n\n            if (typeof documentMap[uid] !== 'object') {\n              delete intersectingDocumentMap[uid];\n            }\n          }\n        }\n      }\n\n      var keys = Object.keys(intersectingDocumentMap);\n      var documents = [];\n\n      for (var i = 0, numKeys = keys.length; i < numKeys; i++) {\n        var uid = keys[i];\n        documents.push(intersectingDocumentMap[uid]);\n      }\n\n      return documents;\n    };\n\n    return UnorderedSearchIndex;\n  }();\n\n  var REGEX = /[^a-zа-яё0-9\\-']+/i;\n  /**\n   * Simple tokenizer that splits strings on whitespace characters and returns an array of all non-empty substrings.\n   */\n\n  var SimpleTokenizer = /*#__PURE__*/function () {\n    function SimpleTokenizer() {}\n\n    var _proto = SimpleTokenizer.prototype;\n\n    /**\n     * @inheritDocs\n     */\n    _proto.tokenize = function tokenize(text) {\n      return text.split(REGEX).filter(function (text) {\n        return text;\n      } // Filter empty tokens\n      );\n    };\n\n    return SimpleTokenizer;\n  }();\n\n  /**\n   * Stemming is the process of reducing search tokens to their root (or stem) so that searches for different forms of a\n   * word will match. For example \"search\", \"searching\" and \"searched\" are all reduced to the stem \"search\".\n   *\n   * <p>This stemming tokenizer converts tokens (words) to their stem forms before returning them. It requires an\n   * external stemming function to be provided; for this purpose I recommend the NPM 'porter-stemmer' library.\n   *\n   * <p>For more information see http : //tartarus.org/~martin/PorterStemmer/\n   */\n  var StemmingTokenizer = /*#__PURE__*/function () {\n    /**\n     * Constructor.\n     *\n     * @param stemmingFunction Function capable of accepting a word and returning its stem.\n     * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n     */\n    function StemmingTokenizer(stemmingFunction, decoratedTokenizer) {\n      this._stemmingFunction = stemmingFunction;\n      this._tokenizer = decoratedTokenizer;\n    }\n    /**\n     * @inheritDocs\n     */\n\n\n    var _proto = StemmingTokenizer.prototype;\n\n    _proto.tokenize = function tokenize(text) {\n      return this._tokenizer.tokenize(text).map(this._stemmingFunction);\n    };\n\n    return StemmingTokenizer;\n  }();\n\n  /**\n   * Stop words list copied from Lunr JS.\n   */\n  var StopWordsMap = {\n    a: true,\n    able: true,\n    about: true,\n    across: true,\n    after: true,\n    all: true,\n    almost: true,\n    also: true,\n    am: true,\n    among: true,\n    an: true,\n    and: true,\n    any: true,\n    are: true,\n    as: true,\n    at: true,\n    be: true,\n    because: true,\n    been: true,\n    but: true,\n    by: true,\n    can: true,\n    cannot: true,\n    could: true,\n    dear: true,\n    did: true,\n    'do': true,\n    does: true,\n    either: true,\n    'else': true,\n    ever: true,\n    every: true,\n    'for': true,\n    from: true,\n    'get': true,\n    got: true,\n    had: true,\n    has: true,\n    have: true,\n    he: true,\n    her: true,\n    hers: true,\n    him: true,\n    his: true,\n    how: true,\n    however: true,\n    i: true,\n    'if': true,\n    'in': true,\n    into: true,\n    is: true,\n    it: true,\n    its: true,\n    just: true,\n    least: true,\n    \"let\": true,\n    like: true,\n    likely: true,\n    may: true,\n    me: true,\n    might: true,\n    most: true,\n    must: true,\n    my: true,\n    neither: true,\n    no: true,\n    nor: true,\n    not: true,\n    of: true,\n    off: true,\n    often: true,\n    on: true,\n    only: true,\n    or: true,\n    other: true,\n    our: true,\n    own: true,\n    rather: true,\n    said: true,\n    say: true,\n    says: true,\n    she: true,\n    should: true,\n    since: true,\n    so: true,\n    some: true,\n    than: true,\n    that: true,\n    the: true,\n    their: true,\n    them: true,\n    then: true,\n    there: true,\n    these: true,\n    they: true,\n    'this': true,\n    tis: true,\n    to: true,\n    too: true,\n    twas: true,\n    us: true,\n    wants: true,\n    was: true,\n    we: true,\n    were: true,\n    what: true,\n    when: true,\n    where: true,\n    which: true,\n    'while': true,\n    who: true,\n    whom: true,\n    why: true,\n    will: true,\n    'with': true,\n    would: true,\n    yet: true,\n    you: true,\n    your: true\n  }; // Prevent false positives for inherited properties\n\n  StopWordsMap.constructor = false;\n  StopWordsMap.hasOwnProperty = false;\n  StopWordsMap.isPrototypeOf = false;\n  StopWordsMap.propertyIsEnumerable = false;\n  StopWordsMap.toLocaleString = false;\n  StopWordsMap.toString = false;\n  StopWordsMap.valueOf = false;\n\n  /**\n   * Stop words are very common (e.g. \"a\", \"and\", \"the\") and are often not semantically meaningful in the context of a\n   * search. This tokenizer removes stop words from a set of tokens before passing the remaining tokens along for\n   * indexing or searching purposes.\n   */\n\n  var StopWordsTokenizer = /*#__PURE__*/function () {\n    /**\n     * Constructor.\n     *\n     * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n     */\n    function StopWordsTokenizer(decoratedTokenizer) {\n      this._tokenizer = decoratedTokenizer;\n    }\n    /**\n     * @inheritDocs\n     */\n\n\n    var _proto = StopWordsTokenizer.prototype;\n\n    _proto.tokenize = function tokenize(text) {\n      return this._tokenizer.tokenize(text).filter(function (token) {\n        return !StopWordsMap[token];\n      });\n    };\n\n    return StopWordsTokenizer;\n  }();\n\n  function _defineProperties(target, props) {\n    for (var i = 0; i < props.length; i++) {\n      var descriptor = props[i];\n      descriptor.enumerable = descriptor.enumerable || false;\n      descriptor.configurable = true;\n      if (\"value\" in descriptor) descriptor.writable = true;\n      Object.defineProperty(target, descriptor.key, descriptor);\n    }\n  }\n\n  function _createClass(Constructor, protoProps, staticProps) {\n    if (protoProps) _defineProperties(Constructor.prototype, protoProps);\n    if (staticProps) _defineProperties(Constructor, staticProps);\n    return Constructor;\n  }\n\n  /**\n   * Simple client-side searching within a set of documents.\n   *\n   * <p>Documents can be searched by any number of fields. Indexing and search strategies are highly customizable.\n   */\n  var Search = /*#__PURE__*/function () {\n    /**\n     * Array containing either a property name or a path (list of property names) to a nested value\n     */\n\n    /**\n     * Constructor.\n     * @param uidFieldName Field containing values that uniquely identify search documents; this field's values are used\n     *                     to ensure that a search result set does not contain duplicate objects.\n     */\n    function Search(uidFieldName) {\n      if (!uidFieldName) {\n        throw Error('js-search requires a uid field name constructor parameter');\n      }\n\n      this._uidFieldName = uidFieldName; // Set default/recommended strategies\n\n      this._indexStrategy = new PrefixIndexStrategy();\n      this._searchIndex = new TfIdfSearchIndex(uidFieldName);\n      this._sanitizer = new LowerCaseSanitizer();\n      this._tokenizer = new SimpleTokenizer();\n      this._documents = [];\n      this._searchableFields = [];\n    }\n    /**\n     * Override the default index strategy.\n     * @param value Custom index strategy\n     * @throws Error if documents have already been indexed by this search instance\n     */\n\n\n    var _proto = Search.prototype;\n\n    /**\n     * Add a searchable document to the index. Document will automatically be indexed for search.\n     * @param document\n     */\n    _proto.addDocument = function addDocument(document) {\n      this.addDocuments([document]);\n    }\n    /**\n     * Adds searchable documents to the index. Documents will automatically be indexed for search.\n     * @param document\n     */\n    ;\n\n    _proto.addDocuments = function addDocuments(documents) {\n      this._documents = this._documents.concat(documents);\n      this.indexDocuments_(documents, this._searchableFields);\n    }\n    /**\n     * Add a new searchable field to the index. Existing documents will automatically be indexed using this new field.\n     *\n     * @param field Searchable field or field path. Pass a string to index a top-level field and an array of strings for nested fields.\n     */\n    ;\n\n    _proto.addIndex = function addIndex(field) {\n      this._searchableFields.push(field);\n\n      this.indexDocuments_(this._documents, [field]);\n    }\n    /**\n     * Search all documents for ones matching the specified query text.\n     * @param query\n     * @returns {Array<Object>}\n     */\n    ;\n\n    _proto.search = function search(query) {\n      var tokens = this._tokenizer.tokenize(this._sanitizer.sanitize(query));\n\n      return this._searchIndex.search(tokens, this._documents);\n    }\n    /**\n     * @param documents\n     * @param _searchableFields Array containing property names and paths (lists of property names) to nested values\n     * @private\n     */\n    ;\n\n    _proto.indexDocuments_ = function indexDocuments_(documents, _searchableFields) {\n      this._initialized = true;\n      var indexStrategy = this._indexStrategy;\n      var sanitizer = this._sanitizer;\n      var searchIndex = this._searchIndex;\n      var tokenizer = this._tokenizer;\n      var uidFieldName = this._uidFieldName;\n\n      for (var di = 0, numDocuments = documents.length; di < numDocuments; di++) {\n        var doc = documents[di];\n        var uid;\n\n        if (uidFieldName instanceof Array) {\n          uid = getNestedFieldValue(doc, uidFieldName);\n        } else {\n          uid = doc[uidFieldName];\n        }\n\n        for (var sfi = 0, numSearchableFields = _searchableFields.length; sfi < numSearchableFields; sfi++) {\n          var fieldValue;\n          var searchableField = _searchableFields[sfi];\n\n          if (searchableField instanceof Array) {\n            fieldValue = getNestedFieldValue(doc, searchableField);\n          } else {\n            fieldValue = doc[searchableField];\n          }\n\n          if (fieldValue != null && typeof fieldValue !== 'string' && fieldValue.toString) {\n            fieldValue = fieldValue.toString();\n          }\n\n          if (typeof fieldValue === 'string') {\n            var fieldTokens = tokenizer.tokenize(sanitizer.sanitize(fieldValue));\n\n            for (var fti = 0, numFieldValues = fieldTokens.length; fti < numFieldValues; fti++) {\n              var fieldToken = fieldTokens[fti];\n              var expandedTokens = indexStrategy.expandToken(fieldToken);\n\n              for (var eti = 0, nummExpandedTokens = expandedTokens.length; eti < nummExpandedTokens; eti++) {\n                var expandedToken = expandedTokens[eti];\n                searchIndex.indexDocument(expandedToken, uid, doc);\n              }\n            }\n          }\n        }\n      }\n    };\n\n    _createClass(Search, [{\n      key: \"indexStrategy\",\n      set: function set(value) {\n        if (this._initialized) {\n          throw Error('IIndexStrategy cannot be set after initialization');\n        }\n\n        this._indexStrategy = value;\n      },\n      get: function get() {\n        return this._indexStrategy;\n      }\n      /**\n       * Override the default text sanitizing strategy.\n       * @param value Custom text sanitizing strategy\n       * @throws Error if documents have already been indexed by this search instance\n       */\n\n    }, {\n      key: \"sanitizer\",\n      set: function set(value) {\n        if (this._initialized) {\n          throw Error('ISanitizer cannot be set after initialization');\n        }\n\n        this._sanitizer = value;\n      },\n      get: function get() {\n        return this._sanitizer;\n      }\n      /**\n       * Override the default search index strategy.\n       * @param value Custom search index strategy\n       * @throws Error if documents have already been indexed\n       */\n\n    }, {\n      key: \"searchIndex\",\n      set: function set(value) {\n        if (this._initialized) {\n          throw Error('ISearchIndex cannot be set after initialization');\n        }\n\n        this._searchIndex = value;\n      },\n      get: function get() {\n        return this._searchIndex;\n      }\n      /**\n       * Override the default text tokenizing strategy.\n       * @param value Custom text tokenizing strategy\n       * @throws Error if documents have already been indexed by this search instance\n       */\n\n    }, {\n      key: \"tokenizer\",\n      set: function set(value) {\n        if (this._initialized) {\n          throw Error('ITokenizer cannot be set after initialization');\n        }\n\n        this._tokenizer = value;\n      },\n      get: function get() {\n        return this._tokenizer;\n      }\n    }]);\n\n    return Search;\n  }();\n\n  /**\n   * This utility highlights the occurrences of tokens within a string of text. It can be used to give visual indicators\n   * of match criteria within searchable fields.\n   *\n   * <p>For performance purposes this highlighter only works with full-word or prefix token indexes.\n   */\n  var TokenHighlighter = /*#__PURE__*/function () {\n    /**\n     * Constructor.\n     *\n     * @param opt_indexStrategy Index strategy used by Search\n     * @param opt_sanitizer Sanitizer used by Search\n     * @param opt_wrapperTagName Optional wrapper tag name; defaults to 'mark' (e.g. <mark>)\n     */\n    function TokenHighlighter(opt_indexStrategy, opt_sanitizer, opt_wrapperTagName) {\n      this._indexStrategy = opt_indexStrategy || new PrefixIndexStrategy();\n      this._sanitizer = opt_sanitizer || new LowerCaseSanitizer();\n      this._wrapperTagName = opt_wrapperTagName || 'mark';\n    }\n    /**\n     * Highlights token occurrences within a string by wrapping them with a DOM element.\n     *\n     * @param text e.g. \"john wayne\"\n     * @param tokens e.g. [\"wa\"]\n     * @returns {string} e.g. \"john <mark>wa</mark>yne\"\n     */\n\n\n    var _proto = TokenHighlighter.prototype;\n\n    _proto.highlight = function highlight(text, tokens) {\n      var tagsLength = this._wrapText('').length;\n\n      var tokenDictionary = Object.create(null); // Create a token map for easier lookup below.\n\n      for (var i = 0, numTokens = tokens.length; i < numTokens; i++) {\n        var token = this._sanitizer.sanitize(tokens[i]);\n\n        var expandedTokens = this._indexStrategy.expandToken(token);\n\n        for (var j = 0, numExpandedTokens = expandedTokens.length; j < numExpandedTokens; j++) {\n          var expandedToken = expandedTokens[j];\n\n          if (!tokenDictionary[expandedToken]) {\n            tokenDictionary[expandedToken] = [token];\n          } else {\n            tokenDictionary[expandedToken].push(token);\n          }\n        }\n      } // Track actualCurrentWord and sanitizedCurrentWord separately in case we encounter nested tags.\n\n\n      var actualCurrentWord = '';\n      var sanitizedCurrentWord = '';\n      var currentWordStartIndex = 0; // Note this assumes either prefix or full word matching.\n\n      for (var i = 0, textLength = text.length; i < textLength; i++) {\n        var character = text.charAt(i);\n\n        if (character === ' ') {\n          actualCurrentWord = '';\n          sanitizedCurrentWord = '';\n          currentWordStartIndex = i + 1;\n        } else {\n          actualCurrentWord += character;\n          sanitizedCurrentWord += this._sanitizer.sanitize(character);\n        }\n\n        if (tokenDictionary[sanitizedCurrentWord] && tokenDictionary[sanitizedCurrentWord].indexOf(sanitizedCurrentWord) >= 0) {\n          actualCurrentWord = this._wrapText(actualCurrentWord);\n          text = text.substring(0, currentWordStartIndex) + actualCurrentWord + text.substring(i + 1);\n          i += tagsLength;\n          textLength += tagsLength;\n        }\n      }\n\n      return text;\n    }\n    /**\n     * @param text to wrap\n     * @returns Text wrapped by wrapper tag (e.g. \"foo\" becomes \"<mark>foo</mark>\")\n     * @private\n     */\n    ;\n\n    _proto._wrapText = function _wrapText(text) {\n      var tagName = this._wrapperTagName;\n      return \"<\" + tagName + \">\" + text + \"</\" + tagName + \">\";\n    };\n\n    return TokenHighlighter;\n  }();\n\n  exports.AllSubstringsIndexStrategy = AllSubstringsIndexStrategy;\n  exports.CaseSensitiveSanitizer = CaseSensitiveSanitizer;\n  exports.ExactWordIndexStrategy = ExactWordIndexStrategy;\n  exports.LowerCaseSanitizer = LowerCaseSanitizer;\n  exports.PrefixIndexStrategy = PrefixIndexStrategy;\n  exports.Search = Search;\n  exports.SimpleTokenizer = SimpleTokenizer;\n  exports.StemmingTokenizer = StemmingTokenizer;\n  exports.StopWordsMap = StopWordsMap;\n  exports.StopWordsTokenizer = StopWordsTokenizer;\n  exports.TfIdfSearchIndex = TfIdfSearchIndex;\n  exports.TokenHighlighter = TokenHighlighter;\n  exports.UnorderedSearchIndex = UnorderedSearchIndex;\n\n  Object.defineProperty(exports, '__esModule', { value: true });\n\n})));\n"]},"metadata":{},"sourceType":"script"}